id,url,url_id,url_title,author,upvote_ratio,score,time_created,num_gold,num_comments,category,text,main_link,flairs
1,https://www.reddit.com/r/MachineLearning/comments/e1r0ou/d_chinese_government_uses_machine_learning_not/,e1r0ou,d_chinese_government_uses_machine_learning_not,sensetime,0.96,840,2019-11-26 03:09:24,0,179,"Tech,","Link to storyThis post is not an ML research related post. I am posting this because I think it is important for the community to see how research is applied by authoritarian governments to achieve their goals. It is related to a few previous popular posts on this subreddit with high upvotes, which prompted me to post this story.Previous related stories:Is machine learning's killer app totalitarian surveillance and oppression?Using CV for surveillance and regression for threat scoring citizens in XinjiangICCV 19: The state of some ethically questionable papersHikvision marketed ML surveillance camera that automatically identifies UyghursWorking on an ethically questionnable project...The story reports the details of a new leak of highly classified Chinese government documents reveals the operations manual for running the mass detention camps in Xinjiang and exposed the mechanics of the region’s system of mass surveillance.The lead journalist's summary of findingsThe China Cables represent the first leak of a classified Chinese government document revealing the inner workings of the detention camps, as well as the first leak of classified government documents unveiling the predictive policing system in Xinjiang.The leak features classified intelligence briefings that reveal, in the government’s own words, how Xinjiang police essentially take orders from a massive “cybernetic brain” known as IJOP, which flags entire categories of people for investigation & detention.These secret intelligence briefings reveal the scope and ambition of the government’s AI-powered policing platform, which purports to predict crimes based on computer-generated findings alone. The result? Arrest by algorithm.The article describe methods used for algorithmic policingThe classified intelligence briefings reveal the scope and ambition of the government’s artificial-intelligence-powered policing platform, which purports to predict crimes based on these computer-generated findings alone. Experts say the platform, which is used in both policing and military contexts, demonstrates the power of technology to help drive industrial-scale human rights abuses.“The Chinese [government] have bought into a model of policing where they believe that through the collection of large-scale data run through artificial intelligence and machine learning that they can, in fact, predict ahead of time where possible incidents might take place, as well as identify possible populations that have the propensity to engage in anti-state anti-regime action,” said Mulvenon, the SOS International document expert and director of intelligence integration. “And then they are preemptively going after those people using that data.”In addition to the predictive policing aspect of the article, there are side articles about the entire ML stack, including how mobile apps are used to target Uighurs, and also how the inmates are re-educated once inside the concentration camps. The documents reveal how every aspect of a detainee's life is monitored and controlled.Note: My motivation for posting this story is to raise ethical concerns and awareness in the research community. I do not want to heighten levels of racism towards the Chinese research community (not that it may matter, but I am Chinese). See this thread for some context about what I don't want these discussions to become.I am aware of the fact that the Chinese government's policy is to integrate the state and the people as one, so accusing the party is perceived domestically as insulting the Chinese people, but I also believe that we as a research community is intelligent enough to be able to separate government, and those in power, from individual researchers. We as a community should keep in mind that there are many Chinese researchers (in mainland and abroad) who are not supportive of the actions of the CCP, but they may not be able to voice their concerns due to personal risk.Edit Suggestion from /u/DunkelBeard:When discussing issues relating to the Chinese government, try to use the term CCP, Chinese Communist Party, Chinese government, or Beijing. Try not to use only the term Chinese or China when describing the government, as it may be misinterpreted as referring to the Chinese people (either citizens of China, or people of Chinese ethnicity), if that is not your intention. As mentioned earlier, conflating China and the CCP is actually a tactic of the CCP.",,"Discussion,"
2,https://www.reddit.com/r/MachineLearning/comments/dxshkg/d_machine_learning_wayr_what_are_you_reading_week/,dxshkg,d_machine_learning_wayr_what_are_you_reading_week,ML_WAYR_bot,0.88,39,2019-11-17 22:00:05,0,1,"Tech,","This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.Please try to provide some insight from your understanding and please don't post things which are present in wiki.Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.Previous weeks :1-1011-2021-3031-4041-5051-6061-7071-80Week 1Week 11Week 21Week 31Week 41Week 51Week 61Week 71Week 2Week 12Week 22Week 32Week 42Week 52Week 62Week 72Week 3Week 13Week 23Week 33Week 43Week 53Week 63Week 73Week 4Week 14Week 24Week 34Week 44Week 54Week 64Week 74Week 5Week 15Week 25Week 35Week 45Week 55Week 65Week 6Week 16Week 26Week 36Week 46Week 56Week 66Week 7Week 17Week 27Week 37Week 47Week 57Week 67Week 8Week 18Week 28Week 38Week 48Week 58Week 68Week 9Week 19Week 29Week 39Week 49Week 59Week 69Week 10Week 20Week 30Week 40Week 50Week 60Week 70Most upvoted papers two weeks ago:/u/adventuringraw: original TrueSkill paper from Microsoft/u/Grimm___: http://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdfBesides that, there are no rules, have fun.",,"Discussion,"
3,https://www.reddit.com/r/MachineLearning/comments/e23ezq/p_using_stylegan_to_make_a_music_visualizer/,e23ezq,p_using_stylegan_to_make_a_music_visualizer,AtreveteTeTe,1.0,31,2019-11-26 20:54:37,0,6,"Tech,","I'm excited to share this generative video project I worked on with Japanese electronic music artist Qrion for the release of her Sine Wave Party EP.Here's the first generated video - two more coming out soon.This was created using StyleGAN and doing a transfer learning with a custom dataset of images curated by the artist.  Qrion picked images that matched the mood of each song (things like clouds, lava hitting the ocean, forest interiors, and snowy mountains) and I generated interpolation videos for each track.The tempo of the GAN evolution is controlled by a few different things:the beat of the songa system I built that incorporates live input (you can tap the keyboard to add a jump to the playback in After Effects)a keyframeable overall playback speed fader systemI've also posted some more images I created with Qrion's custom models here on my site.  There are some further StyleGAN experiments there too if you're interested.It's been fascinating to learn how to use StyleGAN like this.  As a visual effects artist, I'm over the moon with the sorts of things that are possible.  Indeed, I also wanted to shout out /u/C0D32 who shared an art-centered StyleGAN model that was really influential to me!  Thanks for that.  Also, of course, /u/gwern who posted an incredible guide to using StyleGAN.",,"Project,"
4,https://www.reddit.com/r/MachineLearning/comments/e202r7/p_i_reimplemented_stylegan_using_tensorflow_20/,e202r7,p_i_reimplemented_stylegan_using_tensorflow_20,manicman1999,0.89,34,2019-11-26 17:13:01,0,8,"Tech,","Here is a sample of 64 of the images when trained on r/EarthPorn:https://i.imgur.com/K9mU7vH.jpgHere is the code:https://github.com/manicman1999/StyleGAN-Tensorflow-2.0And finally, here is the live web demo:https://matchue.ca/p/earthhd/Enjoy!",,"Project,"
5,https://www.reddit.com/r/MachineLearning/comments/e1zub9/p_benchmarking_metric_learning_algorithms_the/,e1zub9,p_benchmarking_metric_learning_algorithms_the,VanillaCashew,0.79,18,2019-11-26 16:57:24,0,7,"Tech,","I've been researching metric learning algorithms for a while now, and in the process I discovered some issues with the field.You can read about it here: https://medium.com/@tkm45/benchmarking-metric-learning-algorithms-the-right-way-90c073a83968TL;DR:Many papers don't do apple-to-apple comparisons. They change the network architecture, embedding size, data augmentation, or just use performance-boosting tricks that aren't mentioned in their paper.Most papers don't use a validation set.Two baseline algorithms (triplet and contrastive loss) are actually competitive with the state-of-the-art, but are not presented this way in most papers.I've made a flexible benchmarking tool that can standardize the way we evaluate metric learning algorithms. You can see it here: https://github.com/KevinMusgrave/powerful_benchmarker",,"Project,"
6,https://www.reddit.com/r/MachineLearning/comments/e21fgz/r_unsupervised_attention_mechanism_across_neural/,e21fgz,r_unsupervised_attention_mechanism_across_neural,doerlbh,0.88,6,2019-11-26 18:42:17,0,2,"Tech,",,https://arxiv.org/abs/1902.10658,"Research,"
7,https://www.reddit.com/r/MachineLearning/comments/e1zdly/d_how_to_check_if_my_datasets_have_covariate/,e1zdly,d_how_to_check_if_my_datasets_have_covariate,stat_leaf,0.83,7,2019-11-26 16:23:44,0,2,"Tech,","I have 2 datasets where the covariates used are the same but the scale used are different. For example, dataset 1 could have scale for pressure parameter at 0.1, 0.2, 0.5, 0.8 and dataset 2 scale for the pressure parameter is 0.3, 0.8, 0.2, 0.9, 1.0so far I have plotted the distribution for the response variable (dependent variable) and dataset1 and dataset2 have different distributions for the response variable but if I understand correctly, covariate shift occurs when the distribution of the covariate differs between dataset1 and dataset2.How can I properly check this assumption?If I am planning to train a model on dataset1 to be tested for dataset2 with a different distribution, what are the methods that can be used ( this is a regression task) besides Neural Network?Thank you.",,"Discussion,"
8,https://www.reddit.com/r/MachineLearning/comments/e1vgpd/r_gradient_descent_happens_in_a_tiny_subspace/,e1vgpd,r_gradient_descent_happens_in_a_tiny_subspace,jarekduda,1.0,29,2019-11-26 10:09:47,0,16,"Tech,",,https://arxiv.org/pdf/1812.04754,"Research,"
9,https://www.reddit.com/r/MachineLearning/comments/e1v2q1/p_a_visual_guide_to_using_bert_for_the_first_time/,e1v2q1,p_a_visual_guide_to_using_bert_for_the_first_time,nortab,0.97,26,2019-11-26 09:24:04,0,7,"Tech,","Hi r/MachineLearning,I wrote a blog post that I hope could be the gentlest way for you to start playing with BERT for the first time;https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/It uses a lighter version of BERT (the distilled version from HuggingFace, distilBERT) to do sentence embedding, then uses Scikit Learn for Linear Regression classification. As a first exposure to BERT, I'm having people use the general trained model and not worry about fine-tuning for now. After getting people through this initial hump, I'm hoping readers would get more comfortable doing more exploration and poking around with the model and its usecases.I hope you enjoy it. All feedback/corrections are appreciated.",,"Project,"
10,https://www.reddit.com/r/MachineLearning/comments/e1k092/rp_talking_head_anime_from_a_single_image/,e1k092,rp_talking_head_anime_from_a_single_image,pramook,0.98,313,2019-11-25 19:11:28,0,28,"Tech,","I trained a network to animate faces of anime characters. The input is an image of the character looking straight at the viewer and a pose, specified by 6 numbers. The output is another image of the character with the face posed accordingly.Play0:000:00SettingsFullscreenWhat the network can do in a nutshell.I created two tools with this network.One that changes facial poses by GUI manipulation:  https://www.youtube.com/watch?v=kMQCERkTdO0One that reads a webcam feed and make a character imitates the user's facial movement:  https://www.youtube.com/watch?v=T1Gp-RxFZwUUsing a face tracker, I could transfer human face movements from existing videos to anime characters. Here are some characters impersonating President Obama:Play0:000:00SettingsFullscreenThe approach I took is to combine two previous works. The first is the Pumarola et al.'s 2018 GANimation paper, which I use to change the facial features (closing eyes and mouth, in particular). The second is  Zhou et al.'s 2016 object rotation by appearance flow paper, which I use to rotate the face. I generated a new dataset by rendering 8,000 downloadable 3D models of anime characters.You can find out more about the project at https://pkhungurn.github.io/talking-head-anime/.",,"Research,"
11,https://www.reddit.com/r/MachineLearning/comments/e27sef/r_rigging_the_lottery_making_all_tickets_winners/,e27sef,r_rigging_the_lottery_making_all_tickets_winners,hardmaru,1.0,0,2019-11-27 01:46:06,0,1,"Tech,",,https://arxiv.org/abs/1911.11134,"Research,"
12,https://www.reddit.com/r/MachineLearning/comments/e1zw6t/d_ideas_for_interesting_eyeopening_for_beginner/,e1zw6t,d_ideas_for_interesting_eyeopening_for_beginner,titusng074,0.72,3,2019-11-26 17:01:16,0,7,"Tech,","So I'm an IB high school student and the IB curriculum requires us to write an extended essay, which is a 4000-word mini-research paper answering a research question. As I'm interested in machine learning, but CS is not available at school, I chose to write about mathematics. I explored some basic stuffs such as gradient descent and back propagation; but they are too fixed and I can't seem to formulate a question around them. Can you guys suggest some interesting mathematics in machine learning to investigate on?Also, an adult friend of mine suggest me to try ""beta distribution"", but after an hour of research I can't find the relationship between it and machine learning. Some insight will be hugely appreciated. Thanks.",,"Discussion,"
13,https://www.reddit.com/r/MachineLearning/comments/e1pvg1/p_machine_learning_systems_design_open_source/,e1pvg1,p_machine_learning_systems_design_open_source,hardmaru,0.96,53,2019-11-26 01:41:17,0,4,"Tech,","An open source book compiled by Chip Huyen. Feel free to contribute:This booklet covers four main steps of designing a machine learning system:Project setupData pipelineModeling: selecting, training, and debuggingServing: testing, deploying, and maintainingIt comes with links to practical resources that explain each aspect in more details. It also suggests case studies written by machine learning engineers at major tech companies who have deployed machine learning systems to solve real-world problems.At the end, the booklet contains 27 open-ended machine learning systems design questions that might come up in machine learning interviews. The answers for these questions will be published in the book Machine Learning Interviews.project: https://github.com/chiphuyen/machine-learning-systems-designPDF: https://github.com/chiphuyen/machine-learning-systems-design/blob/master/build/build1/consolidated.pdf",,"Project,"
14,https://www.reddit.com/r/MachineLearning/comments/e25746/p_handwritten_text_recognition_using_convolution/,e25746,p_handwritten_text_recognition_using_convolution,spacevstab,0.67,1,2019-11-26 22:48:44,0,0,"Tech,","Convolution Seq-to-SeqInstead of using RNN with Seq-to-Seq modeling, CNN with Seq-to-Seq has been used which reduces the training and inference time. The work is novel when implemented around Dec 2018. The training and testing pipeline has been created for IAM handwitten dataset. Please provide some feedback on this project and its continuity since I would like to make further advancement and formally document the work into a article.",,"Project,"
15,https://www.reddit.com/r/MachineLearning/comments/e1z4ge/190605433v2_tackling_climate_change_with_machine/,e1z4ge,190605433v2_tackling_climate_change_with_machine,Smith4242,0.6,2,2019-11-26 16:04:34,0,2,"Tech,",,https://arxiv.org/abs/1906.05433v2,
16,https://www.reddit.com/r/MachineLearning/comments/e24e5k/d_how_can_i_elaborate_texture_and_statistic/,e24e5k,d_how_can_i_elaborate_texture_and_statistic,Samatarou,1.0,1,2019-11-26 21:58:16,0,2,"Tech,","I have a dataset 2200x34 where 1-33 column are features (texture and statistic) and 34th column is the class (0 or 1). I know my dataset is quite poor, but I splitted in 80% training set and 20% validation test.I'd like to use CNN for classification using these features, my steps are:- Splitting in training set and validation test;- Mean normalisation of features;- Reshaping training set and validation set in order to have 1760x34x1 and 440x34x1 as dimensions;- Create my model:opt = SGD(lr=0.0001)
model = Sequential()
model.add(Conv1D(16, 3, activation=""relu"", input_shape =(34,1)))
model.add(BatchNormalization())
model.add(MaxPooling1D(2))
model.add(Conv1D(32, 3, activation=""relu""))
model.add(MaxPooling1D(2))
model.add(Flatten())
model.add(Dense(512, activation=""relu""))
model.add(Dropout(0.5))
model.add(Dense(1, activation=""sigmoid""))
model.summary()
# compile the model
model.compile(loss='binary_crossentropy', optimizer= opt, metrics=['accuracy'])
Sadly my model has bad performance (acc = 55% more or less and loss = 0.69). Do you have any suggestion to increase my performance? Is there something wrong?Here the model.summary()Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_3 (Conv1D)            (None, 32, 16)            64        
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 16)            64        
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 16, 16)            0         
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 14, 32)            1568      
_________________________________________________________________
max_pooling1d_4 (MaxPooling1 (None, 7, 32)             0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 224)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 512)               115200    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 513       
=================================================================
",,"Discussion,"
17,https://www.reddit.com/r/MachineLearning/comments/e22gmc/discussion_wont_max_pooling_mess_up_a_lot_of/,e22gmc,discussion_wont_max_pooling_mess_up_a_lot_of,avdalim,0.67,1,2019-11-26 19:51:45,0,3,"Tech,","As far as I understood it, Max Pooling takes the maximum positive value and not absolute values.In this paper, optimized mechanical structures get generated with a U-Net by feeding it mechanical information like nodal displacement, element strains, and volume fractions.https://arxiv.org/ftp/arxiv/papers/1901/1901.07761.pdfMy question now is: won't Max Pooling mess up a lot of information, if it just takes the positive value and not the absolute value? Since positive elements in the strain matrix correspond to tensile strains and negative to compressive ones.",,"Discussion,"
18,https://www.reddit.com/r/MachineLearning/comments/e1tsd7/p_i_reimplemented_hyperband_check_it_out/,e1tsd7,p_i_reimplemented_hyperband_check_it_out,Deepblue129,0.86,9,2019-11-26 07:07:12,0,4,"Tech,","Hyperband is a state-of-the-art algorithm for hyperparameter tunning that focuses on resource efficiency. It does so by encorperating early-stopping into it's strategy. Here are some of the results:For more, go here: http://www.argmin.net/2016/06/23/hyperband/ I was unable to find any great implementations of hyperband, so I implemented it! Here it is: https://gist.github.com/PetrochukM/2c5fae9daf0529ed589018c6353c9f7bThe implementation is commented and documented to help ensure correctness and improve code readability.I believe I improve hyperband by allowing support for model checkpoints. The original hyperband assumed that each model was trained from scratch instead of checkpointing. We don't need to train the same model with the same hyperparameters over and over again!Finally, I also explored other improvements to hyperband like splitting based on the largest performance gap instead of splitting in half the search space every time.",,"Project,"
19,https://www.reddit.com/r/MachineLearning/comments/e1ojfo/r_understanding_the_generalization_of_lottery/,e1ojfo,r_understanding_the_generalization_of_lottery,arimorcos,0.89,19,2019-11-26 00:06:29,0,4,"Tech,","Sharing our recent blog post summarizing some of our recent work understanding the boundaries of the lottery ticket hypothesis. In particular, we make some progress towards the following questions:Do winning ticket initializations contain generic inductive biases or are they overfit to the particular dataset and optimizer used to generate them?Is the lottery ticket phenomenon limited to supervised image classification, or is it also present in other domains like RL and NLP?Can we begin to explain lottery tickets theoretically?The blog post is below:Understanding the generalization of ""lottery tickets"" in neural networksAnd the papers covered can be found here:One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizersPlaying the lottery with rewards and multiple languages: lottery tickets in RL and NLPLuck Matters: Understanding Training Dynamics of Deep ReLU NetworksStudent Specialization in Deep ReLU Networks With Finite Width and Input Dimension",,"Research,"
20,https://www.reddit.com/r/MachineLearning/comments/e1pgd0/r_adversarial_examples_improve_image_recognition/,e1pgd0,r_adversarial_examples_improve_image_recognition,hardmaru,0.86,14,2019-11-26 01:11:03,0,3,"Tech,",,https://arxiv.org/abs/1911.09665,"Research,"
21,https://www.reddit.com/r/MachineLearning/comments/e1k81s/d_artificial_life_for_ai_people/,e1k81s,d_artificial_life_for_ai_people,weiqiplayer,0.89,21,2019-11-25 19:25:20,0,8,"Tech,","AI asks fundamental questions about the nature of “intelligence”, but what about understanding life itself? Sina gives an overview of Artificial Life for AI people.https://thegradient.pub/an-introduction-to-artificial-life-for-people-who-like-ai/",,"Discussion,"
22,https://www.reddit.com/r/MachineLearning/comments/e1dpn9/r_deepfovea_neural_reconstruction_for_foveated/,e1dpn9,r_deepfovea_neural_reconstruction_for_foveated,hardmaru,0.96,103,2019-11-25 10:34:08,0,4,"Tech,","I thought this project from FB Research is a really cool work:AbstractIn order to provide an immersive visual experience, modern displays require head mounting, high image resolution, low latency, as well as high refresh rate. This poses a challenging computational problem. On the other hand, the human visual system can consume only a tiny fraction of this video stream due to the drastic acuity loss in the peripheral vision. Foveated rendering and compression can save computations by reducing the image quality in the peripheral vision. However, this can cause noticeable artifacts in the periphery, or, if done conservatively, would provide only modest savings. In this work, we explore a novel foveated reconstruction method that employs the recent advances in generative adversarial neural networks. We reconstruct a plausible peripheral video from a small fraction of pixels provided every frame. The reconstruction is done by finding the closest matching video to this sparse input stream of pixels on the learned manifold of natural videos. Our method is more efficient than the state-of-the-art foveated rendering, while providing the visual experience with no noticeable quality degradation. We conducted a user study to validate our reconstruction method and compare it against existing foveated rendering and video compression techniques. Our method is fast enough to drive gaze-contingent head-mounted displays in real time on modern hardware. We plan to publish the trained network to establish a new quality bar for foveated rendering and compression as well as encourage follow-up research.Project page / paper / video / code: https://research.fb.com/publications/deepfovea-neural-reconstruction-for-foveated-rendering-and-video-compression-using-learned-statistics-of-natural-videos/",,"Research,"
23,https://www.reddit.com/r/MachineLearning/comments/e1ehz1/191109723_fast_sparse_convnets/,e1ehz1,191109723_fast_sparse_convnets,ekelsen,0.94,54,2019-11-25 11:59:30,0,8,"Tech,",,https://arxiv.org/abs/1911.09723,
24,https://www.reddit.com/r/MachineLearning/comments/e1kfy2/r_191106786_stagewise_knowledge_distillation/,e1kfy2,r_191106786_stagewise_knowledge_distillation,akshayk07,0.86,5,2019-11-25 19:39:53,0,5,"Tech,",,https://arxiv.org/abs/1911.06786,"Research,"
25,https://www.reddit.com/r/MachineLearning/comments/e1rpzq/d_where_are_the_good_machine_learning_books_for/,e1rpzq,d_where_are_the_good_machine_learning_books_for,Ctown_struggles00,0.5,0,2019-11-26 04:04:18,0,4,"Tech,","For beginners there's PRML by Bishop and maybe Understanding Machine Learning by Shai2 but for advanced readers or those interested in the deep learning and GAN research landscape (and how to apply it) there really isn't anything good out there.I personally don't like Goodfellow's Deep Learning book. I wish there was a good deep-dive out there but there just isn't what I need.I think Andrej Karpathy is a good writer, kind of wish he could throw something together!",,"Discussion,"
26,https://www.reddit.com/r/MachineLearning/comments/e191z6/p_nboost_boost_elasticsearch_search_relevance_by/,e191z6,p_nboost_boost_elasticsearch_search_relevance_by,colethienes,0.94,79,2019-11-25 03:12:54,0,9,"Tech,","Hi Everyone!New to reddit, but I'd like to share a project I've been working on called NBoost. It's essentially a proxy for search APIs (e.g. Elasticsearch) that reranks search results using finetuned models (e.g. BERT).Check out our medium article or github to learn more!It's main features include:Super easy to set up (you can just pip install nboost)Easy, non-invasive integration with Elasticsearch and potentially other search APIs.Finetuned models are plugins (you can swap them in and out).Fast and scaleable (written at the lowest level possible)",,"Project,"
27,https://www.reddit.com/r/MachineLearning/comments/e1gssh/d_how_do_you_expect_ml_to_transition_over_to/,e1gssh,d_how_do_you_expect_ml_to_transition_over_to,nocomment_95,0.91,10,2019-11-25 15:31:25,0,38,"Tech,","First off I am not an ML engineer. I am am embedded software engineer working mostly in safety critical systems. So if there are some dumb assumptions here don't crucify me. One of the biggest things that strikes me about ML is it's black box nature. We can't ask the machine how it made a descision, in fact I've heard claims that we shouldn't because it would inject human bias into the system. For things like data scraping and image recognition that seems fine, but I can't imagine having a conversation at my work go like this:""X failed, people died. Go figure out how and fix it.Sorry boss I can retrain the model with this new outcome but I can't tell you why it broke or guarantee to any degree of certainty it won't happen again""That just wouldn't fly. Is there something I'm missing?",,"Discussion,"
28,https://www.reddit.com/r/MachineLearning/comments/e1d447/d_imagenet_classification_training_fullresolution/,e1d447,d_imagenet_classification_training_fullresolution,tsauri,0.83,20,2019-11-25 09:26:45,0,14,"Tech,","Are there papers that do so? ImageNet images have various resolutions. Since we already have adaptive pooling techniques such as global average pooling, attention-based pooling, etc. that support variable resolution, should it be possible?Random fixed size crop and resize seems hacky.",,"Discussion,"
29,https://www.reddit.com/r/MachineLearning/comments/e10b5x/d_what_happened_to_the_thread_on_taiwan_and_iccv/,e10b5x,d_what_happened_to_the_thread_on_taiwan_and_iccv,arkady_red,0.95,401,2019-11-24 17:04:43,0,186,"Tech,","As per subject, wasn't there a thread on that yesterday? I can't find it anymore. Was it mowed down by moderators?",,"Discussion,"
30,https://www.reddit.com/r/MachineLearning/comments/e1k8cc/d_datapoisoning_and_trojan_attacks_at_training/,e1k8cc,d_datapoisoning_and_trojan_attacks_at_training,niklongstone,1.0,3,2019-11-25 19:25:50,0,1,"Tech,",I would like to know anyone's opinion on this.Recent work has identified that classification models implemented as neural networks are vulnerable to data-poisoning and Trojan attacks at training time.Source: Attacks on Deep Reinforcement Learning Agents : https://arxiv.org/abs/1903.06638Is it a real threat?How the risk can be identified from someone that just uses the model without access to its source or training data (i.e. prepare a set of tests)?,,"Discussion,"
31,https://www.reddit.com/r/MachineLearning/comments/e1jzkz/discussiond_gradient_norm_tracking/,e1jzkz,discussiond_gradient_norm_tracking,pubertat,1.0,2,2019-11-25 19:10:16,0,3,"Tech,","Are there any best practices on how one should track gradient norms during training? Surprisingly, I haven't been able to find much reliable information on it, except the classical Glorot's paper.My current approach is to track 2-norm of weights raw gradients. However, I don't have any practical intuition on which values should make me worried. Tracking the actual weight updates (e.g adjusted by Adam) makes make much more sense, but I haven't seen anyone doing so.A few words why am I concerned: I'm working on some exotic NN architecture for 3D, where different architecture choices implicate gradient behavior drastically, up to blow up.",,"Discussion,"
32,https://www.reddit.com/r/MachineLearning/comments/e1dxvl/d_image_synthesis_before_gans/,e1dxvl,d_image_synthesis_before_gans,WoahCanyonero,0.77,9,2019-11-25 10:59:31,0,16,"Tech,","I'm writing my master's thesis on image generation and was wondering: which other methods were/are used to synthesize images, aside from GANs? Any time I look up ""image synthesis"" I only find GAN tutorials, and excluding GANs seems to bring up photon scanning.",,"Discussion,"
33,https://www.reddit.com/r/MachineLearning/comments/e1elhy/d_use_ai_to_turn_low_poly_world_into/,e1elhy,d_use_ai_to_turn_low_poly_world_into,AlexaPomata,0.63,5,2019-11-25 12:09:41,0,25,"Tech,","Hi,I wonder why we are still trying to mimic photorealistic world by counting every reflection, polygon, tracing every ray and so on. Shouldn't it be done in such manner that AI is just doing the job basing on photos and low polygon input like here https://assetstore.unity.com/packages/3d/characters/animals/poly-art-forest-set-128568 Also all other games like Zelda BOTW, Team Fortress 2 or even Fortnite could be easily turned by AI into photorealistic env. Shouldn't we start thinking about doing AI accelerators (like first 3dfx cards) for enriching low polygonic world's generated easily by most commodity hardware? I guess even ray tracing could be made by ML. I believed that future belongs to generating world by AI not by tricky mathematic graphics algorithms. Especially that in future it is easier to go from such trained networks into environment where instead of heaving an output on display, the output would be ""drawn"" directly in human brain through neural-connectivity. Also AI is able to properly handle cases where object is moving fast or turning around.Cheers, Alexa",,"Discussion,"
34,https://www.reddit.com/r/MachineLearning/comments/e1jyyd/d_deep_machine_learning/,e1jyyd,d_deep_machine_learning,Rioghasarig,0.4,0,2019-11-25 19:09:09,0,5,"Tech,","So, I'm a big fan of Lex Fridman's deep learning podcast. A big ago I watched one he did with Ian Goodfellow.At the start of the interview Goodfellow describes how deep learning methods are distinguished by the fact that it involves a bunch of computations done in sequence rather than in parallel. (You can watch the video to get a better idea of what he was talking about).Does anyone have any other examples of machine learning techniques that you feel fit his description of being deep? Just curious about this.",,"Discussion,"
35,https://www.reddit.com/r/MachineLearning/comments/e1jxin/p_webpage_data_extraction_using_image/,e1jxin,p_webpage_data_extraction_using_image,JsonPun,0.67,1,2019-11-25 19:06:47,0,3,"Tech,","I am working on creating something that can detect and ideally extract information from a job posting.I have some questions around the data I am using. I currently crawl websites and take screenshots of their career pages. These screenshots vary in dimensions due to the length of the website.Disclaimer, I am not a ML Pro. I am self taught everything and currently using Google's AutoML Services for training my model.My Questions:Should I use these long/large images? Or is it better to cut them in half and then feed it to the AI. With the large images when I zoom in I can see everything fine for labeling. When not zoomed in, it can be hard to make things out.How small should labels be? Google allows the smallest to be 8 pixels by 8 pixels. If they can be big I can use the large images and just zoom in?Is there a way to give context to the classifier/object detector? I realized when I evaluate a job posting I get context from the url and other words on the page that it doesn't get since it only sees a screenshot.Should I try to label every element on the page? if yes, In a high level way or granular?Any other hints or tips I should think about to solve this problem?My Attempts/ApproachesAttempt 1: Object DetectionMy first attempt was to perform object detection on screen shots that were cut down to ~2,000 pixels. I then labeled most of the content on the page with labels like: Header, Footer, Section, Heading, SubHeading, Job Title, Job Posting, Paragraph, Section Heading, Section SubHeading.Results :Total images: 183Test items: 17Total objects: 244Object to image avg: 14.35Precision: 91.43% (Using a score threshold of 0.508)Recall: 13.11% (Using a score threshold of 0.508)Average precision: 0.171 at 0.5 IoUConclusion: Object detection needs many more images, also the labels I provided were not concrete enough. Looking back I found the definitions for certain things to be vague. For example I was using the label heading, subheading and job title. Well sometimes the heading is also a job title, but I would only mark it as job title. Thinking about it from the computers perspective how will it know a heading from a job title? There is not much there visually for it to grab onto. This lead me to cut the images down to a height of 2,000 pixels so I could see each element more clearly.The problem here is do I try to label every HTML element?Attempt 2 Object ClassificationMy second try was to use image classification to determine if I was on a job posting page, then if true use another model to extract the data.My first model1 resultsTotal images: 85Test items: 9Precision: 77.78%Recall: 77.78%My second model2 resultsTotal images: 484**Test items:**55Precision: 90.7%Recall: 70.91%These results were more in-line with what I had thought. When looking at the overall page there over and over there becomes a familiar pattern with what a job posting looks like.Final Attempt - Object Detection:I am now trying again with an object detection model, that is trained only on job posting's, I think this will do better as it only has 3 labels, Job Title, Job Location and Apply Button. I wanted to include a label for: Responsibilities, Qualifications, skills, bonus, ect... but came back to the fact that there is not much for it to grab onto...as I find these in the posting by reading.Model currently in training...Final NotesI believe the correct way for me to do this problem would be to train the AI on the html code, but I am using google's automl services so I dont know how/if that is possible. I was thinking about using/combining different types of data/techniques since there is information in the URL and code that I'm not leveraging. Perhaps apply NLP to the URLS?Thanks for checking out my project any thoughts are appreciated.",,"Project,"
36,https://www.reddit.com/r/MachineLearning/comments/e13qhb/r_a_simple_module_consistently_outperforms/,e13qhb,r_a_simple_module_consistently_outperforms,stopwind,0.87,56,2019-11-24 21:02:39,0,46,"Tech,","In the paper: MUSE: Parallel Multi-Scale Attention for Sequence to Sequence LearningWe delve into three questions in sequence to sequence learning:Is attention alone good enough？Is parallel  representation learning applicable to sequence data and tasks?How to design a module that combines both inductive bias of convolution and  self-attention？We find that there are shortcomings in stand-alone self-attention, and present a new module that maps the input to the hidden space and performs the three operations of self-attention, convolution and nonlinearity in parallel, simply stacking this module outperforms all previous models including Transformer (Vasvani et al., 2017) on main NMT tasks under standard setting.Key features:First successfully combine convolution and self-attention in one module for  sequence tasks by the proposed shared projection,SOTA on three  main translation datasets, including WMT14 En-Fr, WMT14 En-De and IWSLT14  De-En,Parallel  learn sequence representations and thus have potential for acceleration.Quick links:Arxiv : pdf;Github : Code, pretrained models, instructions for training are all available.Main results:Abstract:In sequence to sequence learning, the self-attention mechanism proves to be highly effective, and achieves significant improvements in many tasks. However, the self-attention mechanism is not without its own flaws. Although self-attention can model extremely long dependencies, the attention in deep layers tends to overconcentrate on a single token, leading to insufficient use of local information and difficultly in representing long sequences. In this work, we explore parallel multi-scale representation learning on sequence data, striving to capture both long-range and short-range language structures. To this end, we propose the Parallel MUlti-Scale attEntion (MUSE) and MUSE-simple. MUSE-simple contains the basic idea of parallel multi-scale sequence representation learning, and it encodes the sequence in parallel, in terms of different scales with the help from self-attention, and pointwise transformation. MUSE builds on MUSE-simple and explores combining convolution and self-attention for learning sequence representations from more different scales. We focus on machine translation and the proposed approach achieves substantial performance improvements over Transformer, especially on long sequences. More importantly, we find that although conceptually simple, its success in practice requires intricate considerations, and the multi-scale attention must build on unified semantic space. Under common setting, the proposed model achieves substantial performance and outperforms all previous models on three main machine translation tasks. In addition, MUSE has potential for accelerating inference due to its parallelism.",,"Research,"
37,https://www.reddit.com/r/MachineLearning/comments/e0yvok/p_hypertunity_a_library_for_hyperparameter/,e0yvok,p_hypertunity_a_library_for_hyperparameter,gdikov,0.98,119,2019-11-24 15:04:10,0,22,"Tech,","I would like to share my pet project, Hypertunity, a Python library for black-box hyperparameter optimisation. It's main features are:Bayesian Optimisation using Gaussian process regression by wrapping GPyOpt;Native support for random and grid search;Visualisation of the results in Tensorboard using the HParams plugin;Scheduled, parallel execution of experiments using joblib;Also possible to schedule jobs on Slurm.For the full set of features, check out the docs.Your feedback is very much appreciated!",,"Project,"
38,https://www.reddit.com/r/MachineLearning/comments/e11t34/p_pysnn_spiking_neural_network_framework_built_on/,e11t34,p_pysnn_spiking_neural_network_framework_built_on,DontShowYourBack,0.91,47,2019-11-24 18:52:06,0,15,"Tech,","Hi everyone!Recently a friend and I have been working on a new Python library for machine learning with Spiking Neural Networks (SNNs), called PySNN, which is built on top of PyTorch. We feel it is time to share it with more people, and hopefully get good feedback and contributions:)!Our goal for  PySNN was to make a truly modular framework for machine learning with SNNs, while staying as close to PyTorch as possible. All of the existing frameworks either operate more like simulators for neuroscientific research, or use relatively fixed network and training/evaluation loop designs. PySNN, on the other hand, consists of building blocks for neurons, connections, and learning rules which the user can combine in their desired way. It even allows for mixing learning rules or training only specific parts of the network.Furthermore, since PySNN consists of just the basic elements, the framework is lightweight and allows for easy extension. Because of its tight integration with PyTorch it fully supports GPU acceleration, batching of samples, and supports tools like the jit compiler and graph tracing for TensorBoard.There are still many improvements and extensions that can be made, so feel free to have a look and send out a pull request! We will be very active in helping with any issues! https://github.com/BasBuller/PySNNWe are looking forward to your comments and suggestions!:)",,"Project,"
39,https://www.reddit.com/r/MachineLearning/comments/e1fp0d/p_how_can_i_build_this_simple_textbased_ml_tool/,e1fp0d,p_how_can_i_build_this_simple_textbased_ml_tool,ventura__highway,0.5,0,2019-11-25 13:56:38,0,4,"Tech,","Hello everyone!I work with spreadsheets a lot, doing tasks manually that are just a bit too complex for rules, but I believe they certainly fall into what ML can handle. In a nutshell, I spend 2+ hours a day going through company names, removing legal terms like ""LLC"" or ""Limited"", and humanizing them.For instance, I have a spreadsheet with company names and emails.Company NameEmail AddressConcur Recruitment Limited - 02476 668 204sconvery@concurengineering.co.ukConfluent Technology Groupmark.anderson@confluentgroup.comConstruction Maintenance and Allied Workersdonmelanson@cmaw.caThese would become (currently by hand):Company NameEmail AddressConcur Engineeringsconvery@concurengineering.co.ukConfluentmark.anderson@confluentgroup.comCMAWdonmelanson@cmaw.caWhat we're doing here is:Shorting names to their essenceRemoving legal terms and wordsLooking at domain names (in email addresses) as a clue for the ""most human name""Now, I very well believe this is something Google Cloud has capabilities for. Given the lack of programming involved with Google Cloud ML (and its potential integration with Google Sheets), I'd imagine it's the best vehicle for this tool.Some questions before I embark upon this journey:Would your recommend I use Google Cloud ML or another tool?How much data would you imagine would be necessary to train this tool? (uncleaned spreadsheets and cleaned spreadsheets)Am I critically misunderstanding something here? This is pretty much my first time practically applying ML.Thank you very much for all your help!",,"Project,"
40,https://www.reddit.com/r/MachineLearning/comments/e12eel/d_what_do_you_see_as_the_most_promising/,e12eel,d_what_do_you_see_as_the_most_promising,p6m_lattice,0.86,15,2019-11-24 19:33:40,0,19,"Tech,","I often read from ML researchers, but more from computational cognitive scientists, that humans are able to generalize patterns from only a few data points or use ""rich, informative priors"" even as children, and how that is very important for us as cognitive beings that sets us apart from the current neural network approaches to RL used today.I'm also not entirely convinced that the current neural net paradigm with the McCulloch–Pitts-esque neurons is ever going to become sample efficient enough for real-world reinforcement learning tasks. It seems like despite our best efforts to increase sample efficiency in NN techniques, the most impressive results still use hundreds of thousands or more simulations/data points that could be infeasible to implement for any sufficiently complex real-world environments.That being said, what approaches are you most excited for in reducing sample efficiency in reinforcement learning or in neural network techniques in general?",,"Discussion,"
41,https://www.reddit.com/r/MachineLearning/comments/e149u6/d_anybody_know_an_implementation_of_fchollets/,e149u6,d_anybody_know_an_implementation_of_fchollets,daanvdn,0.86,10,2019-11-24 21:39:33,0,2,"Tech,",This is the paper: Information-theoretical label embeddings for large-scale image classificationhttps://arxiv.org/abs/1607.05691,,"Discussion,"
42,https://www.reddit.com/r/MachineLearning/comments/e0up0p/r_reimplementation_of_hyperspherical_prototype/,e0up0p,r_reimplementation_of_hyperspherical_prototype,ACTBRUH,0.93,60,2019-11-24 07:02:08,0,5,"Tech,","Link to paper: https://arxiv.org/abs/1901.10514Link to my reimplementation: https://github.com/Abhishaike/HyperProtoNetReproduceThis is a Pytorch reimplementation of the NeurIPS 2019 paper ‘Hyperspherical Prototype Networks’ in Pytorch. This paper proposes an extension to Prototype Networks, in which the prototypes are placed a priori with large margin separation, and remain unchanged during the training/testing process of the model. The paper suggests that this extension allows for more flexible classification, regression, and joint multi-task training of regression/classification, and with higher accuracy compared to typical Prototype Networks.This repo includes reproduced benchmarks for most of their datasets. Largely the same accuracy/error, but quite off on CIFAR-100 (not ImageNet-200 though for some reason), so it's possible this is an issue on my end.I also found their use of SGD for prototype creation to be unusual, considering that, the way they phrased the prototype problem, it seems like a job more for a constrained optimization algorithm. Alongside the SGD implementation (which are used for the included benchmarks), I added in two other optimization algorithms, one unconstrained (BFGS) and one constrained (SLSQP). These didn't seem to change the results much.This is my first reimplementation of a paper, so any critiques would be great!",,"Research,"
43,https://www.reddit.com/r/MachineLearning/comments/e0z7xs/discussion_hyperparameters_for_word2vec_for_sms/,e0z7xs,discussion_hyperparameters_for_word2vec_for_sms,conradws,0.78,8,2019-11-24 15:34:27,0,12,"Tech,","Hey all,Working at a small startup, and we have extracted 33 million text messages from our users. We plan to create a model to classify different types of sms relevant to us.First step is to create a Word 2 Vector dictionary for EDA and clustering and possibly to use these embeddings for classification further down the line .Just wanted some guidance about the hyperparameters for the gensim's Word2Vec.The corpus is 33 million sms, average sms length is 16 words and the vocab size is 1.5 million.I used the following hyperparameters and obtained decent results but just wanted to know if I'm doing anything wrong that could be hampering the model from performing even better:Cbow, window = 4, vector size = 125,  iterations =10, workers = 5, min_count= 4.Furthermore does anyone have any tips on how to evaluate the embeddings ( other than checking that the similarity for a small set of words makes sense) so that I can fine-tune these hyperparameters?And final question ( I promise) Would it possible or recomendable to take a pre trained Word2Vec model and improve on it by giving it the sms data so that it learns new words like slang and typos without losing its overall knowledge of the language?Thanks so much for your time in reading.",,"Discussion,"
44,https://www.reddit.com/r/MachineLearning/comments/e0vbhq/d_aistats_2020_reviews/,e0vbhq,d_aistats_2020_reviews,donb1988,0.83,23,2019-11-24 08:12:56,0,11,"Tech,","AISTATS 2020 reviews are marked for release on Nov 24, 2019. Here's a thread to discuss this year's reviews. Godspeed, everyone!",,"Discussion,"
45,https://www.reddit.com/r/MachineLearning/comments/e0j9cb/p_2000x_faster_rapids_tsne_3_hours_down_to_5/,e0j9cb,p_2000x_faster_rapids_tsne_3_hours_down_to_5,danielhanchen,0.73,189,2019-11-23 16:27:45,0,28,"Tech,","TSNE is a very popular data visualization algorithm used alongside PCA and UMAP.Sklearn's TSNE is very effective for small datasets, but on the 60,000 MNIST Digits dataset, expect to wait 1 hour. With RAPIDS cuML, TSNE on MNIST runs in 3 seconds!On 200,000 rows, Sklearn takes a whopping 3 hours, whilst RAPIDS takes 5 seconds! (2,000x faster). Figure 1. cuML TSNE on MNIST Fashion takes 3 seconds. Scikit-Learn takes 1 hour. Check out my blog showcasing how cuML achieves this massive performance boost, and how NVIDIA GPUs can help scientists and engineers save their precious time. https://medium.com/rapids-ai/tsne-with-gpus-hours-to-seconds-9d9c17c941db Figure 2. TSNE used on the 60,000 Fashion MNIST dataset (3 seconds)Give cuML a try! You might know me as the author of HyperLearn, and I can say cuML is the gold standard package for machine learning on GPUs! https://github.com/rapidsai/cumlLinear Regression, UMAP, K-Means, DBSCAN etc are all sped up on the GPU! If you have any questions, feel free to ask! Table 1. cuML’s TSNE time running on an NVIDIA DGX-1 with using 1 V100 GPU. Finally, a big drawback of current GPU implementations is its memory consumption. With cuML TSNE, it uses 30% less GPU memory! In a future release, this will be shaved by 33% again to a total of 50% memory reductions! It will also support PCA initialization.Note: My aim is to showcase how GPUs fair against the common use case. Many scientists and engineers use Sklearn's TSNE, so Sklearn is compared against.",,"Project,"
46,https://www.reddit.com/r/MachineLearning/comments/e0q6y7/d_nonstudents_whats_your_day_job/,e0q6y7,d_nonstudents_whats_your_day_job,Ctown_struggles00,0.91,19,2019-11-24 00:36:42,0,66,"Tech,",What kind of work do you guys do?,,"Discussion,"
47,https://www.reddit.com/r/MachineLearning/comments/e10e40/p_a_chessgoshogi_model_that_passes_the_turing/,e10e40,p_a_chessgoshogi_model_that_passes_the_turing,Pawngrubber,0.42,0,2019-11-24 17:11:01,0,17,"Tech,","I want to build a model for Chess/Go/Shogi that is trained and tested on real players, and I want it to pass the Turing test.  I don't want my model to play the best move in a position, I want it to play the move that a person would play (of a certain strength, time control, etc..).It's easy to make this a classification problem and train a CNN on a one-hot encoded policy of actual moves played.  The only problem is, without some kind of look-ahead algorithm (MCTS for example) the model fails to learn sequences that require multiple moves, such as tactics.However, current MCTS/alpha-beta/minimax models require evaluation of leaf nodes.  I don't have a way to shape the reward to an evaluation of a leaf node.  So my question: how would I incorporate a look-ahead algorithm in an imitation learning problem like this?",,"Project,"
48,https://www.reddit.com/r/MachineLearning/comments/e0x56q/need_some_advice_for_training_bert_to_classify/,e0x56q,need_some_advice_for_training_bert_to_classify,shstan,0.57,1,2019-11-24 11:59:27,0,9,"Tech,","Basically, so far, I have been trying to train BERT on a very long document by cutting start, middle , and end sections of article so it could be fit into the limited input dimension of 512. However; the performance has been dismal for most of the time. So far, I am not sure if using LSTM+GRU was a better approach than this. But are there other ways to train it than just cutting up the article? When I googled for an alternative approach, I couldn’t find much...",,"Project,"
49,https://www.reddit.com/r/MachineLearning/comments/e0ijkd/d_generating_visualizations_for_network/,e0ijkd,d_generating_visualizations_for_network,ssd123456789,0.92,39,2019-11-23 15:29:33,0,16,"Tech,",Deep learning papers often have very good diagrams of their architectures. Does anyone know of tools that can be used to generate these sorts of diagrams. I'm not looking for automatically generated diagrams.So my question is this:What kind of software do people use to make nice looking Visualizations for their network architecture. A really nice example is the pointnet architecture. So does anyone know what was or could have been used to generate that architecture diagram.,,"Discussion,"
50,https://www.reddit.com/r/MachineLearning/comments/e0s430/r_190800156_deep_gaussian_networks_for_function/,e0s430,r_190800156_deep_gaussian_networks_for_function,AforAnonymous,0.6,3,2019-11-24 03:08:45,0,2,"Tech,",,https://arxiv.org/abs/1908.00156,"Research,"
51,https://www.reddit.com/r/MachineLearning/comments/e10e1h/discussion_the_wolf_of_silicon_valley_data/,e10e1h,discussion_the_wolf_of_silicon_valley_data,stensool,0.36,0,2019-11-24 17:10:50,0,2,"Tech,",A satirical piece I wrote on the parallels between machine learning engineers and Wall Street traders:https://towardsdatascience.com/the-wolf-of-silicon-valley-150e5f501216,,"Discussion,"
52,https://www.reddit.com/r/MachineLearning/comments/e03azf/n_china_forced_the_organizers_of_the/,e03azf,n_china_forced_the_organizers_of_the,Only_Assist,0.94,825,2019-11-22 17:28:14,0,224,"Tech,","Link: http://www.taipeitimes.com/News/front/archives/2019/11/02/2003725093The Ministry of Foreign Affairs yesterday protested after China forced the organizers of the International Conference on Computer Vision (ICCV) in South Korea to change Taiwan’s status from a “nation” to a “region” in a set of slides.At the opening of the conference, which took place at the COEX Convention and Exhibition Center in Seoul from Tuesday to yesterday, the organizers released a set of introductory slides containing graphics showing the numbers of publications or attendees per nation, including Taiwan.However, the titles on the slides were later changed to “per country/region,” because of a complaint filed by a Chinese participant.“Taiwan is wrongly listed as a country. I think this may be because the person making this chart is not familiar with the history of Taiwan,” the Chinese participant wrote in a letter titled “A mistake at the opening ceremony of ICCV 2019,” which was published on Chinese social media under the name Cen Feng (岑峰), who is a cofounder of leiphone.com.The ministry yesterday said that China’s behavior was contemptible and it would not change the fact that Taiwan does not belong to China.Beijing using political pressure to intervene in an academic event shows its dictatorial nature and that to China, politics outweigh everything else, ministry spokeswoman Joanne Ou (歐江安) said in a statement.The ministry has instructed its New York office to express its concern to the headquarters of the Institute of Electrical and Electronics Engineers, which cosponsored the conference, asking it not to cave in to Chinese pressure and improperly list Taiwan as part of China’s territory, she said.Beijing has to forcefully tout its “one China” principle in the global community because it is already generally accepted that Taiwan is not part of China, she added.As China attempts to force other nations to accept its “one China” principle and sabotage academic freedom, Taiwan hopes that nations that share its freedoms and democratic values can work together to curb Beijing’s aggression, she added.",,"News,"
53,https://www.reddit.com/r/MachineLearning/comments/e0pir2/dwhy_isnt_chainer_more_useddiscussed/,e0pir2,dwhy_isnt_chainer_more_useddiscussed,TheAlgorithmist99,0.64,5,2019-11-23 23:47:20,0,9,"Tech,","Pretty much what it says in the title, but to elaborate on the two questions:Why isn't Chainer more used? It seems to have pioneered some nice ideas like model subclassing, has many interesting ""sub-libraries"", like ChainerCV and ChainerRL, but I think it is barely used outside Japan (not exactly sure if they use it a lot either)And then in the same vein, why is it not more discussed when talking about Deep Learning frameworks? We see a lot of comparison between Pytorch and Tensorflow, then maybe some MxNet and new players (Jax, Halide) and non-python frameworks (mostly Julia's), but Chainer almost seems to be ignored in most of these discussions.(Also feel welcome to comment on pretty much the same questions but regarding Cupy vs Numba or similar)",,"Discussion,"
54,https://www.reddit.com/r/MachineLearning/comments/e0jepq/p_predict_figure_skating_world_championship/,e0jepq,p_predict_figure_skating_world_championship,seismatica,0.72,5,2019-11-23 16:39:49,0,0,"Tech,","I'm trying to predict the ranking of figure skaters in the annual world championship by their scores in earlier competition events in the season. The obvious method to do is by average the scores for each skater across past events and rank them by those averages. However, since no two events are the same, the goal for my project is to separate the skater effect, the intrinsic ability of each skater, by the event effect, how an event influence the score of a skater.I've previously posted on Reddit my attempts to do so using simple linear models, which you can read on Medium part 1 of my project. These models will output a latent score for each skater that we can use to rank them.However, another approach to learn the latent scores of skater is to think of factorizing the event-skater matrix of raw scores in the season into a skater-specific matrix and an event-specific matrix of latent scores that multiply together to approximate the raw score. Therefore, this is exactly the same as the [matrix factorization in recommender systems](https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)), but with user=skater, item=event, and rating=raw score.As a result, I used a variant of the famous FunkSVD algorithm to learn the latent scores of skater. In part 2 of my project, I tried finding just a single latent score for each skater, and rank skaters by those scores. Next, in part 3, I learned multiple latent factors for each skater using the same FunkSVD method. Since I'm implementing it from scratch, I try using various implementations of the algorithm: from a naive approach using for loop, to one using numpy broadcasting, and one using matrix multiplication, and benchmark them both in time and space complexity.However, one major problem with multiple factors is that it's hard to know which factor to rank skater with. Thankfully, the ranking metric I use in the project (Kendall's tau) allows me to build a simple logistic regression model to combine these scores to rank the skaters. This can be done with pairwise score differences in each factor as predictors, and the world championship ranking itself as the response. I later learned that this belong to the pairwise learning-to-rank methods often encountered in information system, and you can read my implementation of it in part 4.However, the result at the end of this part was not very encouraging, likely due to the way that I use FunkSVD to train the latent factors. Therefore, I part 5, I modified my FunkSVD implementation to solve this problem, by training the factors in sequence instead of all at once. I then discovered afterward that Mr Funk also originally trained all of his factors in sequence, so I should have read his work more carefully at the start!You can see all the code I used for my project in the Github repo. I'm more than happy to receive any questions or feedback from you guys on my project!",,"Project,"
55,https://www.reddit.com/r/MachineLearning/comments/e0akbb/d_iclr_reviewers_and_making_the_ml_community/,e0akbb,d_iclr_reviewers_and_making_the_ml_community,watercannon123,0.87,35,2019-11-23 01:59:40,0,18,"Tech,","I'm reviewing for ICLR myself, so I know reading the revised papers and carefully reading all the lengthy rebuttals feels like a terrible time-sink, but to everyone else who's also reviewing: please remember that most authors have spent an enormous time and effort in their submissions.I've noticed that many reviews have already been updated after the rebuttal period but it seems that most if not all miss key points that are addressed in the rebuttal or in the revised paper. There's an option to compare revisions which highlights the changes -- please use this feature, as some authors address points in the revision but don't mention it explicitly in the rebuttal (this actually happened for all papers I'm reviewing). I submitted a paper myself and my reviews were shorter than last year, and I also have the feeling that my rebuttal wasn't carefully read by the reviewers who updated their reviews.I also know that many reviewers this year are reviewing for the first time, but please do make an effort to spend some time going over rebuttals and revisions. You're now part of the ML academic community -- try to make it better, we need it especially now that the many of the highest-rated papers have extremely short reviews with low confidence scores, including reviews as short as 20 words.TLDR: we all know there are not enough reviewers and way too many submissions. while reviewing for free can be frustrating, the community depends on us and the job includes being thoughtful and reading rebuttals/revisions carefully",,"Discussion,"
56,https://www.reddit.com/r/MachineLearning/comments/e03m49/p_cleanlab_accelerating_ml_and_deep_learning/,e03m49,p_cleanlab_accelerating_ml_and_deep_learning,cgnorthcutt,0.93,38,2019-11-22 17:50:17,0,8,"Tech,","Hey folks. Today I've officially released the cleanlab Python package, after working out the kinks for three years or so. It's the first standard framework for accelerating ML and deep learning research and software for datasets with label errors. cleanlab has some neat features:If you have model outputs already (predicted probabilities for your dataset), you can find label errors in one line of code. If you don't have model outputs, its two lines of code.If you're a researcher dealing with datasets with label errors, cleanlab will compute the uncertainty estimation statistics for you (noisy channel, latent prior of true labels, joint distribution of noisy and true labels, etc.)Training a model (learning with noisy labels) is 3 lines of code.cleanlab is full of examples -- how to find label errors in ImageNet, MNIST, learning with noisy labels, etc.Full cleanlab announcement and documentation here: [LINK]GitHub: https://github.com/cgnorthcutt/cleanlab/ PyPI: https://pypi.org/project/cleanlab/As an example, here is how you can find label errors in a dataset with PyTorch, TensorFlow, scikit-learn, MXNet, FastText, or other framework in 1 line of code.# Compute psx (n x m matrix of predicted probabilities)# in your favorite framework on your own first, with any classifier.# Be sure to compute psx in an out-of-sample way (e.g. cross-validation)# Label errors are ordered by likelihood of being an error.# First index in the output list is the most likely error.from cleanlab.pruning import get_noise_indicesordered_label_errors = get_noise_indices(s=numpy_array_of_noisy_labels,psx=numpy_array_of_predicted_probabilities,sorted_index_method='normalized_margin', # Orders label errors)cleanlab logo and my cheesy attempt at a slogan.P.S. If you happen to work at Google, cleanlab is incorporated in the internal code base (as of July 2019).P.P.S. I don't work there, so you're on your own if Google's version strays from the open-source version.",,"Project,"
57,https://www.reddit.com/r/MachineLearning/comments/e00qdj/p_windhive_ml_based_coding_assistant_to_boost/,e00qdj,p_windhive_ml_based_coding_assistant_to_boost,crystal_alpine,0.84,57,2019-11-22 14:07:03,0,16,"Tech,","Hi r/MachineLearning, we were tired of constantly having to search Google, StackOverflow, and GitHub for code examples and API documentation when writing code. We built WindHive.ai, a smart coding assistant that provides you contextually relevant code snippets and docs directly from your editor!WindHive does this by using machine-learned code representations/embeddings. We have trained neural networks on hundreds of publicly available code repositories to create embeddings for the task of deciding which snippets of code would be most useful to show you at any given time. Using these embeddings, we are able to index and search through tens of thousands of code snippets and show you exactly what you need.We believe WindHive can help you increase your programming productivity and avoid reinventing the wheel! Please to to windhive.ai to find out more and share your feedback with us!",,"Project,"
58,https://www.reddit.com/r/MachineLearning/comments/e0ju09/d_something_like_leetcode_for_to_learn_mlpython/,e0ju09,d_something_like_leetcode_for_to_learn_mlpython,Knackmanic,0.29,0,2019-11-23 17:10:50,0,7,"Tech,",I'd like to become more proficient in Python and ML. Have you found a method to train yourself?,,"Discussion,"
59,https://www.reddit.com/r/MachineLearning/comments/e09kjp/discussion_understanding_subscale_wavernn_usage/,e09kjp,discussion_understanding_subscale_wavernn_usage,bigbawsboy,1.0,6,2019-11-23 00:45:06,0,0,"Tech,","Related Paper: Efficient Neural Audio SynthesisI have been reading the sections relating to Subscale WaveRNN in where the DeepMind team was able to generate B samples in a single step. They have discussed about conditioning a particular sample using past samples and up to F samples from the previous sub-tensors future context. In their case, they used a masked dilated CNN (this can be found on the last paragraph of 4.1 Subscale Dependency Scheme). Here's the excerpt specifically to this:The Subscale WaveRNN that generates a given sub-tensor is conditioned on the future context of previous sub-tensors using a masked dilated CNN with relus and the mask applied over past connections instead of future ones.My first question is: how could a masked dilated CNN help with this?Next, Nal Kalchbrenner has tweeted this quick demo of the Subscale WaveRNN. This one confuses me a lot when I'm referring back to the original paper.My final question is: does anyone have taken a look at subscaling more closely?Any insights would be appreciated.(Note: This is my first post and I am hoping that I followed the format correctly.)",,"Discussion,"
60,https://www.reddit.com/r/MachineLearning/comments/e04xzg/r_hybrid_composition_with_idleblock_more/,e04xzg,r_hybrid_composition_with_idleblock_more,ZihengJiang,0.92,11,2019-11-22 19:21:17,0,1,"Tech,",,https://arxiv.org/abs/1911.08609,"Research,"
61,https://www.reddit.com/r/MachineLearning/comments/e02grw/r_deep_neuroethology_of_a_virtual_rodent/,e02grw,r_deep_neuroethology_of_a_virtual_rodent,hardmaru,0.91,8,2019-11-22 16:27:29,0,5,"Tech,",,https://arxiv.org/abs/1911.09451,"Research,"
62,https://www.reddit.com/r/MachineLearning/comments/dzwm9r/r_efficientdet_scalable_and_efficient_object/,dzwm9r,r_efficientdet_scalable_and_efficient_object,hardmaru,0.92,46,2019-11-22 06:37:28,0,10,"Tech,",,https://arxiv.org/abs/1911.09070,"Research,"
63,https://www.reddit.com/r/MachineLearning/comments/dzzjzb/d_uncertainty_estimation_in_dl/,dzzjzb,d_uncertainty_estimation_in_dl,Maplernothaxor,0.78,7,2019-11-22 12:09:03,0,5,"Tech,",Any interesting papers pushing the boundaries of creating well calibrated uncertainties with neural networks (with minimal computational expense ideally)?,,"Discussion,"
64,https://www.reddit.com/r/MachineLearning/comments/dzzw5c/d_an_open_source_stack_for_managing_and_deploying/,dzzw5c,d_an_open_source_stack_for_managing_and_deploying,thumbsdrivesmecrazy,0.77,7,2019-11-22 12:46:04,0,1,"Tech,","https://towardsdatascience.com/an-open-source-stack-for-managing-and-deploying-models-c5d3b98160bcIn this tutorial, we’re going to use DVC to create a model capable of analyzing StackOverflow posts, and recognizing which ones are about Python. We are then going to deploy our model as a web API, ready to form the backend of a piece of production software.DVC stores your model weights and training data in a centralized location, allowing collaborators to get started easily, while also tracking changes and ensuring an accurate version history.As a final step in this tutorial, we’re going to integrate DVC with another open source tool—Cortex—that allows us to deploy DVC-generated models as web APIs, ready for production.",,"Discussion,"
65,https://www.reddit.com/r/MachineLearning/comments/dzmssp/d_why_does_hierarchical_bayesian_regression_work/,dzmssp,d_why_does_hierarchical_bayesian_regression_work,paulie007,0.97,172,2019-11-21 18:38:42,0,34,"Tech,","I have a dataset of electrical outages and it is extremely imbalanced, <2% of all of the data are positive classes. I am using weather station data to try to predict the probability of an outage occurring near the weather stations.When I try any other model I have to rebalance the data to get any good results. However I have recently tried hierarchical Bayesian logistic regression and it performs just fine without resampling. In my methodology every individual weather station has a unique intercept and coefficients, but they are each drawn from a parent distribution.What I would like to discuss is why does the hierarchical approach perform so much better on the imbalanced dataset?",,"Discussion,"
66,https://www.reddit.com/r/MachineLearning/comments/e020vo/n_how_to_convert_a_nn_model_from_tensorflow_lite/,e020vo,n_how_to_convert_a_nn_model_from_tensorflow_lite,xmartlabs,0.6,1,2019-11-22 15:54:13,0,1,"Tech,","Hey everyone,We recently put together this blogpost, to show you how to convert a NN model from TensorFlow Lite to CoreMLHope folks find something helpful here!https://blog.xmartlabs.com/2019/11/22/TFlite-to-CoreML/",,"News,"
67,https://www.reddit.com/r/MachineLearning/comments/dzs00o/p_openai_safety_gym/,dzs00o,p_openai_safety_gym,hardmaru,0.86,14,2019-11-22 00:23:31,0,12,"Tech,","From the project page:Safety GymWe’re releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while training. We also provide a standardized method of comparing algorithms and how well they avoid costly mistakes while learning. If deep reinforcement learning is applied to the real world, whether in robotics or internet-based tasks, it will be important to have algorithms that are safe even while learning—like a self-driving car that can learn to avoid accidents without actually having to experience them.https://openai.com/blog/safety-gym/",,"Project,"
68,https://www.reddit.com/r/MachineLearning/comments/dzsssi/d_voice_assistant_better_to_use_a_model_trained/,dzsssi,d_voice_assistant_better_to_use_a_model_trained,elmosworld37,0.82,10,2019-11-22 01:22:58,0,20,"Tech,","I would like to make a deep-learning based voice assistant for an application I have that controls a digital camera. Some example commands are ""auto focus"", ""set zoom to 2"", ""turn off flash"", etc.I see two ways of going about this:Train a model that classifies an audio snippet as containing one of the commands or background noise. This seems easier than option 2 but also less robust, as I would have to retrain the model every time I add a new command. Also not sure how numbers would work (record myself saying every number up to like 100?).Use STT to convert audio to text and do some fuzzy string matching to see if it matches a command. I've downloaded Mozilla's DeepSpeech and it did not seem to work very well, so I'm guessing that creating a good STT model is very difficult.Which of these is a better approach? Or is there some in-between approach that's even better?Edit: no cloud solutions please, I want to keep everything offline.",,"Discussion,"
69,https://www.reddit.com/r/MachineLearning/comments/dzimhf/r_video_analysis_muzero_mastering_atari_go_chess/,dzimhf,r_video_analysis_muzero_mastering_atari_go_chess,ykilcher,0.89,55,2019-11-21 13:29:49,0,11,"Tech,","https://youtu.be/We20YSAJZSEMuZero harnesses the power of AlphaZero, but without relying on an accurate environment model. This opens up planning-based reinforcement learning to entirely new domains, where such environment models aren't available. The difference to previous work is that, instead of learning a model predicting future observations, MuZero predicts the future observations' latent representations, and thus learns to only represent things that matter to the task!Abstract:Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.Authors: Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis, Thore Graepel, Timothy Lillicrap, David Silverhttps://arxiv.org/abs/1911.08265",,"Research,"
70,https://www.reddit.com/r/MachineLearning/comments/dzwrk1/d_ai_to_monitor_network/,dzwrk1,d_ai_to_monitor_network,nvitaly,0.5,0,2019-11-22 06:52:12,0,14,"Tech,","Hello,I have monitoring system watching for bandwidth, connections and connections rates from multiple firewalls, which is stream of counters with interval 5 min.My current system create baseline from data for last 4 weeks and compare current value with baseline. It is ok but it either give me lots of false alerts or too slow to react without additional triggers. Is there anything better available today ? Some system I can feed data in that will learn patterns and identify outages in real time.Open source, but that I can use without getting into machine learning theory too deep just to start using it :)Thank you",,"Discussion,"
71,https://www.reddit.com/r/MachineLearning/comments/dzovrl/d_is_the_python_statsmodels_library_production/,dzovrl,d_is_the_python_statsmodels_library_production,AlexSnakeKing,0.79,5,2019-11-21 20:57:11,0,8,"Tech,","I've had success with sklearn in production, as well as with TF.Is statsmodels something that can run in production? Its documentation doesn't seem up to par but its code base doesn't look bad.",,"Discussion,"
72,https://www.reddit.com/r/MachineLearning/comments/dzakrs/r_191108265_mastering_atari_go_chess_and_shogi_by/,dzakrs,r_191108265_mastering_atari_go_chess_and_shogi_by,ankeshanand,0.98,213,2019-11-21 00:54:00,0,89,"Tech,",,https://arxiv.org/abs/1911.08265,"Research,"
73,https://www.reddit.com/r/MachineLearning/comments/e02lq4/d_what_are_some_interesting_questions_we_can/,e02lq4,d_what_are_some_interesting_questions_we_can,mrsailor23,0.24,0,2019-11-22 16:37:22,0,1,"Tech,","Hi everyone,I have created a simple concept: “Train an AI to answer everyday questions and upload the simulations online”I already created the first project/simulation a couple of months ago, but I’m now looking for the next questions we could answer using AI. I have a few ideas like:“A.I. Learns: Is it better to walk or run in the rain?”“A.I. Learns: How to make a profit from cryptocurrency”etc…..Topics could be serious or lighter and funny sometimes :)So, what are some interesting questions we can answer using AI?I’ll pick up interesting answers for my next project.Thank you.",,"Discussion,"
74,https://www.reddit.com/r/MachineLearning/comments/dzmml5/d_combining_nontext_features_with_text_classifier/,dzmml5,d_combining_nontext_features_with_text_classifier,saint----,0.81,9,2019-11-21 18:26:57,0,5,"Tech,","Hi! So I'm building a classifier which primarily looks at text, but I also want to include other features, which are non-text, and I was wondering what is the best way to do it? I feel like just adding another dimension in the vector which represents the text might cause these features to get 'lost', but maybe that's not true. Is ther there some sort of agreed upon way of including these additional non-text features in? By non-text I mean just information which is not part of the body of the text, like some other meta data.Thanks!",,"Discussion,"
75,https://www.reddit.com/r/MachineLearning/comments/dzhgyg/d_does_efficientnet_really_help_in_real_projects/,dzhgyg,d_does_efficientnet_really_help_in_real_projects,___mlm___,0.91,26,2019-11-21 11:37:20,0,14,"Tech,","There are large amount of papers which show that EfficientNet improves some CV  tasks e.g. EfficientDet: Scalable and Efficient Object Detection.But does it help much in real projects ? Do you guys have any experience with that ?One more thing - ImageNet or COCO datasets are far away from what we have to deal with in real projects. Usually we have only small amount of images/classes, so improvements for COCO/ImageNet != improvements for real projects. What do you think ?",,"Discussion,"
76,https://www.reddit.com/r/datascience/comments/e0xo6f/weekly_entering_transitioning_thread_24_nov_2019/,e0xo6f,weekly_entering_transitioning_thread_24_nov_2019,datascience-bot,0.81,6,2019-11-24 13:00:29,0,65,,"Bleep Bloop. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki. You can also search for past weekly threads.I am a bot created by the r/datascience moderators. I'm open source! You can review my source code on GitHub.",,"Discussion,"
77,https://www.reddit.com/r/datascience/comments/e2en0j/failed_a_job_interview_was_my_approach_wrong/,e2en0j,failed_a_job_interview_was_my_approach_wrong,Falc7,0.9,59,2019-11-27 12:10:15,0,35,,"So I currently work as a data scientist, and I recently failed a data science job interview at a large professional services firm.The feedback from my interview was that I came across very well, but that I failed on the technical test.The technical test was to do a Powerpoint presentation of how I would deduplicate a dataset of 10 million rows which contains information such as name, address ect. There was no limit placed on the type of approach or packages used. My approach was to preprocess the data, split it into chunks, deduplicate a chunk, and then systematically compare the deduplicated chunk with other chunks, and iterate the same process through the remaining chunks.In the feedback from the interview they said the main reason why I failed is that for the within-chunk-deduplication and comparison-with-other-chunks parts of the process I used a pre-built package rather than building one from scratch myself.To me, building one myself is a waste of time, as I would just be recreating something that already exists. But obviously they thought I did the wrong thing.In case something like this comes up again, I would be interested to hear what others think, did I do wrong by using an existing package? Or did they do wrong by expecting candidates to approach the task and not try to time-optimise the approach?",,
78,https://www.reddit.com/r/datascience/comments/e2hkia/is_data_science_the_same_as_data_analyst/,e2hkia,is_data_science_the_same_as_data_analyst,gkarwchan,1.0,0,2019-11-27 16:30:17,0,3,,"I am learning Machine learning now, and the world of machine learning and data science overlap a lot.I am a bit puzzled by what exactly is data science, and is it the same as what we used to call Data Analyst, or Data Engineer.Is it the same as BI (business intelligence)?BI has been for decades now, and it is not new.I know that the new about the data world is the Social Media data, which bring terra bytes of data, and this is why technologies like Spark, and Hadoop are booming now.But beside Spark and Hadoop, is Data Science the same as BI?",,"Discussion,"
79,https://www.reddit.com/r/datascience/comments/e2g8j8/best_practices_processing_xml_data/,e2g8j8,best_practices_processing_xml_data,beegeetee,1.0,4,2019-11-27 14:48:27,0,1,,"For those of you who routinely work on data that either resides in XML files or is processed from XMLs, what does your pipeline look like (e.g. how do you do data validation etc) and what do you think are best practices working on such data?",,
80,https://www.reddit.com/r/datascience/comments/e208vd/150_successful_machine_learning_models_6_lessons/,e208vd,150_successful_machine_learning_models_6_lessons,da_chosen1,0.96,177,2019-11-26 17:24:03,0,15,,,https://www.kdd.org/kdd2019/accepted-papers/view/150-successful-machine-learning-models-6-lessons-learned-at-booking.com,"Discussion,"
81,https://www.reddit.com/r/datascience/comments/e27g21/best_data_science_podcasts/,e27g21,best_data_science_podcasts,TinFoilKufi,0.98,32,2019-11-27 01:20:40,0,15,,So I just saw Linear Digressions mentioned. Anybody have any other favorites?,,
82,https://www.reddit.com/r/datascience/comments/e2g3db/apply_ds_to_real_estate_investing/,e2g3db,apply_ds_to_real_estate_investing,philmtl,1.0,2,2019-11-27 14:36:07,0,6,,"I was contacted for a analyst role for a real estate company. I've built web scrapers and programs calculating cash flow and roi.Just I want to apply machine learning to my scraped data.I'm just wondering some ideas I could offer them?I'm thinking tax rate increase predictions, house price increase by area, demand..I'm really interested in real estate but don't want to be a agent or property manager I want to do analysis but I need to convince them that I can really help their business",,
83,https://www.reddit.com/r/datascience/comments/e2irz9/what_are_some_indicesmeasures_of_a_realworld/,e2irz9,what_are_some_indicesmeasures_of_a_realworld,aurorhapsody,1.0,0,2019-11-27 17:51:18,0,0,,"I'm thinking of starting a mini-project to explore some new skills I've learnt and I want your opinions...With increasingly more data becoming available to us nowadays, it can't be helped that people (governments, organisations, individuals) are creating many such indices to measure something in the real world that really aren't the optimal ways of measurement... Some of them are subjective or, worse still, blatantly inaccurate... Any index that tries to rank cities, for instance, in my opinion is prone to some problems. What other indices come to mind for you?",,"Projects,"
84,https://www.reddit.com/r/datascience/comments/e2080s/taking_a_job_in_a_data_science_discipline_you/,e2080s,taking_a_job_in_a_data_science_discipline_you,fread9999,0.89,43,2019-11-26 17:22:32,0,9,,"I was offered a job doing marketing mix modeling for an advertising company.I have never done marketing mix modeling before.  They said they would have scripts available that they used for other products, but it would be basically building a marketing mix model for a new product from scratch and using the other scripts as inspiration.On a coding proficiency, Im extremely strong in both R and Python.  Most of the datascience jobs that ive had has been more data engineering, big data, and building business rules based models.   I do have  a masters in stats, so im not clueless on the math side, but its been a while.My current job sucks.  It was a bait and switch. the company didnt deliver any of the promises they made about the position when they hired me.So, thoughts on this? i have high motivation to find a new job, but i'd have to do alot of learning on the fly, probably more so then the hiring manager thinks.",,"Job Search,"
85,https://www.reddit.com/r/datascience/comments/e2d2o3/where_can_i_practice_modelling_functions_to_data/,e2d2o3,where_can_i_practice_modelling_functions_to_data,RamboCambo15,0.33,0,2019-11-27 09:23:11,0,2,,"I’ve always been curious on how to model data to a function. What are some resources which can point me in the right direction? (This is a pure interest question - I like math) I know this is a bit of a crude example, but if I had some ambiguous data, how would I potentially find a model which was y = (x2)/(2q(x/3)1/3) to fit that data?",,
86,https://www.reddit.com/r/datascience/comments/e1ox5f/social_media_for_the_ai_industry_and_ai_community/,e1ox5f,social_media_for_the_ai_industry_and_ai_community,dominic0627,0.95,304,2019-11-26 00:32:56,0,29,,"So I this is a project I've been working on for a while now. It's called Wonahub, and it's the worlds first social media for the A.I. industry and A.I. community. My goal behind Wonahub was to utilize the collective aspect of social media, but instead of stopping there I wanted to give people in the A.I. community a place to find other likemined individuals with the goal of building teams to combat major issues that face humanity - particularly Climate Change, Poverty, Education, and Healhcare. Social networks are a great way of allowing users, people, to create community, but why stop there. Why not provide the tools for the community to create the change they want to see in the world? That was my aim with Wonahub, and please take this self promotion with candour. My name is Dominic Thomas Pagan and I am the creator of Wonahub! If you want to sign up I will attach the link, otherwise please disregard: Wonahub",,"Projects,"
87,https://www.reddit.com/r/datascience/comments/e21to8/remote_work_options/,e21to8,remote_work_options,KarlWalters,0.72,3,2019-11-26 19:08:29,0,7,,"My background: Data Science roles for 8 years including stints as a DS TPgM for a large cross functional as platform at a major tech company. Currently a Senior DS at a small-midsized series D company owning everything from retention modeling to forecasting and our A/B/N testing platform. My formal background is a MA in Political Psychology with masters level economics, stats, quant methods courses and came into DS as my strength was breaking down complex business problems into a set of actionable deliverables that incrementally add value and reduce operational costs. The only thing I have not done is manage ICs as management was not really interesting to me. Working towards a Lead/Director level role at my current company.At the same time I don’t like the quality of life in the Bay Area and don’t want to stay there. I need to be closer to the outdoor activities that keep me sane. In considering remote work, however, it seems positions either want:A do it all person more on the CS or DE side to build an end-to-end pipeline. I have built such pipelines and own an Airflow/Docker/AWS pipeline for logging and scoring that feeds into Salesforce and Tableau as well as our biz RDS. So I could do this, but it’s not my forte.An analyst to build dashboards and build simple regression models.Am I completely missing something? I always figured valuable DS work would require a bit more presence and domain integration and knowledge than would be doable as a remote hire, but hoping I don’t have to completely transition careers. For those who do work remote: what do you primarily do/build?",,
88,https://www.reddit.com/r/datascience/comments/e243zf/can_python_do_everything_r_can_do/,e243zf,can_python_do_everything_r_can_do,JackIsNotInTheBox,0.63,2,2019-11-26 21:39:35,0,18,,Most jobs require Python OR R.  So I'm wondering if it's redundent to learn both.,,"Discussion,"
89,https://www.reddit.com/r/datascience/comments/e1zivu/where_are_the_good_machine_learning_books_for/,e1zivu,where_are_the_good_machine_learning_books_for,Ctown_struggles00,0.5,0,2019-11-26 16:34:30,0,2,,"For beginners there's PRML by Bishop and maybe Understanding Machine Learning by Shai2 but for advanced readers or those interested in the deep learning and GAN research landscape (and how to apply it) there really isn't anything good out there.I personally don't like Goodfellow's Deep Learning book. I wish there was a good deep-dive out there but there just isn't what I need.I think Andrej Karpathy is a good writer, kind of wish he could throw something together!",,"Discussion,"
90,https://www.reddit.com/r/datascience/comments/e1qx3v/kaggle_kernels_compilation/,e1qx3v,kaggle_kernels_compilation,_Farb,0.92,10,2019-11-26 03:01:52,0,4,,"Hello everyone,I made a compilation with good Kernels that I found on Kaggle.Before, I was forking a lot to study the kernels and learning from it and got a nice improvement on my skills, but today saved the links on my Evernote and it's here to share with you all.The compilation will be updated every time I find a new interesting Kernel.https://www.evernote.com/l/AbN0dHPJaohG467tMLMumI8bbgKNVJEsex4/",,"Education,"
91,https://www.reddit.com/r/datascience/comments/e1xywc/does_every_data_scientist_write_blogs_and_share/,e1xywc,does_every_data_scientist_write_blogs_and_share,Laurence-Lin,0.5,0,2019-11-26 14:31:08,0,18,,"Hello! I'm a newbie to data science, recently I've seen some online sharing experience of how to become a data scientist. I've found lots of people recommend to write blog online to record their learning process.However, I tried and found it's a bit time consuming for me. I'd wrote hand note, but type a blog online on medium is another issue.Does everyone who want to become a data scientist wrote blogs online?",,"Discussion,"
92,https://www.reddit.com/r/datascience/comments/e1gk1j/looking_into_elections_results_anomaly/,e1gk1j,looking_into_elections_results_anomaly,i_not_give_shit,0.87,61,2019-11-25 15:11:12,0,16,,"Hello. I've been looking into last elections results in my country. And I noticed, that percentage for a candidate does not correlate with a voter turnout on the the polling place. As, I assume, it should be. (These are plots for candidates with axis x as voter turnout and axis y as percentage for candidate.)https://imgur.com/a/KXbmT23It was true for every candidate except one.https://imgur.com/a/0sDzHvsThe higher turnout, the higher percentage for that candidate. One possible explanation to such abnormality is that some votes for the candidate were ""added"".Is there a method to separate those ""added"" votes from normal ones, in your opinion? Thank you.",,
93,https://www.reddit.com/r/datascience/comments/e1uo86/i_have_access_to_linkedinlearning_and_can_give_it/,e1uo86,i_have_access_to_linkedinlearning_and_can_give_it,poolguy8,0.6,1,2019-11-26 08:38:33,0,8,,"Edit: I apologize, my company decided to retract this offer due to a 1/6th budget cut mentioned this morning. I'm really sorry.",,
94,https://www.reddit.com/r/datascience/comments/e1wnix/i_just_hit_a_major_roadblock/,e1wnix,i_just_hit_a_major_roadblock,JackIsNotInTheBox,0.38,0,2019-11-26 12:22:50,0,9,,Is it true all data science jobs in the US require citizenship because data is sensitive?There aren't many data science jobs where I live. Have I wasted my whole life in this field?,,"Job Search,"
95,https://www.reddit.com/r/datascience/comments/e1zw6u/10_is_a_terrible_default_number_of_folds_for_cv/,e1zw6u,10_is_a_terrible_default_number_of_folds_for_cv,theAbominablySlowMan,0.4,0,2019-11-26 17:01:16,0,2,,"To say it’s been chosen based on any statistical argument would be a lie. The only other thing to consider when choosing number of folds, is practicality. Most machines have 4/8/12 cores nowadays, so you can realistically do 12 fold cv for (almost) free in a lot of cases. if you’re going to shout out a random number, at least pick one that’s friendly to your PC!",,
96,https://www.reddit.com/r/datascience/comments/e1tfsd/thoughts_on_an_idea_for_a_data_challenge/,e1tfsd,thoughts_on_an_idea_for_a_data_challenge,happyramen123,0.67,1,2019-11-26 06:34:08,0,1,,"Just recently, I found some info from World In Data regarding plastic mismanagement rates around the world. For an upcoming challenge, I wanted to try and choose some social, environmental, political and technological factors and see which factors have the most direct correlation with plastic mismanagement.I would like some thoughts on the feasibility and practicality of this project.",,"Education,"
97,https://www.reddit.com/r/datascience/comments/e1c81m/validate_data_as_you_receive_it_so_you_know_your/,e1c81m,validate_data_as_you_receive_it_so_you_know_your,ed_elliott_,0.93,57,2019-11-25 07:51:10,0,4,,"I was tired of having to keep re-writing the same validation code for every pipeline I wrote so I wrote this tool to help:https://show.schemaed.com/The idea is that you define a schema which contains, data types, non-null, unique constraints as well as custom constraints which you can write in python so when you process a file you know you are guaranteed that the input file matches your original assumptions.When data is invalid (according to our schema) each failed row gets a description of exactly why it failed so you don't have to start testing every row and column to find out where incorrect values areWould love some feedback :)",https://www.reddit.com/r/dataengineering/comments/dz3n2s/validate_data_as_you_receive_it_so_you_know_your/,
98,https://www.reddit.com/r/dataengineering/comments/dz3n2s/validate_data_as_you_receive_it_so_you_know_your/,dz3n2s,validate_data_as_you_receive_it_so_you_know_your,ed_elliott_,0.98,29,2019-11-20 16:33:42,0,16,,"I was tired of having to keep re-writing the same validation code for every pipeline I wrote so I wrote this tool to help:https://show.schemaed.com/The idea is that you define a schema which contains, data types, non-null, unique constraints as well as custom constraints which you can write in python so when you process a file you know you are guaranteed that the input file matches your original assumptions.When data is invalid (according to our schema) each failed row gets a description of exactly why it failed so you don't have to start testing every row and column to find out where incorrect values areWould love some feedback :)",,
99,https://www.reddit.com/r/datascience/comments/e1qbes/data_pipelines/,e1qbes,data_pipelines,Siba911,1.0,1,2019-11-26 02:14:31,0,1,,A forewarning here... I know very little about DS compared to the community here. I’m a Finance Officer in the military and am trying to transition to the Operations Research Functional Area. I’m a quarter of the way through with a MS in Analytics.I’ve been thinking about assisting my current organization I fall under with making some changes with how they pull and track their financial data. The army uses a financial system that is based off of SAP. Out of sheer curiosity is the following an example of a very simple data pipeline?:Establish daily background reports in SAP with pertinent data and sent via emailCreate a VBA macro that pull the reports from the email daily and formats the dataThe data feeds into a dashboard like PowerBI that is refreshed daily after the macro is done running.Profit??,,"Discussion,"
100,https://www.reddit.com/r/datascience/comments/e1cf3s/how_can_data_science_helps_small/,e1cf3s,how_can_data_science_helps_small,tsunjeck,0.83,26,2019-11-25 08:11:25,0,18,,"Hello all, What do you guys think of applying data analytics into startups? I feel like data analytics is not important for early stage startups as there isn’t any valuable data to look into, how can we change this? Would like to get some thoughts and insights.",,"Discussion,"
101,https://www.reddit.com/r/datascience/comments/e1jza6/how_much_math_review_is_too_much/,e1jza6,how_much_math_review_is_too_much,heptoop,1.0,3,2019-11-25 19:09:44,0,3,,"I’ve been going through “Mathematics for Machine Learning” and have some doubts on whether this much review is necessary.I was following along with Andrew Ng CS229 course notes, and I understood really high level what’s going on, but not the details.I’ve taken intro stats and calc and linear algebra in uni, but 5ish years ago.Is it better to know all the nuts and bolts or just keep the understanding high level? I don’t have a quantitative undergrad or masters but want to land my first DS job.",,
102,https://www.reddit.com/r/datascience/comments/e1p6wo/data_science_and_containerships/,e1p6wo,data_science_and_containerships,pinkrazorscooter,0.5,0,2019-11-26 00:51:45,0,6,,"Hi! I'm still a student but am considering a career in data science. My main interest is computer science, but I would also  love the opportunity for a job that gets to work with package shipping in some form, specifically those massive container ships. Is data science / a degree in data science a possible way to get into a mix of this field and computer science? Do you know anyone that has a job that mixes shipping + data / computer science? What should I be considering / learning / doing? Am I even asking this question in the right place?",,"Career,"
103,https://www.reddit.com/r/datascience/comments/e1j4kq/medieval_data_sources_sought/,e1j4kq,medieval_data_sources_sought,erud_IT,1.0,2,2019-11-25 18:16:27,0,3,,"Aspiring data scientist seeks sources of Medieval data, ideally regarding criminal justice.Those monks were diligent!  Therefore, I am sure this exists somewhere - likely in non-digitized form in some monastery or something.  I need the Gregor Mendel of the Guillotine.If you are an academic researcher - particularly in Germany, Ireland, Italy or the former Austro-Hungarian empire, I would love to talk to you about potential sources of Medieval or Premodern criminal justice data.  French Cathar data, or some of Robespierre's accounts, could be ideal since je parle français assez bien.I am trying to train this AI and it needs to learn about this.",,"Projects,"
104,https://www.reddit.com/r/datascience/comments/e1h15j/is_it_common_at_all_for_a_data_scientist_to_be_a/,e1h15j,is_it_common_at_all_for_a_data_scientist_to_be_a,SquareCurvesStudio,0.67,2,2019-11-25 15:49:43,0,15,,"Curious, just because of how fluid these two positions can be and how both positions can have different scopes of responsibilities depending on the company size, industry, etc.And I ask this mainly because of what I hear from time to time, which is that a Data Scientist might be doing more of Analyst-type work and vice versa, an Analyst that handles a lot of the data process and is essentially doing more Data Scientist-type stuff. I assume that in the first scenario, the Data Scientist only has to do more of the Analyst-type work because the company is large and has multiple DS in the team and delegates accordingly. And then the latter being an Analyst at, say a small or startup-ish company that can't afford a big Data team and so that one ""Analyst"" has to do everything (as much as he's capable of).So I guess I'm wondering if that first scenario is somewhat more common than the latter? Am I dumb to think that as an Analyst I can, if I'm lucky and am in the right place and time, land a Data Scientist position that's actually more of an Analyst position?",,"Discussion,"
105,https://www.reddit.com/r/datascience/comments/e1ki3r/how_do_you_share_projects_with_other_teams/,e1ki3r,how_do_you_share_projects_with_other_teams,8589934591,0.67,1,2019-11-25 19:43:53,0,5,,"My team is responsible for creating and launching a dash/ML application. We developed it using Ubuntu. There is some interest in the data science team to try out our application locally in their systems. We know that some people in the data science team use windows, ubuntu, macos, fedora, etc. How exactly do we create a reproducible README that would help the team members install in their local system?For example, what would you tell windows users when/if your application is dependent on say redis? I have also never used windows with pip/docker/etc.One way I can think of is having docker installed in all systems, then use the image of the application.",,
106,https://www.reddit.com/r/datascience/comments/e1jtsk/guidance_for_data_normalization_when_fetching/,e1jtsk,guidance_for_data_normalization_when_fetching,dilator,1.0,1,2019-11-25 19:00:25,0,1,,"Hi People,I'm working on a startup, I have created a reporting tool that accumulates data from 20 different platforms.Currently, I’m providing an on-demand solution where I fetch data from APIs whenever a report needs to be generated.I want to expand the number of platforms multifold, approx 100.Apart from data analytics, I want to provide other advanced features like clubbing data from different platforms, data comparison between platforms, etc.To achieve that scale, based on my research and understanding I realized that I need to normalize the data I receive from APIs and store it in my database to provide data analytics on the data apart from just reporting.Currently, my application is built on MEAN stack.What are the tools/databases I can use to normalize and save the data, are there any predefined standards or basic things which I need to keep in mind before approaching to solve the problem? Is data normalization the right approach or is there any better way?Those of you who have previously worked on such data analytics tools, your feedback would be very valuable to me.",,"Projects,"
107,https://www.reddit.com/r/datascience/comments/e0puay/how_much_real_is_it/,e0puay,how_much_real_is_it,Osiris_R,0.94,1123,2019-11-24 00:10:46,0,54,,,,
108,https://www.reddit.com/r/datascience/comments/e13xsd/meteorological_data_science/,e13xsd,meteorological_data_science,PatienceAVirtue,0.75,4,2019-11-24 21:16:29,0,7,,"Does anyone on this subreddit have experience/work in the field of meteorology and weather prediction (e.g. at the NOAA)? I would love to hear about data work being done in this field, as it seems a fascinating area to work in. Thanks in advance!",,"Discussion,"
109,https://www.reddit.com/r/datascience/comments/e1829r/looking_to_improve_data_management_in_my_zoo/,e1829r,looking_to_improve_data_management_in_my_zoo,rgr1988,0.6,1,2019-11-25 01:56:36,0,8,,"Hi everyone,I work as a zookeeper and one of our tasks is to monitor all the nestboxes of the bird section to keep an eye if there are eggs or chicks, relevant dates, etc. Usually someone has to go around once or twice a week to manually inspect these boxes and gather the required data, which is usually written on a diary and that's it. We're interested in streamlining this process by using a tablet or something to carry around and enter the info there and then and preferably having the option to view data by species or enclosure, sort by dates, see when hatching is expected, etc.Is there any program we could use for this? My supervisor mentioned Excel but I thought there should be something maybe more friendly, maybe Access?Apologies if I'm in the wrong sub and sorry for my niche question!",,
110,https://www.reddit.com/r/datascience/comments/e15gng/the_best_google_notebook_sharing_site_i_have_come/,e15gng,the_best_google_notebook_sharing_site_i_have_come,mathieudempsey,0.54,1,2019-11-24 22:56:32,0,0,,"From the creator:https://www.google-colab.comI started by cataloguing a few interesting notebooks in a github repo and want to make it more easy for others to share their work and receive comments.If you are interested, the posts also push to twitter, linkedin, reddit and facebookSo why Google Colab? -- Its is fairly easy to use with a click-and-run format and helps those with limited resources. And even though it has some issues, I am sure we are only at the start of a long-term project and that Colab would keep on improving. If you have any feedback, please let me know.",,"Projects,"
111,https://www.reddit.com/r/datascience/comments/e14s4a/transaction_dataset_and_churn_rate_calculation/,e14s4a,transaction_dataset_and_churn_rate_calculation,datapim,0.57,1,2019-11-24 22:12:34,0,7,,"I'm trying to calculate churn rate for a dataset that contains transaction data of customers, I have date of transaction, cost and customer ID and based on those variables I need to check the churn rates for the customer (the dataset is for several years).So I'm wondering what should be the correct way for this.At first I thought I should count how many customers came back next month after buying in given month, then how many came after 2-3 months, 4-5 and so on. Also count how many never purchased again. Is this correct way of doing that? Or it does nto make sense?Then second idea is to count how many customers are in one month, then count how many of them dropped in next month, how many new joined and repeat for every following month.Im not sure if this kind of approach makes some analytical sense, so I wonder if there is some better way that I could go with this kind of data?",,"Discussion,"
112,https://www.reddit.com/r/datascience/comments/e0l3uu/list_of_20_simple_distinct_colors/,e0l3uu,list_of_20_simple_distinct_colors,rtphokie,0.94,144,2019-11-23 18:37:16,0,19,,,https://sashat.me/2017/01/11/list-of-20-simple-distinct-colors/,"Discussion,"
113,https://www.reddit.com/r/datascience/comments/e11vck/how_can_i_convert_a_job_description_into_a_graph/,e11vck,how_can_i_convert_a_job_description_into_a_graph,Abyss_Above,0.5,0,2019-11-24 18:56:19,0,6,,I’m interviewing for an engineering/data science position. The job description is about 7 pages of text with several categories. I want to convert this text into a graph indicating my competency in each section. If I lack in a section I’d like to state a proposed timeline until I reach an acceptable level of competency. I’m unsure which type of graph to use to bring the point across.,,
114,https://www.reddit.com/r/datascience/comments/e0x3ys/is_it_right_time_to_transition_to_data_science/,e0x3ys,is_it_right_time_to_transition_to_data_science,geekinside18,0.58,2,2019-11-24 11:55:10,0,7,,"So dear fellow data science enthusiasts, I currently work for a data analytics based consulting company. I do consulting work for one of the top 3 credit card issuers of USA (any guesses..). We mainly advise our client on strategies best for optimising profitability and reducing losses in the credit card business based on data analytics. I use mainly SAS/SQL and excel combined with business aptitude to narrow down on our solutions.Well the reason for writing this post is because of my struggle to decide whether I should devote my time and energy to learn python/machine learning/deep learning on my own time or continue the line of work which will ultimately transition into a business role as i climb up the corporate ladder.Let me just explain a bit of reasoning behind my struggle.Currently, I have the credit card domain knowledge (banking jargons, well they do mean sth) which in itself is very valuable across banks/lending institutions.No cutting edge models are in place in US lending business because of regulatory issues, but this is bound to change sometime in the future and I do not want to get fired if any recession/down sizing happens.I have the fear of being left out when the whole world is transitioning into the complex world of data science and devising unique ways to reduce 'cost functions' where the only USP i have is the domain knowledge and playing with Excel pivots.I can also counter-argue against my own above point that by the time complex data science catches up in the banking sector, I will be high up the ladder enough not to get affected by this (ever see the AVPs, VPs of consulting firms/banks, they don't know what a L1/L2 regularisation is).I guess the problem really boils down to business side vs core technical side. I would really appreciate quality 'consulting' into my own professional life from fellow redditors. Feel free to ask anything.",,
115,https://www.reddit.com/r/datascience/comments/e0scdm/data_scientists_what_does_your_current_tech_stack/,e0scdm,data_scientists_what_does_your_current_tech_stack,cutie0513,0.82,7,2019-11-24 03:28:00,0,14,,"My current tech stack could use some work, would love to hear what technologies data scientists are currently using. thanks in advance!",,"Tooling,"
116,https://www.reddit.com/r/datascience/comments/e0sboh/hyperparameters_for_word2vec_for_sms_corpus/,e0sboh,hyperparameters_for_word2vec_for_sms_corpus,conradws,0.8,3,2019-11-24 03:26:25,0,3,,"Hey all,Working at a small startup, and we have extracted 33 million text messages from our users. We plan to create a model to classify different types of sms relevant to us.First step is to create a Word 2 Vector dictionary for EDA and clustering and possibly to use these embeddings for classification further down the line .Just wanted some guidance about the hyperparameters for the gensim's Word2Vec.The corpus is 33 million sms, average sms length is 16 words and the vocab size is 1.5 million.I used the following hyperparameters and obtained decent results but just wanted to know if I'm doing anything wrong that could be hampering the model from performing even better:Cbow, window = 4, vector size = 125,  iterations =10, workers = 5.Furthermore does anyone have any tips on how to evaluate the embeddings ( other than checking that the similarity for a small set of words makes sense) so that I can fine-tune these hyperparameters?And final question ( I promise) Would it possible or recomendable to take a pre trained Word2Vec model and improve on it by giving it the sms data so that it learns new words like slang and typos without losing its overall knowledge of the language?Thanks so much for your time in reading.",,
117,https://www.reddit.com/r/datascience/comments/e0n54v/colorbrewer_color_advice_for_data_viz/,e0n54v,colorbrewer_color_advice_for_data_viz,beegeetee,0.8,6,2019-11-23 20:57:57,0,0,,,http://colorbrewer2.org/,
118,https://www.reddit.com/r/datascience/comments/e0dgu5/from_zero_data_science_knowledge_to_competing_on/,e0dgu5,from_zero_data_science_knowledge_to_competing_on,Humble_muslim,0.82,75,2019-11-23 06:14:11,0,60,,,,"Education,"
119,https://www.reddit.com/r/datascience/comments/e0sar7/do_i_need_a_statistics_degree_to_become_a_data/,e0sar7,do_i_need_a_statistics_degree_to_become_a_data,LetsEndSuffering,0.57,1,2019-11-24 03:24:20,0,12,,"My undergrad degree is Finance. Is this sufficient to land a data analyst job? Job descriptions often say ""BS degree in quantitative discipline"" or ""4 year degree in Math, Statistics, Physics, Economics or other quantitative discipline"" - would Finance fit into this category? And even if it does, is it realistic to expect to out compete Statistics graduates (most relevant degree) in getting the jobs?If I were to get a masters degree for data analyst or data science roles, should i choose Computer Science or Statistics? Thanks",,"Career,"
120,https://www.reddit.com/r/datascience/comments/e0sset/entering_the_data_engineering_field/,e0sset,entering_the_data_engineering_field,samerpoosh,0.4,0,2019-11-24 04:04:39,0,1,,"I'm really interested in entering the Data Engineering field, and I have a year experience as a Data Analyst, but it seems like everyone is only looking for people with experience using Hadoop environments.I'm doing my part and learning about using Hadoop environments from MOOCS and playing around with them on my free time, but it seems like no one even wants to interview a candidate unless he has 3+ years experience as a Data Engineer.How does one make it into that field?",,"Career,"
121,https://www.reddit.com/r/datascience/comments/e0h0mp/simulating_data_based_on_summary_statistics/,e0h0mp,simulating_data_based_on_summary_statistics,davegvon,0.69,5,2019-11-23 13:01:39,0,13,,"I'm hoping to develop a simulated data set based on reported income figures for a suspicious pyramid scheme company.They have provided a mean, along with a top 50 percentile mean and a bottom 50 percentile mean. The lower bound cannot go below 0.The number of income earners at this level is  175494. The average income is $839.Nothing too difficult. But we also get a split on the Top 50 Average and the Bottom 50 Average.Top 50: $9,166Bottom 50: $18Now I'm trying to wrap my head around a set of data that could possibly deliver these results. I've tried online data generators but it doesn't have the ability to produce a comprehensible data set that would match these stats. Does anyone have any suggestions?(My only inclining is that all $0 earners are not counted in the top 50 counts, but are included in averages calculations).Source: https://embed.widencdn.net/pdf/view/arbonne/bnavepu80y/9035R18_US_ICCS_Fly_final-1.pdf?u=seno6f",,"Projects,"
122,https://www.reddit.com/r/datascience/comments/e02uap/has_anyone_ever_interviewed_their_former/,e02uap,has_anyone_ever_interviewed_their_former,statistical_engineer,0.92,122,2019-11-22 16:54:25,0,51,,"This did not happen to me, but a friend of mine who is a data scientist at another company mentioned that they are interviewing his old professor.  I was wondering how common this is?",,
123,https://www.reddit.com/r/datascience/comments/e09fxv/why_is_deep_learning_considered_a_black_box_but/,e09fxv,why_is_deep_learning_considered_a_black_box_but,logicallyzany,0.8,14,2019-11-23 00:35:55,0,27,,"This might not be the right sub for this, but isn’t deep learning sort of like a parallel logistic logistic regression?",,
124,https://www.reddit.com/r/datascience/comments/e0dt31/andrew_ngs_course_intro_to_statistical_learning/,e0dt31,andrew_ngs_course_intro_to_statistical_learning,failingstudent2,0.6,3,2019-11-23 06:49:10,0,10,,"Hi guys,I'm thinkning of forming a study group of similar timezones for the above materials in December.Instead of being accountable - I would suggest we spend one hour a day on a call and spend the time going through the materials, forcing ourselves to actually spend time on it instead of procrastinating. What do you guys think?(Please delete if not applicable)",,"Education,"
125,https://www.reddit.com/r/datascience/comments/e09cm9/is_the_knowledge_of_data_warehousing_valuable_for/,e09cm9,is_the_knowledge_of_data_warehousing_valuable_for,Franzese,0.8,11,2019-11-23 00:29:13,0,13,,"I've been wondering lately, is the knowledge of how Warehouses work, ETL, SSIS, valuable for a future specialized Data Scientist?My opinion is that it is too much, even though there is a trend and rumors of full-stack Data Scientists (unicorns), but how the heck can employers ask for full-stack Data Scientists when most people and companies have many different definitions of these areas.I would love to hear your opinions!",,"Discussion,"
126,https://www.reddit.com/r/datascience/comments/dzkcaf/coding_habits_for_data_scientists_very_good/,dzkcaf,coding_habits_for_data_scientists_very_good,datascientist36,0.98,483,2019-11-21 15:50:17,0,74,,,https://www.thoughtworks.com/insights/blog/coding-habits-data-scientists,
127,https://www.reddit.com/r/datascience/comments/dzx0x7/the_truth_about_data_science_salaries_in_hedge/,dzx0x7,the_truth_about_data_science_salaries_in_hedge,txiao007,0.8,18,2019-11-22 07:18:11,0,16,,,https://news.efinancialcareers.com/us-en/3002709/data-science-salaries-hedge-funds,
128,https://www.reddit.com/r/datascience/comments/e0648g/biomedical_engineering_neuroscience_project/,e0648g,biomedical_engineering_neuroscience_project,Ginsy3000,0.5,0,2019-11-22 20:42:17,0,2,,"Hello fellow Redditors! I have a BME Neuroscience project and have been scouring the web for open source data associated with a research paper with no luck. For the class, we need to come up with a hypothesis based on data (image or numbers) and analyze it in python, so having data associated with a study would be very helpful. I can't seem to find anything after many hours searching. If anyone knows good sources to find this data or know any datasets it would be greatly appreciated!!! Thank you!",,"Projects,"
129,https://www.reddit.com/r/datascience/comments/e06t6j/clustering_large_dataset_and_storing_the_cluster/,e06t6j,clustering_large_dataset_and_storing_the_cluster,koushrk,0.25,0,2019-11-22 21:28:35,0,1,,"Hello Folks,So I am going to start working on a project that requires clustering text data and was looking for some knowledge I should have before diving into the implementation. I know how tf-idf and clustering work and most of the blog/tutorials on the web are related to that. What I really want to know is how the clusters are stored and calculated when the dataset is large and possibly incrementing.To list down in pointsI have a dataset of text articles for different newspapers spread across different dates. I would need to caculate cluster articles across newspapers and dates.My question is since this is going to possibly large amount of data, what is the best way to go about this. Should I first calculate smaller clusters like for a day and for single newspapers and then try to construct larger clusters from this smaller cluster set.Also how should I store the already calculated clusters? Possibly a list of ordering between new articles and cluster id?Since I am working on this project from scratch, I want to do it the right way. Any reference to open source projects tackling the same problems or even blog would be really helpful.Thank you :)",,"Discussion,"
130,https://www.reddit.com/r/datascience/comments/dzhsvv/detecting_financial_crashes_with_topological_data/,dzhsvv,detecting_financial_crashes_with_topological_data,T-dog-machine,0.83,68,2019-11-21 12:11:44,0,26,,"If you had to generate constant chaos, what do you do? Instead of running in circles shaking your arms i would suggest organising a competition, a number betting competition. Give no restriction on the numbers, and everyone must try to guess the average of all guesses. Unless the contestants are organised, this will result in massive chaos.This is basically what is happening in financial markets. The competitive betting happening there removes any form of pattern from the time series, because a pattern is an opportunity for making money.So success on the markets comes down to finding patterns that other's don't... With topological data analysis you're finding a geometric pattern that helps quantify the shape of noise and find hidden cycles.The idea is to map a sliding window into a higher dimensional space, and study the topology of the aggregated time series. The whole pipeline is explained in this medium article, there is code, which uses Giotto's time series TDA.",,"Projects,"
131,https://www.reddit.com/r/datascience/comments/dzl1fk/is_there_any_chance_the_data_science_field_is/,dzl1fk,is_there_any_chance_the_data_science_field_is,Greenface1998,0.93,12,2019-11-21 16:40:55,0,42,,I’m a college senior going to get a master in ds but I’m slightly concerned because it seems like I hear people around me talking about data science all the time. The number of people planning to go into the field worries me. Is there a chance it’s about to substantially harder to get a data science job due to hype around the field making to many people go into it?,,
132,https://www.reddit.com/r/datascience/comments/dzn8iz/what_does_your_ideal_data_science_position_and/,dzn8iz,what_does_your_ideal_data_science_position_and,chef_lars,0.72,3,2019-11-21 19:07:48,0,8,,Currently working at a company that's 100+ years old and is slow to change. Data science here (a team of my manager and myself) has been hamstrung by a lack of C-Level support. Today they layed off my boss to reorganize 'analytics' (which is now just me lol and I'm still here because I'm cheaper) into a different department. Long story short I'm suddenly far more open to job opportunities. Sorry for the rant.What does your ideal data science position look like? What about company?What are your strategies for identifying these?,,"Job Search,"
133,https://www.reddit.com/r/datascience/comments/dzh02k/measuring_influencers_performance/,dzh02k,measuring_influencers_performance,chiiatew1863,0.8,11,2019-11-21 10:48:15,0,8,,"In data science manner, how should we measure the performance of influencer. In recent marketing, influencer and SNS(Instagram, Facebook, Twitter) is huge....but in terms of measuring those performance, how do you do it? Anyone experienced in this area?",,
134,https://www.reddit.com/r/datascience/comments/dz5irm/take_home_assignments_and_intellectual_property/,dz5irm,take_home_assignments_and_intellectual_property,catalinacruiseking,0.97,129,2019-11-20 18:49:37,0,57,,"I'm currently on the job hunt for DS roles and have been tasked with several take-home assignments that are relatively extensive, require a fair bit of development, and appear to be closely related to an actual problem the company is currently dealing with. A couple companies have moved me forward in the process, a couple companies have never gotten back to me...I recognize that these assignments CAN be a valuable part of the interview process but I am curious if I'm just doing free DS work for a current overworked data analyst to implement later. Do you gainfully employed scientists think this is a reasonable concern/something that actually happens? Is there anything I can do to protect my IP, or am I just signing my work away to a black hole of 0 feedback or response?",,"Discussion,"
135,https://www.reddit.com/r/datascience/comments/dzow0z/having_trouble_understanding_descriptions_of/,dzow0z,having_trouble_understanding_descriptions_of,NewStart793,1.0,1,2019-11-21 20:57:39,0,1,,"I am a master's student, and I have been reading about causal inferences, and I am a child in this area of topic. I was trying to discern about the way that causality would work, and I felt that I would need to understand the keywords that are used in the tutorials for causality.This led me to find the Daggity website, in which they describe the basic terminologies in causality. I am still not able to discern the explanation for a ""Proxy Confounder"" and a ""Competing Exposure"". I wasn't able to visualize the existence of covariate variables because I have only studied linear modelling until now. I am not able to see how we would let variables outside exposure and outcome variables, exist. I just feel like intuitively ,we would seek to quantify every variable possible and see if they would stand to be an exposure or outcome variable.I was also wondering if covariate variables could refer to unquantifiable variables in my data. For example: Hope, love, etc.  If they would refer to such variables how would you go about establishing a mathematical relationship between them, when there are no numbers to go on.I am sorry, if I sound stupid, I am still thinking in ""predictions"" and am not use to thinking in terms of ""interventions"". Can anyone explain the basics or direct me to any tutorial that explains it a bit simpler for someone like me ??",,"Education,"
136,https://www.reddit.com/r/datascience/comments/dzjkwm/venting_or_showing_gratitude_to_the_package/,dzjkwm,venting_or_showing_gratitude_to_the_package,thoughts57,0.83,4,2019-11-21 14:50:28,0,4,,There are quite a few packages I have used from github for python for ETL and some missing data related functionalities. I have mixed feelings for some and some genuine gratitude for others. I wanted to leave these reviews on github but I couldn’t really do it. Where do you guys go and talk about these things?,,"Tooling,"
137,https://www.reddit.com/r/datascience/comments/dzlyyc/examples_of_machine_learninga_applied_to_shipping/,dzlyyc,examples_of_machine_learninga_applied_to_shipping,jirukulapati,0.67,1,2019-11-21 17:42:22,0,6,,"Can anybody who works in this space give me an example?  Not necessarily state of the art, but more so a stable industry project you have worked on/ are working on.  Is it mainly price prediction?",,"Projects,"
138,https://www.reddit.com/r/datascience/comments/dzobr2/i_have_access_to_120_generic_mailboxes_of/,dzobr2,i_have_access_to_120_generic_mailboxes_of,Flanker420,0.43,0,2019-11-21 20:20:37,0,0,,,,"Discussion,"
139,https://www.reddit.com/r/datascience/comments/dzf2yu/data_and_the_religious_perspective/,dzf2yu,data_and_the_religious_perspective,damjanv1,0.73,5,2019-11-21 07:14:58,0,4,,"Hi all,Would love to know the answer to this question as I have potentially no background in this area (to the point where I do not even know how to ask the question properly).I’m interested in the views that various religions have on data, data privacy and AI.How do various religions feel about AI? What are some considerations on data privacy that someone from your religion may make that an atheist or non believer would not? Are there any considerations that one would need to take to de-bias data sets from the perspective of your religion? Do religions find it ethical to use AI for their own behalf, or does anyone know of any such projects where a religious body has done so (i.e. predictive models for churn / conversion)?I seriously don’t know anything on the position for any of these issues, and would love to hear from people that do or have thought about it. I know a lot about DS and I know that design for AI / ML considerations will gain importance in the future if they currently have not already. Whereas I know a lot about DS, I know very little (probably area I’m most ignorant about) religion so I would love to hear people’s opinions here",,"Discussion,"
140,https://www.reddit.com/r/datascience/comments/dzts25/based_on_the_research_of_100s_of_job_posts_here/,dzts25,based_on_the_research_of_100s_of_job_posts_here,ishwarjha,0.15,0,2019-11-22 02:39:04,0,3,,,,"Career,"
141,https://www.reddit.com/r/datascience/comments/dz7r9x/random_when_is_data_considered_to_be_big_data/,dz7r9x,random_when_is_data_considered_to_be_big_data,SquareCurvesStudio,0.87,24,2019-11-20 21:23:31,0,36,,"Title. In your opinion, you Data Scientist you ;), what defining traits does Data have to have in order to go from just being a large amount of data, to this so-called Big Data?",,"Discussion,"
142,https://www.reddit.com/r/datascience/comments/dzbjjf/broadly_speaking_what_skill_setstoolkits_does/,dzbjjf,broadly_speaking_what_skill_setstoolkits_does,Lostwhispers05,0.88,6,2019-11-21 02:10:06,0,4,,"Landing my first data job after several months of intense self-studying and portfolio-building was very satisfying, but it also brought to light the gaps that existed in my skillset.My lack of understanding of the back-end Data Engineering that our senior devs do behind the scene has been a pretty huge bottleneck in my productivity. For me in particular, it's been things like AWS, cron jobs, docker containers, and such that have been completely alien to me, and yet my colleagues speak to me about them as though I should intimately understand them. This is where my non-CS background really becomes evident (my major was in Chemistry!)I'm curious to hear about other people in this situation, the skills they had to learn, and how they went about learning them.",,
143,https://www.reddit.com/r/datascience/comments/dzaxfj/what_do_employers_think_about_data_science/,dzaxfj,what_do_employers_think_about_data_science,LetsEndSuffering,0.7,4,2019-11-21 01:21:50,0,28,,"Data Science masters programs are popping up everywhere. what do employers think about them? What do you think about them? Do you think they are too new and fluffy, and that a CS or Stats program should be chosen over them ,or do you think it is better than CS or Stats masters programs for jobs in data science?",,"Discussion,"
144,https://www.reddit.com/r/datascience/comments/dyv7ph/great_presentation_deck_by_arvind_narayanan_how/,dyv7ph,great_presentation_deck_by_arvind_narayanan_how,atruetoe,0.98,216,2019-11-20 03:24:51,0,42,,,https://twitter.com/random_walker/status/1196870349574623232,"Discussion,"
145,https://www.reddit.com/r/datascience/comments/dz63ur/how_can_one_learn_about_data_lakes_ie_hadoopspark/,dz63ur,how_can_one_learn_about_data_lakes_ie_hadoopspark,bigpizzafan93,0.91,8,2019-11-20 19:30:33,0,8,,I consistently am asked about my data engineering skills for DS interviews and I want to learn at least the basics of these tools to set myself apart.,,"Education,"
146,https://www.reddit.com/r/datascience/comments/dz2uab/have_any_of_you_switched_to_a_different_field/,dz2uab,have_any_of_you_switched_to_a_different_field,jirukulapati,0.75,6,2019-11-20 15:33:36,0,10,,"If so, what field?  Why the transition?  And how did you do it?",,"Career,"
147,https://www.reddit.com/r/datascience/comments/dz4fqa/could_i_use_apache_airflow_to_automate_weekly/,dz4fqa,could_i_use_apache_airflow_to_automate_weekly,knewkungfukenny,1.0,5,2019-11-20 17:32:09,0,14,,"Hi all,I've started a junior data analyst job recently, and part of the job includes running weekly and monthly reports, typically pulling the data from MySQL and then doing some analysis. I've just discovered Apache Airflow, but am struggling to find examples of it used for something as simple as scheduling weekly SQL queries. Is this a viable use of Apache Airflow, or is it used more for big data?Thank you!",,"Career,"
148,https://www.reddit.com/r/datascience/comments/dywwuc/could_we_get_a_paretos_principle_list_of/,dywwuc,could_we_get_a_paretos_principle_list_of,logicallyzany,0.93,35,2019-11-20 05:42:00,0,14,,"I think many non-experts have wondered “when do I know enough statistics?” While there probably is no answer to that question I think if he had a consensus answer to a different question, this would be useful to the community.For the expert data scientists of reddit, what is the 20% of statistics that accounts for 80% of all data science problems, being as specific as possible, e.g. “Possion Distribution” not “Discrete distributions”",,
149,https://www.reddit.com/r/datascience/comments/dz756b/so_i_passed_my_dell_emc_today/,dz756b,so_i_passed_my_dell_emc_today,myredditusernameisnt,0.56,1,2019-11-20 20:41:41,0,1,,That’s it. Just had to share cos not many people in my family understand what I do. Yeah.,,
150,https://www.reddit.com/r/datascience/comments/dz41aw/got_a_job_offer_for_a_machine_learning_engineer/,dz41aw,got_a_job_offer_for_a_machine_learning_engineer,azzipog,0.83,4,2019-11-20 17:02:42,0,16,,"I've heard mixed things about working for Accenture. I have 2 yeara if experience as a data scientist and am wondering if this would be a good career move. I want to improve my technical skills as quickly as possible.They are offering a base salary of $115,000Thoughts?",,
151,https://www.reddit.com/r/datascience/comments/dz7gqd/azure_sql/,dz7gqd,azure_sql,2407s4life,1.0,1,2019-11-20 21:03:24,0,2,,Does anyone here use Azure for data management for the DoD (USAF specifically). I'm looking for an online database solution and this seems like it would work well.,,
152,https://www.reddit.com/r/datascience/comments/dyldgq/okcupid_presents_peekaboo_sometimes_no_data_is/,dyldgq,okcupid_presents_peekaboo_sometimes_no_data_is,jgugges,0.96,176,2019-11-19 15:50:02,0,7,,,https://tech.okcupid.com/peek-a-boo-cases-where-data-can-hide-the-truth/,"Discussion,"
153,https://www.reddit.com/r/datascience/comments/dyptgb/how_much_statistics_do_i_really_need_to_know_for/,dyptgb,how_much_statistics_do_i_really_need_to_know_for,iMakeBaadChoices,0.88,66,2019-11-19 21:01:43,0,24,,"I'm doing an undergrad in Statistics and I'm graduating this year and I plan to go into the Data Science field afterwards. For some reason I still don't feel like I know enough about statistics if that makes sense. I've taken the typical intro to probability, statistics, regression, data collection, data analysis courses and I've passed all of them (some like regression and data collection I did well since it was more applied, but intro to probability theory and such I had a bit of trouble) but I still have this feeling I don't know enough.I know statistics is important in terms of data science but how much do I really need to know?When it comes to applied statistics (hypothesis tests, confidence intervals) I know what they're all about but when it comes to theoretical things, that's where I get kinda shaky. For example, a question I have as an assignment right now and I'm kinda stuck on is like, if Y|u~Poisson, and we let u~gamma, what's the marginal dist of Y. Like I get a question like this and it makes me think I know absolutely nothing about stats and I need to re-learn everything.Likewise, I want to start the ""An Introduction to Statistical Learning"" book and I'm only into chapter 2 and I understand everything that's being talked about, but in the back of my mind I have thoughts like ""Oh you're cheating you should learn more about stats before reading this book, go back and learn more stats"".tldr: So what do I really need to understand about stats, how much of an understanding do I need? How can I test whether or not I really have an enough of an understanding of stats and I'm just overreacting or I actually am under prepared.",,"Education,"
154,https://www.reddit.com/r/datascience/comments/dz2utj/what_tools_do_you_use_to_analyze_graph_data/,dz2utj,what_tools_do_you_use_to_analyze_graph_data,m-hoff,1.0,2,2019-11-20 15:34:51,0,1,,I'm curious about what state-of-the-art tools exist for graph mining/network analysis. I'm more interested in the software packages that are used as opposed to the algorithms and methods.I'm trying to gauge the interest in a tool for graph mining that is designed for users without a strong data science background. Something like an AutoML approach to graph mining. Thoughts?,,"Discussion,"
155,https://www.reddit.com/r/datascience/comments/dz3bhb/american_red_cross_analyticsbased_methods_improve/,dz3bhb,american_red_cross_analyticsbased_methods_improve,senorgraves,0.6,1,2019-11-20 16:10:20,0,4,,,https://www.informs.org/Impact/O.R.-Analytics-Success-Stories/American-Red-Cross-Analytics-based-methods-improve-blood-collection-operations,"Discussion,"
156,https://www.reddit.com/r/datascience/comments/dz5tv6/do_you_think_it_is_possible_to_fully_automate/,dz5tv6,do_you_think_it_is_possible_to_fully_automate,throwmeplz232,0.25,0,2019-11-20 19:11:07,0,2,,"Let's take an analog of AI implementation in machines and robots that make decisions on their own.What about AI implementation in some basic online-based business models?Do you think it is possible to make a combination of a certain and simplified business model(where majority if micro/macro-decision making is purely based on quantitative data)?Are there any articles or something about some self--macro-managing businesses I mean building marketing campaigns, running them, comparing with the database and testing whether its profitable or not , learning, same thing for business development, leadlist development all these micro/macro tasks that are usually done by junior-level employees.Of course major decisions cannot be substituted by AI, but at least 70-80% of time-consumptions could be?Whether your answer is yes or no, what kind of business models have most exposure to being automized the most? (I am mostly talking 1-10 employee business post-automation)",,"Discussion,"
157,https://www.reddit.com/r/datascience/comments/dyyvnn/help_advice_and_resources_needed_for_my_masters/,dyyvnn,help_advice_and_resources_needed_for_my_masters,coffeestainedjeans,1.0,3,2019-11-20 08:54:17,0,4,,"Hi everyone!I'm pursuing my Master's in DS and I have to do a thesis. My proposal revolves more or less around the idea of mood. It has two parts:What semi-constant factors (education, financial status etc.) impact an individual's mood?Is there a general trend related to the concept of mood in general for this population or are there any significant correlations with factors found in 1?I've structured my problem-solving in such a way that it involves a month or so of data collection. I know I could've looked for datasets online but I really wanted to dive deep with this since this is my first thesis and the problem statement is close to my heart since I have mood swings and anxiety issues.All that said, I'm looking to solve data collection like this:Part 1Ask people to fill an initial survey. My friend is ready to help me with the website. I have some experience too. The data is anonymous and they'll only be asked to input their initials (this comes in later) as an identifier.They fill a rather long survey for their semi-constant factors. I've figured the following out but I need help figuring more out since I want this to be as exhaustive as possible.Socio-economic status:Educational BackgroundAnnual IncomeFamily BackgroundHabits:SmokingDrinkingExercisingDrugsPersonal LifeHobbies - Presence or not - Can be expandedCommunityRelationship satisfactionMarital statusSelf-worth - Could be a scale of 1-10Anything else?Then, they receive a Code which would be their initials followed by a random 3-digit number. This would be secret and will be used to login for the second part.Part 2The Code will help me join Part 1 and Part 2 of Data Collection, and keep the information anonymous. Now, they will either be asked to or get a push notification (however we work out the tech side of it) to fill in how they felt on a day for 30 days.The first thought is to have a simple slider scale with a few tappable tags that describe their mood (need help figuring these out as well)----------Once all that is done, I'll move to my analysis and modelling if all of the data collection goes well. I'm hoping to target an n of 100 at least but I know it'll be difficult. Still, I'll try to make it work. I want to challenge myself on this as well.----------Here's what I need help with:More factors for Part 1 of the SurveyTags for Part 2 of the Survey (possibly some expert who has worked with this domain before could help)Anything I'm missing here which could come to bite me laterOverall opinion about this approach and/or suggestions to make it better.----------Thank you so much. I'm really inching on my deadlines since I have to manage this with my full-time job (the MS is online) and another part-time one so I'm really hoping this subreddit can help me out.",,"Projects,"
158,https://www.reddit.com/r/datascience/comments/dyx26f/data_visualisation_request_trying_to_generate_a/,dyx26f,data_visualisation_request_trying_to_generate_a,BurmaJones,0.8,3,2019-11-20 05:54:43,0,1,,"See this for exampleI have the data on the left and want to create the bar on the right, is it possible to do this using stacked bars or some other means in excel. It is to try and create a geological ground profile. I have been playing around for the past hour or so but am having difficulty.How can this be accomplished using R or Python if i can't use excel. I'm interested in learning this as it would be very useful for creating geological sections from borehole data in the future.",,
159,https://www.reddit.com/r/datascience/comments/dz0174/is_there_a_database_with_homogeneous_data_from/,dz0174,is_there_a_database_with_homogeneous_data_from,Alzzira2,1.0,1,2019-11-20 11:03:16,0,4,,I was doing a fun project to entertain myself and to master R a bit more but I kind of got frustrated because the only csv data files that I've found are different from each other and some don't even have the some variables. I wanted to compare how different leagues do in their country versus how they do in the european stage.,,"Projects,"
160,https://www.reddit.com/r/datascience/comments/dyz17k/dimensionality_reduction_and_clustering_on_big/,dyz17k,dimensionality_reduction_and_clustering_on_big,ibetDELWYN,1.0,1,2019-11-20 09:11:23,0,7,,"Hi, I'd like to ask on you guys' thoughts on best practices for clustering on mixed datatypes? What methodologies have worked for you?I've read that one hot encoding your categorical features isn't an option as calculating distances between binary values doesn't really make sense, and I can't convert categorical data into scalar values (doesn't make sense to convert, say, Occupation into a numerical field).I've also read that Gower's Distance is something to consider, but that it's also just a heuristic so it should be supplemented by other metrics. What other distance metrics are there to consider that handle mixed datasets?And what dimensionality reduction techniques have worked? I heard tSNE isn't an option for big data, so would UMAP work? Or what other techniques should I use?Thank you in advance!",,"Discussion,"
161,https://www.reddit.com/r/datascience/comments/dyhod1/data_science_for_aml_antimoney_laundering/,dyhod1,data_science_for_aml_antimoney_laundering,Arelich,0.95,80,2019-11-19 09:26:21,0,26,,"Hi!I'm currently doing my masters in applied mathematics and statistics and I'm interested in a future in data science. Recently a data scientist from a major bank came to our school to talk about working with data science for AML. I found it really interesting and therefore I really want to do some project that is relevant to this field, mostly to see if it might be something for me. But I can't seem to find any data that I can use for such a project. Does anyone know of where I could get some data that I could use? If anybody here is currently working with AML, what type of projects would you recommend that one could try to get a feel for AML? And what kind of projects give high merit when applying for a job in AML?Thanks!",,"Projects,"
162,https://www.reddit.com/r/datascience/comments/dyqa2g/do_i_need_a_phd_to_be_at_the_top_of_the_totem_pole/,dyqa2g,do_i_need_a_phd_to_be_at_the_top_of_the_totem_pole,Greenface1998,0.75,8,2019-11-19 21:32:18,0,21,,"I was told anecdotally that data science firms only promote people with PhD to the most senior positions, that’s there’s ceiling to career mobility for people who only have a masters. Is this true?",,
163,https://www.reddit.com/r/datascience/comments/dyybu6/is_medium_worth_paying_for/,dyybu6,is_medium_worth_paying_for,da_chosen1,0.43,0,2019-11-20 07:54:30,0,4,,"I read a ton of data science articles on Medium, and I use incognito to view extra articles. I’m curious how many people pay for medium, and for those of you that do, why do you pay for it?",,"Discussion,"
164,https://www.reddit.com/r/datascience/comments/dz0uw9/announcing_jupyter_notebooks_on_ai/,dz0uw9,announcing_jupyter_notebooks_on_ai,kailashahirwar12,0.36,0,2019-11-20 12:32:41,0,0,,"Hi Everyone,The last two months have been hectic for us as we have been working on Jupyter Notebooks for our AI Cheatsheets portal. Two months back, I felt, we need a portal for beginners with tools to learn data science and machine learning. Sometimes, beginners struggle to acquire resources and tools they need to learn data science and machine learning.Finally, we are happy to announce the release of Jupyter Notebooks on our AI Cheatsheets portal. Now you can launch Jupyter Notebooks for your data science needs.We are providing 600 free credits which are equal to 10 Notebook hours. After you use 600 credits, you can request us for a customized package with more credits.Visit us at https://www.aicheatsheets.comWe are working on a few more cheatsheets as promised and will release them soon.Also, help us by submitting your valuable feedback.Disclaimer: Jupyter Notebooks are in the Beta phase and you might face issues while creating or using notebooks.We have tried our best to make the experience as smooth as possible. In case of any issues, reach out to us at aicheatsheets@gmail.com",,"Education,"
165,https://www.reddit.com/r/datascience/comments/dyviqd/can_someone_help_me_understand_this/,dyviqd,can_someone_help_me_understand_this,ho1doncaulfield,1.0,1,2019-11-20 03:48:40,0,3,,"I'm having an argument on Twitter. It's about college football and preseason polls, and the bias inherent in preseason polls. Most of the argument is centered around bias in preseason rankings, and he brings up two different statistical models and says ""but these agree with human perception, and they're statistics!"" But both statistical models take into account preseason polls (which are inherently biased) before week 7, when he explains that the models then use raw data from football games. Here's a link:https://twitter.com/cameronsoran/status/1196977532706250752I need to understand what this person is getting at, because it's not making sense to me. Does data actually work this way? You can't just remove a data point, at some arbitrary point during collection, without it STILL affecting proceeding results, right? Or am I not looking at this clearly?Image if you don't feel like viewing a Twitter thread:",,"Discussion,"
166,https://www.reddit.com/r/datascience/comments/dyln3d/resourcesgetting_models_into_production/,dyln3d,resourcesgetting_models_into_production,senorgraves,0.82,7,2019-11-19 16:11:03,0,5,,"I'm an MS Analytics student currently. The company I work for has 1000 employees, with zero data science happening beyond descriptive stats and trends in Excel/Tableau.I've learned a lot already and there are tons of things I could model to help the business, but I have no clue what I would do once my model was complete. How do I put it in production, and make sure non-data-scientists can benefit from it?I'm looking for resources along these lines, because I don't think it is a big is it the curriculum in my degree, and I have no one to learn from at my company.Is this the biggest challenge I can expect to face trying to singlehandedly drag this company towards more advanced data analysis/modeling?",,
167,https://www.reddit.com/r/datascience/comments/dyu1xn/what_laptop_to_get_for_data_science/,dyu1xn,what_laptop_to_get_for_data_science,pinkypigs,0.6,1,2019-11-20 01:55:10,0,12,,I’m still in high school but I plan on taking a graduate degree in data science after computer science. Should I be buying a laptop that’s good for both courses? And what laptop would you guys suggest?,,
168,https://www.reddit.com/r/datascience/comments/dy97k5/how_to_interview_a_data_scientist_to_understand/,dy97k5,how_to_interview_a_data_scientist_to_understand,McHighland,0.94,117,2019-11-18 21:46:47,0,22,,"I've been pulled in to interview for a few data science positions at my company! I am on an engineering/product team that works with a lot of Data Scientists! Our Data Scientists aren't on engineering teams but partner with teams solving similar problems.I've been asked to interview candidates to help understand their ability to work with product/engineering teams, shipping models to production, innovate/bring ideas forward, and collaborate across multiple teams.What would be questions that enable candidates to share their experiences in these areas? Does anyone have experience interviewing Data Scientists to answer what I've been tasked with finding out??",,"Discussion,"
169,https://www.reddit.com/r/datascience/comments/dyrash/anyone_working_as_a_growth_ds/,dyrash,anyone_working_as_a_growth_ds,colorblnd_foto,0.6,1,2019-11-19 22:39:31,0,6,,"I'm in the position to choose which kinds of projects I'd like to focus on and define my role as a data scientist. One option is to focus on marketing growth, which will include customer retention, marketing metric definition/strategy and LTV modeling.Does anyone here work specifically with growth marketing and could you share some details about what kinda of projects you work on?",,
170,https://www.reddit.com/r/datascience/comments/dyiopn/discussion_interesting_blog_post_about_time/,dyiopn,discussion_interesting_blog_post_about_time,AlexSnakeKing,0.86,5,2019-11-19 11:27:16,0,1,,"Here's an interesting article on how to automate time series forecasting:https://towardsdatascience.com/on-the-automation-of-time-series-forecasting-models-technical-and-organizational-considerations-286db3120c8eI'm curious about the organizational models described in the end:How viable is the second model, i.e. where the data scientists are themselves the business owners of the forecast: It seems to me that once forecasting with ML models matures, it will no longer be necessary to use this model, and only the first model (automated forecast generation, managed by an engineering team and consumed by business analysts) will remain.Any thoughts?",,"Discussion,"
171,https://www.reddit.com/r/datascience/comments/dyovvd/data_analysis_using_spss/,dyovvd,data_analysis_using_spss,twentyxtwenty,1.0,1,2019-11-19 19:59:55,0,1,,"Hi everyone, I’m trying to run a statistical test on my data. I’m trying to see if an intervention is working over time.My data set includes data for the intervention at four different time points (sessions) for multiple participants (roughly 100). We will run the data through SPSS to evaluate whether there has been a significant change over time in the response of the participants.There is only one group of participants and no control group.Can someone tell me what type of analysis I could run on the data to see if it is significant?Thanks",,"Education,"
172,https://www.reddit.com/r/datascience/comments/dyte78/college_student_looking_to_get_into_business/,dyte78,college_student_looking_to_get_into_business,InterestingGrape,0.2,0,2019-11-20 01:06:17,0,2,,"I was looking for some advice. I am a freshman at a mid size state college on Long Island currently enrolled in the business management program. I am currently exploratory in what I plan on doing out of college. During one of my classes, my business professor mentioned if you're looking to get a nice paycheck right out of college, business analytics is the way to go.I have read about the roles, and career opportunities. It sounds like it would fit my personality and I would enjoy the role very much as I've owned several small business and was always interested in analyzing my company and competitors.My issue is that I don't really know where to begin. Do I switch my major into BA? Is there any way I can build a portfolio for BA instead of switching?I was hoping I could get some advice from someone with some experience in this career path. I've been leaning towards sticking with my Business Management major and applying for BA interns. Is this something worth doing? What would be good place to start if I were to go in this direction?Any advice would be appreciated.",,"Career,"
173,https://www.reddit.com/r/datascience/comments/dylx8p/data_science_in_commodities/,dylx8p,data_science_in_commodities,anapple77,0.5,0,2019-11-19 16:31:44,0,0,,"Hi guys, I’m new to this community. I used to do statistics back when I was still in school but I have since then not been using it. Recently, I’ve started joining online courses to learn more about data science.I am currently in the commodities industry so I was thinking why not use the data science techniques to apply on something related to me. I am just a backend worker so I don’t deal with analysis in my work and so, I have no ideas what data sets or mini projects can I start on my own.Anyone have any experience or ideas in applying data science in commodities industry?? Much appreciated!",,
174,https://www.reddit.com/r/datascience/comments/dyjwkd/looking_for_a_dataset_please/,dyjwkd,looking_for_a_dataset_please,Liverpool1900,0.33,0,2019-11-19 13:40:55,0,3,,"Power Consumption Dataset with categoriesHello everyone,I am looking for a dataset for any location of any size which has power Consumption for an address. I found one for Geelong Australia. However, i also require another column indicating the type of property for example Residential, Commercial or Mixed. Any help is highly appreciated.Thank you all.",,
175,https://www.reddit.com/r/datascience/comments/dyg8kl/how_do_you_organize_your_team_for_data_science/,dyg8kl,how_do_you_organize_your_team_for_data_science,ibetDELWYN,1.0,2,2019-11-19 06:43:57,0,4,,"I recently volunteered to lead a small team for a quarter-long project with people of differing levels of expertise. It's my first time leading a small team for a modeling project, and I want to get it right.What tools and frameworks worked for you guys? And what about them made it work?",,"Discussion,"
176,https://www.reddit.com/r/datascience/comments/dyhf9u/can_someone_give_me_a_milehigh_overview_of_how/,dyhf9u,can_someone_give_me_a_milehigh_overview_of_how,old_enough_to_drink,1.0,1,2019-11-19 08:54:39,0,1,,"Is a language model required? If yes, how is it used to detect and correct grammatical errors?Thanks!",,
177,https://www.reddit.com/r/datascience/comments/dxw94b/data_science_project_ideas_for_beginner/,dxw94b,data_science_project_ideas_for_beginner,root91,0.94,156,2019-11-18 02:43:36,0,22,,"Hey, I’m looking for some project ideas to work on preferably something to do with Sensors, OpenStreetMap etc. Thanks!",,
178,https://www.reddit.com/r/datascience/comments/dy8218/hello_i_need_help_chosing_my_stat_test_for/,dy8218,hello_i_need_help_chosing_my_stat_test_for,ibotismariah13,0.69,6,2019-11-18 20:30:50,0,10,,"I have a large set of data for my science fair, on whether population density affects how teens see success. I do not have stats till next semester and I have no clue what type of test to use.  If you want to help I will send more info. I do not know what all info is valuable to share. Thank you.",,"Discussion,"
179,https://www.reddit.com/r/datascience/comments/dyaiyd/big_career_decisionlooking_for_guidance/,dyaiyd,big_career_decisionlooking_for_guidance,Passacagalia,0.67,2,2019-11-18 23:14:27,0,13,,"Hey everyone, first time posting here. I hope this is the right place to post this.I’m an MS statistics graduate student (with a DS concentration) graduating summer 2020.I am in the fortunate position of having 2 job offers and I’m having a really hard time deciding which is the smarter long term choice. I have about 2 years of experience doing statistical work as a research assistant, but this will be my first big job in this field.Any and all advice/experience would be really helpful!Option A:-Big Finance Company (well-known)-Senior Analyst Position-85k base, 97k tc-Lead my own projects (but most of them have been more SWE than Statistical in nature)-Dream location (but higher cost of living)-Little to no mentoring-I’m the only stats person in a team of SWE-Potential to move into leadership role since my skills are niche here-I have to work while I finish grad school (I’m a full-time student) and there is very little flexibility for taking time for exams/school stuff-good work/life balance-2 weeks paid vacation-Horrible work/life balance while I finish school (pushing 70+ hour weeks currently and it’s affecting my health).-More established department (Risk MGMT), bureaucraticOption B:-Big Bank (regional but still big company)-Data Scientist Position-115k base, 132k tc-Projects decided for me, but more consulting style (variety of projects), and working in teams-Low cost of living area (but not desirable)-Work with other statisticians/data scientists so more opportunity for collaboration-Finish school, take 1 month off, THEN start-40-60hr weeks because there are deadlines-3 weeks paid vacation-Relocation Package-Higher 401k contribution-Newer department (2 years old, decision science) so may function more like start upIf it helps I’m in my mid-20’s and I’m trying to think of what decision is best long-term.I’ve been racking my brain on this for 2 weeks now. Option B would be much easier to pick if Option A wasn’t my dream city.Thanks for your help!",,"Career,"
180,https://www.reddit.com/r/datascience/comments/dydimh/video_as_data/,dydimh,video_as_data,pp2568,0.6,1,2019-11-19 02:50:55,0,2,,"Hi y’allI’m working on a project where we have video clips of people playing some video games. We’d love to use the videos to get data. More specifically, there are four characters on the screen, and we’d like to map out the routes they take going around certain obstacles. Does anyone have resources on how we can translate this video into data?",,
181,https://www.reddit.com/r/datascience/comments/dyaq06/help_understanding_the_roc_curve/,dyaq06,help_understanding_the_roc_curve,mrdlau,1.0,1,2019-11-18 23:28:21,0,8,,"I feel like I understand the definition of the components of the ROC curve and understand the higher the curve in the top left the butter, but i'm not quite tying it all together in terms of how to interpret what the curve and individual datapoints are telling me.Example image from google:By the looks of this curve, if I look the point y=.25, x=.125. Is this saying:  ""if I set my true positive threshold at .25, then my false positive is .125.This doesn't make a lot of sense to me.",,"Tooling,"
182,https://www.reddit.com/r/datascience/comments/dy1al3/advice_for_python_data_analysis_on_hpc_facilities/,dy1al3,advice_for_python_data_analysis_on_hpc_facilities,thatsnotmyname95,0.9,8,2019-11-18 11:07:54,0,6,,"I recently started a PhD in atmospheric chemistry modelling, and do most of my work with python (analysing results), probably some tinkering with fortran soon. The models I run output a lot of large (~50GB) netcdfs and I do a lot of plotting, calculations and coding for them. To do all this, I use an HPC facility, running a condo environment for a remote Jupiter notebook. I like the clarity of breaking up the code into blocks, the markdown capability. But most of my group don't work this way, some use ipython consoles, others send their local scripts from BBedit, etc...For anyone with experience with (python) coding on HPCs, what did you use and why would you recommend it?",,"Discussion,"
183,https://www.reddit.com/r/datascience/comments/dy8olg/does_dataquest_do_black_friday_sales/,dy8olg,does_dataquest_do_black_friday_sales,sadgrad2,0.56,1,2019-11-18 21:12:21,0,3,,"I've been working through the free lessons of the Python courses, and I've been liking it enough that I am considering going premium soon (definitely like better than past experiences with datacamp). Current price is 24.50/mon (294 annually), which it's claiming is 50 percent off. But so close to black friday, I'm guessing I can get a better deal by waiting?",,"Education,"
184,https://www.reddit.com/r/datascience/comments/dxvi8a/what_makes_statistics_so_much_more_difficult_to/,dxvi8a,what_makes_statistics_so_much_more_difficult_to,LetsEndSuffering,0.81,32,2019-11-18 01:43:33,0,45,,"When i ask people if i should do masters degree on stats or cs, they often say Statistics because it is harder to self-teach stats than CS. Why is that? And is self-teaching statistics more difficult than self-teaching other math topics like calculus, where you can do read the textbook, do the problems, and check the answers at the back of the book? If so, why? Is reading the textbook, doing the problems, and then checking the answers like you would when self-teaching calculus a good way to self-teaching statistics? Why or why not?And do you think i should get a masters degree in statistics or computer science for jobs in data science? I'm confused since data science is the intersection of both for the sake of application instead of theory - so shouldn't the statistics needed be less than the CS needed for data science jobs?  Shouldn't the statistics needed be only the applicable stuff instead of esoteric theoretical stuff of statistics?Thanks.",,"Career,"
185,https://www.reddit.com/r/datascience/comments/dxn739/eigenvectors_from_eigenvalues_a_numpy/,dxn739,eigenvectors_from_eigenvalues_a_numpy,likelihoodtprior,0.97,133,2019-11-17 15:31:22,0,23,,,http://predictivehealthcare.pennmedicine.org/Eigenvectors%20from%20Eigenvalues.html,
186,https://www.reddit.com/r/datascience/comments/dxs5la/to_people_who_are_in_grad_school_ms_in_ds_or/,dxs5la,to_people_who_are_in_grad_school_ms_in_ds_or,whiteshark243,0.88,30,2019-11-17 21:36:56,0,70,,"I am seriously considering doing a M.S. in DS and wondering if a good tag name from big schools could aid much in the job hunt after graduation. Based on your experience, are there many recruiters reaching out to you? How desirable it is with a M.S. in DS in 2020? I heard a lot about computer science job market getting saturated and it’s getting much harder to find a DS job compared to 2015-2017 period.",,"Career,"
187,https://www.reddit.com/r/datascience/comments/dxsoeu/any_model_deployment_experts_out_there/,dxsoeu,any_model_deployment_experts_out_there,sieltigre,1.0,6,2019-11-17 22:13:14,0,4,,I wrote an article on how you can deploy your ML models to Azure Functions and I was wondering if anyone could give it a read and give me some feedback?The link is hereI've also done write ups on AWS Lambdas if you're into that too.,,
188,https://www.reddit.com/r/datascience/comments/dxmamu/is_there_any_other_way_to_predict_a_gender_based/,dxmamu,is_there_any_other_way_to_predict_a_gender_based,Likewise231,0.71,21,2019-11-17 14:03:40,0,35,,"Hello,I was wondering what is the best practice to predict gender based on name. Names are mostly not english. The dirty way would be to write a function which would categorize based on a long list of scraped-from-the-internet female or male names, but that seems like a bad practice that can lead to a lot of errors.  I found some packages for english names specifically but nothing for non-english names(Scandinavia/Western Europe).I am looking for some sort of package which would assign gender based on first name and save a lot of time of scraping list of names by gender and country from the internet.",,"Discussion,"
189,https://www.reddit.com/r/datascience/comments/dxplpf/what_metrics_are_used_to_determine_data_as_the/,dxplpf,what_metrics_are_used_to_determine_data_as_the,Photodorf,0.78,5,2019-11-17 18:37:48,0,3,,"Is there anyway to track the value of data as a whole? With the somewhat recent news of data becoming the most valuable resource in the world, I'm curious as to what metrics are being measured to get that outcome and if it can even be tracked to begin with.",,"Discussion,"
190,https://www.reddit.com/r/datascience/comments/dxmssr/negotiating_salary_of_first_ever_job/,dxmssr,negotiating_salary_of_first_ever_job,chandlerbing_stats,0.89,7,2019-11-17 14:54:59,0,13,,"Hi everyone,I was wondering what people’s thoughts are on negotiating your first ever DS job right out of grad school (M.S.)?I have an offer from a well known consulting firm for their data science branch and they offered me a pretty nice starting salary.I’ve read online that I would be doing myself injustice if I don’t try to get more money. But, it’s also my first ever industry job! My data science experience mostly comes from statistical research I did during undergrad and grad and a 10 week internship with a information services company in the industry. Apart from that, I am just another entry level data scientist joining a team that is bigger than myself.What are your thoughts?",,"Career,"
191,https://www.reddit.com/r/datascience/comments/dxlqd0/weekly_entering_transitioning_thread_17_nov_2019/,dxlqd0,weekly_entering_transitioning_thread_17_nov_2019,datascience-bot,1.0,9,2019-11-17 13:00:28,0,123,,"Bleep Bloop. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki. You can also search for past weekly threads.I am a bot created by the r/datascience moderators. I'm open source! You can review my source code on GitHub.",,"Discussion,"
192,https://www.reddit.com/r/datascience/comments/dxti2v/for_an_case_study_interview_considering_a_very/,dxti2v,for_an_case_study_interview_considering_a_very,dattud,0.4,0,2019-11-17 23:10:44,0,18,,,,
193,https://www.reddit.com/r/datascience/comments/dxbqsm/advice_for_transitioning_from_an_engineering_phd/,dxbqsm,advice_for_transitioning_from_an_engineering_phd,Dreoasteh,0.87,70,2019-11-16 20:55:55,0,52,,"I'm a PhD candidate in computational fluid dynamics with a background in aerospace engineering. Currently, I'm half way through my research project and have been increasingly interested in data science.I've taken a PhD course in computational python and machine learning at my university and since some months ago I've shifted my main coding language from MATLAB to python. I also have C++ knowledge which I employ to make high-performance and scalable code when necessary.Although I still have a couple of years to go before finishing, I would like to know which are the most important aspects of DS that I should aim to learn. Also, pointers to good resources (books, courses, etc) are greatly appreciated. I'm currently starting with ""Data Science from Scratch"" (2nd Ed.) as I have access to all O'Reilly stuff for free. Is it a good enough source? Would you go for any other one?My idea was to start putting stuff out there once I got all the ""technical"" pieces together: play around with some Kaggle kernels and competitions even and eventually build something and sheare it on GitHub. Any thoughts?PS: Regarding career advice, I'm from Sweden so maybe some USA-centric advice might not be relevant",,"Career,"
194,https://www.reddit.com/r/datascience/comments/dxdgnk/data_for_social_good/,dxdgnk,data_for_social_good,thelittlenatnat,0.87,29,2019-11-16 23:02:10,0,0,,"I'm considering applying for the Data Science for Social Good fellowship this summer and I'm curious to hear from some alumni of the program. Specifically, where did you end up and did your fellowship experience play a role in the opportunities you ended up pursuing?",,
195,https://www.reddit.com/r/datascience/comments/dx60l4/how_many_tasks_should_i_do_in_sql_before_moving/,dx60l4,how_many_tasks_should_i_do_in_sql_before_moving,throwmeplz232,0.95,104,2019-11-16 12:56:57,0,47,,"First of all , i am a BI intern and not a DS, however i still believe this subreddit is bigger and will give more insights than r/BusinessIntelligence.Aside of reporting and dashboards, I am given a very vague  task to pretty much find insights about the company. I have a long list of things to do.I was expecting to have some BI-specialized person give me straightforward tasks and then i would do it and move to the next one. The tasks here are very vague and there is noone i can ask for an advice aside from database questions.So i am kind of confused of how to approach this task, since the process can be as long as whole month lol...I kind of plan to just exctract data to R and do analysis there. But the problem i find is that well... I have to analyze all the tables in the database but it doesnt seem very pratical for me to just analyze everything in 1 script. Is it common to exctract different subsets of data into different R scripts before doing analysis?Another question is how much of data analysis do I do in SQL before moving to R? Or maybe you just connect tables and filter data before moving to R and do the rest of analysis from there? I am very confused at this part because I have never been in situation nor thought about that part of moving data from SQL to R > I always either played with data in R or SQL, but not both. So it bothers me so much i just dont know . Should i still make summaries in SQL and filter data there or should i move it to R immediatelly ?On top of that there is not so much independent-dependent variable relationship in the database. The data consists of customers, bookings, services etc.. The database wasn't set up for proper analysis how i understand as there is no information about customers like who they are etc. all the data is surrounded around the booking as the main observation and for me all i can do seems to just summarize data based on 3-4-5 different dimensions like locations,etc.etc.I was expecting to be able to apply a ML algoirihms but the database just doesn't have anything. The most useful thing there is - probably location and payment time. There are like 10 tables with on average maybe 20 collumns  and most of it are just dates, technical things like spaceholders for various reason etc.",,"Discussion,"
196,https://www.reddit.com/r/datascience/comments/dxdeat/connecting_pythonjupyter_notebook_to_sas/,dxdeat,connecting_pythonjupyter_notebook_to_sas,eckwr002,0.89,15,2019-11-16 22:57:22,0,13,,Most of the raw data is in SAS but prefer to do my work with python/pandas. Thanks in advance.,,
197,https://www.reddit.com/r/datascience/comments/dx89ib/am_i_expecting_too_much_as_a_junior_ds/,dx89ib,am_i_expecting_too_much_as_a_junior_ds,TraditionalTale,0.9,46,2019-11-16 16:30:53,0,22,,"Just started a DS position right out of college. I mostly do data analysis, data viz and software development. I don't really get to work on ML projects, which is really what I'm interested in.Also I wish the team had senior DS. From the get go, they gave me full autonomy on how I should conduct the projects I'm responsible for; there is no guidance, the only thing we do is have weekly discussion about our own projects, but people are just here agreeing with what I do without what I would expect feedback to look like for a junior.Manager is an IT guy transitioning into the DS field.",,"Discussion,"
198,https://www.reddit.com/r/datascience/comments/dxi3f8/given_multitext_featured_training_data_has/,dxi3f8,given_multitext_featured_training_data_has,dattud,1.0,3,2019-11-17 05:31:04,0,7,,"I cannot add any more data. I required to work with what I got. Is my only option to combine the bottom 4 classifications as other.So far, only best score I got was by using Complement Naive Bayes, and got the following normalized confusion matrix score:Class1(5215):0.89 Class2(631): 0.88 Class3(23): 1.0 Class4(16):0.5 Class5(2): nan Class6(12): 1.0",,
199,https://www.reddit.com/r/datascience/comments/dxfxi9/how_do_you_guys_get_over_engineering_constraints/,dxfxi9,how_do_you_guys_get_over_engineering_constraints,IAteQuarters,0.79,5,2019-11-17 02:19:04,0,8,,"I work on a data science team that works with engineers to put models into production. Essentially, our team builds models/features and tests them on our datasets and when the time comes we start pushing it into production. We have weekly meetings with the VP of R&D and Engineers who are responsible for implementing our code. We use Python and Scala and the product is not written in that.When the times comes for implementation there is generally push back about features we would like to implement. It makes sense, things like word2vec are hard to recreate in an environment that doesn't have it and creating tables willy-nilly in Vertica is looked down upon. This has been causing me a lot of grief because sometimes things that make sense and are easy to implement in Python get push-back because it might be too hard to implement.The only solution I can think of is someone on our team (let's say me) begins to pick up those skills needed to push things to production. However, I've had push-back from my manager who wasn't pleased when he discovered I was learning Scala during company hours and effectively said to me ""learning scala won't make you more productive.""What can I do in this sort of situation. What might be helpful are anecdotes of how you convinced engineering or the team that implements your code why features in their current state might be useful. Or what limitations do you set on yourself before you start a project, such that, there is minimal friction between engineering and data science.",,"Discussion,"
200,https://www.reddit.com/r/datascience/comments/dxoi93/machine_learning_to_predict_student_grades/,dxoi93,machine_learning_to_predict_student_grades,failingstudent2,0.33,0,2019-11-17 17:20:49,0,12,,"College student here, DS major.Finally got down and dirty and spent time reading up on Log Reg, StatQuest and all that jazz.Seems like schools would have almost no issues predicting the grades of students even before they get officially admitted. What are the flaws of doing so and does anyone have experience with doing it?Just seems pretty cool - am thinking of conducting a paid study in my dorm just for the lulz",,"Fun/Trivia,"
201,https://www.reddit.com/r/datascience/comments/dxnbqb/when_not_to_use_machine_learning/,dxnbqb,when_not_to_use_machine_learning,weihong95,0.27,0,2019-11-17 15:42:20,0,4,,"When you are solving a problem, in what circumstances will you apply machine learning?Is it true that in every circumstance, machine learning will always outperform rules and heuristic approaches?In this article, I will explain using several real-world cases to illustrate why sometimes machine learning will not be the best choice to tackle a problem.Link: https://towardsdatascience.com/when-not-to-use-machine-learning-14ec62daacd7?source=friends_link&sk=90b0f6d1945e92f9fcdccc1d6c6a95f7Comment below if you have any thoughts to add on!",,"Education,"
202,https://www.reddit.com/r/datascience/comments/dxa9j3/when_is_r_better_than_excel/,dxa9j3,when_is_r_better_than_excel,Squids4daddy,0.69,5,2019-11-16 19:06:08,0,29,,"Contemplating a career change, I'm taking and edx course on ""R"".  I understand that the teaching exercises are ""trivial"", but I'm having difficulty understanding what it is about R that makes it so preferential to excel.For simple (simplistic?) things like ""what percent of tall people are women"", I feel like what would be two clicks in excel becomes, in R, me typing heights$height and heights$sex over and over and over and over again.  And the syntax...  and the troubleshooting (relative to excel) OMG, what a nightmare.So sock it to me:  what kind of things did people do in excel yesterday that when they made the switch to R they burst out with ""this is AMAZING!!! Why didn't I know about R 5 years ago???""",,
203,https://www.reddit.com/r/datascience/comments/dx1lwo/any_ml_engineers_here_i_will_be_grateful_for_some/,dx1lwo,any_ml_engineers_here_i_will_be_grateful_for_some,Ryien,0.81,50,2019-11-16 04:32:06,0,44,,"I want to pursue a career as a ""Machine Learning Engineer"" after graduating. I'm aware these roles typically require a software backend background as well as a data science background. I love programming software/apps but also want to dive into the field of machine learning and computer vision, so I figured ML Engineer might be a fit for me.I'm going to start my full-time M.S. - Comp Sci program at a top 20 ranked US school in January 2020 and hope to graduate by Dec 2020 (exactly 1-year) because the requirement is only 10 courses.These are my 10 courses below.Does anyone think everything listed here will be sufficient to obtain a ML engineer post-grad internship/entry level role afterwards?Winter Semester:(I am required to finish these 3 ""foundation courses"" first before taking any electives.)1.) Foundations of Algorithms2.) Foundations of Computer Architecture3.) Foundations of Software EngineeringPersonal time — Java OOP projects to build portfolio, learn more python and stats, etc...Summer Semester:1.) Data Science (Overview and Intro to DS topics)2.) Intro to Machine Learning (More theory related and can't use libraries/tools)3.) Intro to Database Systems4.) Large-Scale Database SystemFall Semester:1.) Applied Machine Learning (Covers ML libraries/tools and apply to real-world data from Kaggle/UCI/KDD)2.) Big Data Processing Using Hadoop3.) Information Retrieval (Similar to Data Mining I believe)Personal time — Do own machine learning projects/try Kaggle competitions to improve portfolioI don't want to waste money/time taking unnecessary courses, that is why I want more opinions on this.Any advice is highly appreciated, thank you all! :) .",,"Education,"
204,https://www.reddit.com/r/datascience/comments/dwwfji/am_i_deluding_myself_thinking_my_skill_set/,dwwfji,am_i_deluding_myself_thinking_my_skill_set,Zeiramsy,0.93,106,2019-11-15 21:29:24,0,50,,"I am 5 years into my career as a business consultant and have climbed up the ladder to manager (project lead, team lead,involved in hiring and promotion decisions, etc.).While I generally enjoy doing strategic consulting my real passion is data analysis.Over the last two years I have prioritized evolving from run-of-the-mill market research analysis towards using more advanced analytics. I use R & Python now instead of SPSS, train ML models (Random Forest, Xgboost, etc.) instead of simply multivariate analysis and have dipped into advanced stuff like neural nets,etc.I`d really like to switch towards a pure data science role because I like the work and want to get away from consultant work hours.However in the end I do not have a CS background and while I understand the basics do not have time to really get familiar with stuff like SQL,non-analytics Python and possible languages to prototype apps and front-ends. From a practically stand point my current work really only focuses on analytics (based on mostly available data) as well as the strategic context (which questions to ask, what to do with the answers as well as consulting business on how to develop DS capabilities). None of the models I developed have ever been put into production for example.I don`t think that would be a problem if I want to switch towards entry level data science but I feel with my business and management background I should aim higher (even if just to avoid a wage downgrade).Taking this all together I do not know whether I am actually skilled and desirable enough for the senior level data science roles I covet.What do you think?Update:In another post somebody summed up four key dimensions of DS skills which I really liked. So I think my profile would be something like this:Data Engineering: 1/5Data Analytics: 5/5ML/AI: 3/5Management/Business Knowledge: 5/5",,
205,https://www.reddit.com/r/datascience/comments/dx9w4s/exploding_gradients_in_simple_gradient_descent/,dx9w4s,exploding_gradients_in_simple_gradient_descent,marathonjohnathon,0.75,2,2019-11-16 18:37:46,0,2,,"Hi all, this will be a little lengthy but I'd really appreciate someone educating me. In order to make sure that I really understand the steps of training a neural network, I'm trying to program a simple gradient descent algorithm line-for-line. I keep running into exploding gradients and I think it may be due to one of a couple things I talk about at the end but I'm looking for what's different between my algorithm and say something from sklearn.My ""ground truth"" data is simply Y = 2X with a little noise.The function that I'm learning is Y = MX + B (a straight line) with the changing parameters being M and B. I believe this is equivalent to a neural network with one input node, one output node, and a bias node.My cost function is C = (output - Y)^2Replacing the output term with the model equation and differentiating with respect to M gives me the gradient for M:2X(MX + B - Y)Differentiation wrt B gives the gradient for B:2(MX + B - Y)My algorithm runs as follows:M = random (0 to 1)B = random (0 to 1)learning_rate = 0.01for each x, y pair:derivative_M = 2X(MX + B - Y)derivative_B = 2(MX + B - Y)delta_M = -1 * learning-rate * derivative_Mdelta_B = -1 * learning-rate * derivative_BM = M + delta_MB = B + delta_Bend loopSo each loop I also calculate the output and cost (left it out to keep the pseudocode clean). The algorithm works fine if all the training values are relatively small. But around the 30-50 range, the gradients get so large that the cost actually increases with each time step. It does so exponentially, and after about 5 time steps the numbers get so large the program crashes.I have a couple thoughts. The first is that I should probably use a bounded activation function like tanh to keep values small. But in trying to implement this I realized I don't actually know exactly how they're implemented. Do I apply the function to the input node and the output node, or just the output node? And once I have the tanh-adjusted value from the output node, how do I get the original sample Y value back to calculate cost? The other thought I had is that maybe this is a good example of why you should min-max or z-score your data before running it through a machine learning algorithm. While I know this is best practice, sklearn modules don't seem to have this crash-your-computer problem if you don't normalize. So what are they doing that I'm not? Is it just the activation function, or are there explicit techniques for handling exploding gradients that the professional algorithms all use?I know this was a wall of text. If you made it through thank you!",,"Education,"
206,https://www.reddit.com/r/datascience/comments/dx0g0z/creating_a_data_sciencedata_viz_portfolio/,dx0g0z,creating_a_data_sciencedata_viz_portfolio,exc99,0.82,10,2019-11-16 02:46:54,0,3,,"Hi all, I am a college Junior and have been working on my data visualization skills in Matplotlib. I’m currently in search of a Data Science internship and I was wondering how I can put together a “portfolio”. Also, do recruiters actually look at these portfolios if I were to link it in my resume?",,"Career,"
207,https://www.reddit.com/r/datascience/comments/dwsscr/paper_graphical_models_for_processing_missing_data/,dwsscr,paper_graphical_models_for_processing_missing_data,aiforworld2,0.88,38,2019-11-15 17:03:57,0,4,,"Graphical Models for Processing Missing DataBy Karthika Mohan and Judea Pearl, UCLAThis paper, revised in 2019, reviews recent advances in missing data research using graphical models to represent multivariate dependencies. machinelearning #datascience #artificialintelligence #AIhttps://arxiv.org/abs/1801.03583",,"Tooling,"
208,https://www.reddit.com/r/datascience/comments/dx2f9t/best_tool_for_etl/,dx2f9t,best_tool_for_etl,Heretic_Raw,1.0,3,2019-11-16 05:51:02,0,11,,"Hi all. So I’ve very recently started a job as a Big Data Engineer and my very first task is to do some research on the following tools for data integration and ETL (Spark, SSIS, Apache Nifi, Talend) and present to them team so we can decide which one to use for a project.My background is more to do with machine learning and maths so I was hoping someone here who has some relevant experience could shed some light on which of these tools they would use over the others and why?",,"Discussion,"
209,https://www.reddit.com/r/datascience/comments/dwugs0/artiba_artificial_intelligence_board_of_america/,dwugs0,artiba_artificial_intelligence_board_of_america,FourierEnvy,0.83,15,2019-11-15 19:05:10,0,9,,"Has anyone else heard of this new organization called the Artificial Intelligence Board of America?Here is a link for those curious: https://www.artiba.org/Has anyone taken the exam? Planning to take the exam? Or have any experience with them whatsoever?As a person in the industry and looking to find ways to differentiate in the job market for next year, I'm curious if this is a good path to take.Thanks for reading!",,"Discussion,"
210,https://www.reddit.com/r/datascience/comments/dwsg6q/this_website_offered_very_good_intuitive_idea/,dwsg6q,this_website_offered_very_good_intuitive_idea,dattud,0.76,19,2019-11-15 16:39:32,0,5,,,https://elitedatascience.com/primer,
211,https://www.reddit.com/r/datascience/comments/dwjowz/do_you_do_any_data_volunteer_work/,dwjowz,do_you_do_any_data_volunteer_work,PasghettiSquash,0.96,186,2019-11-15 02:52:12,0,52,,I just had a birthday and I guess I'm doing some mid-career reflection. I work at an F100 company and work mostly in sales analytics (I'm a little more on the business side and I still dont consider myself a data scientist but I'm not that far off).A few years back one of my teams did some volunteer work - I stood next to phD data scientists at a food bank as we took bananas out of their plastic wrapping and put them back in the boxes (guess they last longer?)  I couldn't help but think my team could've spent the same 4 hours doing actual analytics and helped the foodbank more.I'm wondering if theres opportunities to do actual data science work for a good cause? I know a lot of places have publically available data sets but I'm not sure that's what I have in mind either.Are there any options out there?,,"Discussion,"
212,https://www.reddit.com/r/datascience/comments/dwvlbw/a_lot_of_the_machine_learning_and_neural_network/,dwvlbw,a_lot_of_the_machine_learning_and_neural_network,gregoryg323,0.76,6,2019-11-15 20:27:52,0,11,,"A lot of the steps in building and training a model, tuning hyper parameters, etc. seems to be pretty standard across the board. Is there any big name or up and coming software that makes the whole process easier without having to code?",,"Discussion,"
213,https://www.reddit.com/r/datascience/comments/dwxagl/quit_well_paid_developer_job_in_order_to_pursue/,dwxagl,quit_well_paid_developer_job_in_order_to_pursue,Sargaxon,1.0,6,2019-11-15 22:33:54,0,6,,"I've been working as a backend developer for 2 years and I've known that I would like to steer my career towards data science since college, so I started going through some online courses and learning by myself - had a really high motivation to succeed. Everything looked interesting, but seemed like there's like a lot of things to digest. The reason I took this backend role is because they told me I would be slowly transitioning into data science after 6 months.2 years have passed and they are still promising me ""it's coming, but (insert some wait-for-it reason)"". After some time I found it hard to be programming 8 (sometimes more) hours daily and still have focus and motivation to go through courses or continue programming within working days, which left me only with weekends, but most of them I'm busy doing something else. Overtime I even forgot the things I've learned 2+ years ago.The thing is, I'm like really really well paid to be doing what I'm doing, have great working conditions and an understanding boss, nobody's pressuring me to work harder or faster. I have days where I just slack off or stay home ""working"" and so on, nobody will tell me anything. My living conditions are quite good - a nice apartment, everything I need, low rent, 15 minutes walk to work, no traffic etc.. The only downside is having a hard time finding like-minded people in this small town and all of my friends are in bigger cities.On the other hand, I'm not happy with what I'm doing at work and see no motivation to strive in this job. Since this was my first job, I'm not entirely sure if it's even the job which I find problematic, the lack of friendships, the boredom of a small city or is it just the 8hour work week which is draining me? I was thinking about quitting my job, moving back to my parents house and learning data science, doing some projects, with the hopes of landing a job somewhere, but there's so many variables I still don't know. I've always been interested in data science and would love to strive in this field, but I have uncertainties what if I'm not made for it, how will I get a job, how much effort will I need to put in and how long will it last, how will I handle my parents for a prolonged period of time etc etc.Should I quit my job and a lifestyle most people are looking up to pursue data science for which I might have more interest, ambition and motivation at this moment?",,"Career,"
214,https://www.reddit.com/r/datascience/comments/dx2bpj/where_will_you_work/,dx2bpj,where_will_you_work,MathAvenger,0.67,1,2019-11-16 05:40:49,0,6,,"I am a new undergraduate with a Data science degree, hoping to get a data scientist (but probably start with a data analyst first) job. But I am deciding where I should work. I currently have 3 choices: Canada, the US, or HongKong. What do you guys think? My personal opinion on this is:HongKong, it seems to be an international city with lots of Top companies. I feel like I can learn a lot in HK.The US seems to be the country where data science is the most popular and developed.Canada is where I am from, so... one of the choice. But I'm from Vancouver, I am willing to move to other places like Toronto.Any advices? Thanks in advance!",,"Career,"
215,https://www.reddit.com/r/datascience/comments/dx1n3z/what_to_do_about_a_small_and_unbalanced_dataset/,dx1n3z,what_to_do_about_a_small_and_unbalanced_dataset,conradws,0.6,1,2019-11-16 04:35:04,0,4,,"Just wanted to hear your thoughts on what approach you would use for a small ( and I mean really small)  dataset of 1500 examples with binary classes split 80-20. What worries me the most is that this means class 0 only has 300 examples whereas class 1 has over 1200.How would you tackle this? I was thinking about using the generative approach where you model the distribution for each class and then estimate the probabilitity of a new point belonging to one or the other ( after having multiplied by its class frequency) but I've only seen this been used for univariate and bivariate datasets, and I have around 50 - 100 variables in mine.Or is this situation as a whole completely hopeless?Looking forward to really your comments.",,
216,https://www.reddit.com/r/datascience/comments/dwu3dt/which_16_mbp_for_datascience_applications/,dwu3dt,which_16_mbp_for_datascience_applications,blkpingu,0.71,4,2019-11-15 18:37:45,0,31,,"The new 16"" brings a lot of things together I wanted to see from Apple and I'm looking to invest in it.I have a lot of pretty big datasets to analyse for my bachelors thesis and wanted to ask professionals what they would spec if they would buy one of the new 16""ers.I'm working mostly with Python (tensorflow / spacy etc)  and Scala ( mostly spark) tooling, so nothing crazy.I have access to clusters, but before training on the clusters I work out a proof of concept on my local machine, which is getting quite tiresome with an old 13"" late 2013 mbp. Even smaller datasets of 200mb take a 20 seconds to run through with spark it's adding up to a lot of wasted time.I saw it has an AMD chipset for graphics, which is unlucky, as most if not all ML stuff is done on nvidia chips.So I'm mostly interested in RAM and Processor related thoughts.Looking forward to your recommendations and I hope I'm allowed to ask this stuff here.Questions:Since numpy / tensorflow mostly run single core, does it make sense to go with the i7 or the i9? This is more or less the question i have no good answer for.Does more ram, meaning not going with default 16gb and in 32 or 64 gb make sense? I don't run a lot of vm's but that might or chance in the future because docker. I would tend towards 32gb, but I'd be interested in an experienced opinionIs 500gb fine or should one invest in a decent sized ssd as in 1tb. I mostly work with bigger datasets on clusters, so I would tend towards no.",,"Discussion,"
217,https://www.reddit.com/r/datascience/comments/dwppxh/best_books_for_understanding_linear_regression/,dwppxh,best_books_for_understanding_linear_regression,JuliusAvellar,0.83,13,2019-11-15 12:52:35,0,14,,"So I thought that I understood linear regression, you know, it's just Y = mX + B, right? Nothing complicated. [insert ML joke here] But, I actually want a more in depth understanding so I can to build the right model to show interaction effects. Does anyone have any recommendations for books that cover linear regression? Bonus points if the book has R code in it (hint: I'm an R user)",,
218,https://www.reddit.com/r/datascience/comments/dx0efy/new_usability_ratings_on_kaggle_datasets/,dx0efy,new_usability_ratings_on_kaggle_datasets,breck,1.0,1,2019-11-16 02:42:48,0,0,,,https://www.kaggle.com/product-feedback/93922,"Discussion,"
219,https://www.reddit.com/r/datascience/comments/dwuhfe/what_have_you_use_unsupervised_learning_models/,dwuhfe,what_have_you_use_unsupervised_learning_models,blinkOneEightyBewb,0.63,2,2019-11-15 19:06:24,0,19,,My impression is that these models are usually used for more exploratory analysis scenarios. Curious whether that’s correct,,"Discussion,"
220,https://www.reddit.com/r/datascience/comments/dww1la/all_the_research_papers_ive_read_in_the_past_2/,dww1la,all_the_research_papers_ive_read_in_the_past_2,bbennett36,0.5,0,2019-11-15 21:01:21,0,5,,,,"Education,"
221,https://www.reddit.com/r/datascience/comments/dwqq7f/study_buddies_and_mentoring/,dwqq7f,study_buddies_and_mentoring,GCProgrammer,0.62,3,2019-11-15 14:24:03,0,0,,"Do you want to be mentored in mathematics, programming or computer science? Ask questions, request exercises and submit code for feedback? Or do you want to mentor other people? 6 months ago we've set up a Discord community to fulfill your needs and we currently reached over 5.800 members! Note that this is not a paid service. https://discordapp.com/invite/aJwTAgS",,"Education,"
222,https://www.reddit.com/r/datascience/comments/dwv1i2/anyone_use_the_rtx_5000_quadro/,dwv1i2,anyone_use_the_rtx_5000_quadro,Zenith_N,0.67,1,2019-11-15 19:47:50,0,2,,"For machine learning and deep learning algorithms, I am looking at the thinkpad P53 as a personal mobile laptop for personal use and projects. I would like to also be able to game on the laptop. However, I have read that Quadro variants are not as powerful as their GTX counterparts when it comes to machine learning. Please let me know if I am approaching this the right way. Thank you",,"Discussion,"
223,https://www.reddit.com/r/datascience/comments/dwosqm/job_titles_for_people_with_experience_in_data/,dwosqm,job_titles_for_people_with_experience_in_data,johnsonfrusciante,0.84,4,2019-11-15 11:12:40,0,5,,"Hey guys, long story short, I'm very happy working as a Data Scientist in an interesting start-up but am eventually moving out of the country and will therefore need a new job.My issue is the following: even while recruiting people to work under me, Data Science positions are constantly asking for machine learning experience. I don't have any, and while I'm good at math and can quickly grasp concepts in different courses, I think I'm still highly valuable as I have a unique blend of management experience, Data Science experience (data cleaning, wrangling, visualizations, etc), and Data-Engineering experience (not with the creation of data-pipelines and database, but experience maintaining data-bases, debugging issues with builds, Airflow issues, etc), and a little experience in Django...Anyway my question for you: I feel like a pure Data Science position is not the title that best encapsulates this blend of work. What kind of job do you think I should look for given that I have more engineering and less statistical work than what I imagine most pure data scientists have? I feel I have a unique blend of experience that will be highly valuable, but don't want to waste time applying to the wrong jobs that don't need these strengths as much.Hopefully that's clear. Any advice would be much appreciated!!",,"Job Search,"
224,https://www.reddit.com/r/datascience/comments/dwayzg/how_are_ab_tests_performed_at_your_company/,dwayzg,how_are_ab_tests_performed_at_your_company,Quas_TheUnseen,0.99,125,2019-11-14 16:24:01,0,17,,"As a scientist, I understand experimentation. But now that I’m interested in data science, I’d like to know how experiments are done in industry. A few example questions:how are users identified/selectedhow do you determine the length?how do you deal with statistical power?do you write down all hypotheses and procedures in a shared document before it’s run?do you deploy the tests on a separate platform than your main workflow(s)Looking forward to hearing from you! Thanks",,
225,https://www.reddit.com/r/datascience/comments/dwophw/data_sharing_between_organisations/,dwophw,data_sharing_between_organisations,MrEnthusiasm,1.0,1,2019-11-15 11:03:12,0,9,,"What do people use to share data between organisations?I'm thinking:what companies might use internally and how that works for sharing data to contractorswhat data drop services freelancers use to receive data (Dropbox, S3 bucket, SaaS tools?)How these fare on security, ease of use, collaboration - any obvious pain points or advantages?Are people just emailing CSVs?",,"Tooling,"
226,https://www.reddit.com/r/datascience/comments/dw0ysp/xkcd_machine_learning_captcha/,dw0ysp,xkcd_machine_learning_captcha,rohan36,0.97,465,2019-11-14 01:08:24,0,12,,,https://www.xkcd.com/2228/,"Fun/Trivia,"
227,https://www.reddit.com/r/datascience/comments/dwo1ud/how_to_run_an_ab_test_with_different_designs_of_a/,dwo1ud,how_to_run_an_ab_test_with_different_designs_of_a,PM_ME_YOUR_TRAVELTIP,0.67,1,2019-11-15 09:50:03,0,3,,Are there tools for A/B testing that let you run a test for a specific part of the homepage while being able to alter other parts of it? I know this is not ideal. But how would you run A/B tests with different versions of the homepage of a website that still needs to be updated daily? E.g. news paper websites?,,
228,https://www.reddit.com/r/datascience/comments/dwnf70/working_with_http_in_polynote/,dwnf70,working_with_http_in_polynote,adamw1pl,0.5,0,2019-11-15 08:40:42,0,0,,,https://blog.softwaremill.com/working-with-http-in-polynote-d950dcfcd75f,"Tooling,"
229,https://www.reddit.com/r/datascience/comments/dwkbin/what_field_of_datascience_should_i_learn_for_this/,dwkbin,what_field_of_datascience_should_i_learn_for_this,yama_nemuru,0.76,2,2019-11-15 03:43:43,0,6,,"I got a training opportunity in a company. This company is just starting. They have some plans like creating a big database based on some open source existing databases in order to create a search engine in their niche. They are willing to start with this project in a few months, as it is not their priority right now.I am just starting in data-science (worked a little with pandas).Even though my lack of knowledge was obvious, we ended up having a nice interview. The boss told me that he is in no hurry and that he will give me a desk in the office to learn there on my own. So when the time comes and he is willing to hire a team I will be competent enough to be a part of it.I tried to know more about what exactly he needs but he doesn't really know himself and nobody in the company does because as I said he hasn't started yet his data project so he didn't hire anybody related to the issue.My question is what should I learn now? Is it Big data? data science? Python or SQL?I feel like this an interesting opportunity for me and I hope I won't miss it. And even if it didn't work out, in the end, I will still be learning a lot.",,"Career,"
230,https://www.reddit.com/r/datascience/comments/dwco7u/what_are_your_favorite_sales_kpis_to_use/,dwco7u,what_are_your_favorite_sales_kpis_to_use,mindlessmeaning,1.0,6,2019-11-14 18:23:23,0,10,,"Junior DS here and I'm doing some work for a company where they really don't know what they want to measure, but they've asked me to create a dashboard to track sales metrics, they've outlined a 1 or 2 but they're giving me some freedom to pick out what I think would be best to track.I've done some initial research and found stuff like RFM, churn analysis, average profit margin, but I'm just curious if anyone else has found some really interesting KPI's that they like to track?The tricky thing is this isn't an e-commerce based company, it's basically a software company that does contracts with other businesses, so most of the ones I'm finding aren't super useful.Are there any cool KPI's that you've used in the past that might be useful in this situation?",,"Projects,"
231,https://www.reddit.com/r/datascience/comments/dwcd5c/name_of_tool_for_interactive_data/,dwcd5c,name_of_tool_for_interactive_data,Oxbowerce,0.83,4,2019-11-14 18:03:12,0,10,,"Some days ago I stumbled upon a data visualization tool which allowed you to create a webpage with buttons and sliders, which in turn could update your visualizations. Unfortunately, I can't seem to remember the name of the tool anymore. What I do remember are the following points:It is a python library, allowing it to seemingly integrate with existing version control tools such as gitIt allowed for caching of the dataset so it would only have to rerun the actual code for the data processingWriting html/CSS for the interactive webpage was not necessaryAn example of its capabilities was shown using a dataset consisting of dash cam videos on which they used a YOLO classifier to classify cars/pedestrians etc.Hope someone can help me remember the name of the tool, thanks in advance for any suggestions you may have.Edit: It was not one of dash, plotly, or bokeh. Streamlit seems similar however does not seem to be the one I was thinking of. I'm pretty sure the website had a dark background and showed a graphic comparing the normal steps in the process of creating an interactive webpage (writing python code, writing html/css/js for the webpage and going through the whole pipeline vs a much more streamline process of only two steps, write python and run the webpage).",,
232,https://www.reddit.com/r/datascience/comments/dwh3pe/do_data_scientists_prefer_messy_data_to_missing/,dwh3pe,do_data_scientists_prefer_messy_data_to_missing,ed_elliott_,0.57,1,2019-11-14 23:33:45,0,5,,"Martin Fowler wrote about data lakes here: https://martinfowler.com/bliki/DataLake.htmlIn the article he says:“The data lake is schemaless, it's up to the source systems to decide what schema to use and for consumers to work out how to deal with the resulting chaos. Furthermore the source systems are free to change their inflow data schemas at will, and again the consumers have to cope. Obviously we prefer such changes to be as minimally disruptive as possible, but scientists prefer messy data to losing data.”Is this true? It seems to me that messy data and missing data are both pretty bad news??",,
233,https://www.reddit.com/r/datascience/comments/dwgkj9/starting_my_first_analytics_role_next_week/,dwgkj9,starting_my_first_analytics_role_next_week,germany221,0.44,0,2019-11-14 22:57:13,0,17,,"I will be starting my first analytics role next week and have a few questions mainly about setup:Are IDE's (PyCharm/Rstudio) usually already downloaded onto the companies PC?I am nervous about using a companies database. I know SQL syntax and have worked on the internal DB that comes with the MySQL download, but using a large scale company DB is a little intimidating. Any tips or videos for setup and best practices for learning the system? Also could I get some examples of things you should never do in SQL that could potentially delete data?Any other tips that you all use or wish you had done when you first start a job?EDIT: Why is this getting down voted so hard?? lol",,"Discussion,"
234,https://www.reddit.com/r/datascience/comments/dwfqe1/how_do_i_change_the_ensemble_size_in_weka_while/,dwfqe1,how_do_i_change_the_ensemble_size_in_weka_while,ihavefewq,0.57,1,2019-11-14 21:58:21,0,0,,,,"Discussion,"
235,https://www.reddit.com/r/datascience/comments/dwfo5f/have_you_experienced_much_difference_in_those_who/,dwfo5f,have_you_experienced_much_difference_in_those_who,poolguy8,0.33,0,2019-11-14 21:53:49,0,3,,,,"Education,"
236,https://www.reddit.com/r/datascience/comments/dwety2/how_to_find_which_features_are_most/,dwety2,how_to_find_which_features_are_most,wtfzambo,0.67,1,2019-11-14 20:54:19,0,3,,"Hello,I've been  trying to find this answer for a while, but almost everything I managed to find online are guides on how  to perform feature selection / dimensionality reduction. I'm looking for something else:The question is in the title, but I'll provide an example.Let's say I have a dataset of pets (cat, dog, bird, rabbit...) and a bunch of features describing each pet (e.g. weight, fur, length, etc..).All of them are already properly classified and I don't have to train a model for anything, but I wanna know per each kind of animal, which are the most representative features, example:""Hey what's the best way to tell a bird apart from the rest?""""Well feathers of course!""""And for cats?""""Claws!""I'm making these up but you get the point. Is there a way (via statistics / machine learning / whatnot) to get this kind of result?The only  thing that came to my mind so far is a Z-test between the class distribution and the whole population, per each feature. However, it seems impractical when a dataset contains a large number of features.Any input is greatly appreciated.---Side note: this question is language agnostic, but if you are aware of any python library that helps in performing this task, do let me know!",,"Discussion,"
237,https://www.reddit.com/r/datascience/comments/dweehz/how_could_i_interpret_this_histogram_how_can_i/,dweehz,how_could_i_interpret_this_histogram_how_can_i,Birab10,0.4,0,2019-11-14 20:24:03,0,9,,,,
238,https://www.reddit.com/r/datascience/comments/dvv4iz/best_ds_da_machine_learning_modeling_predictive/,dvv4iz,best_ds_da_machine_learning_modeling_predictive,will_riker,0.98,88,2019-11-13 18:34:17,0,28,,"I am looking to get your feedback into what you think the best stats/ DS/ DA/ machine learning/ modeling/ predictive modeling/ books might be.If you could only get one book that would be the most “bang for your buck” and give you as much depth and breadth into the field as possible, what would you choose?One that has come highly recommended was Kuhn’s “Applied Predictive Modeling”, but that appears to have been released in 2013, and I am concerned if it may perhaps be missing key developments from the last five years. Any thoughts on that book or others?Thanks for any feedback.",,
239,https://www.reddit.com/r/datascience/comments/dwcxlr/building_a_world_where_data_privacy_exists_online/,dwcxlr,building_a_world_where_data_privacy_exists_online,craigspencersmith,0.5,0,2019-11-14 18:40:59,0,0,,"Dawn Song, an expert in computer security and trustworthy artificial intelligence, is working on making that vision a reality.By Craig S. SmithNov. 10, 2019Data is valuable — something that companies like Facebook, Google and Amazon realized far earlier than most consumers did. But computer scientists have been working on alternative models, even as the public has grown weary of having their data used and abused.Dawn Song, a professor at the University of California, Berkeley, and one of the world’s foremost experts in computer security and trustworthy artificial intelligence, envisions a new paradigm in which people control their data and are compensated for its use by corporations. While there have been many proposals for such a system, Professor Song is one actually building the platform to make it a reality.“As we talk about data as the new oil, it’s particularly important to develop technologies that can utilize data in a privacy-preserving way,” Professor Song said recently from her San Francisco office with an expansive view of the bay.It is an unlikely trajectory for Professor Song, who grew up in Dalian, China, a seaport in the northeastern province of Liaoning. She is the daughter of two local civil servants with no background in computers. And while she was an exceptional student in high school, she dreamed of being a National Geographic-style nature photographer. One of her teachers, a mentor, gently dissuaded her.Her mother wanted her to study business and filled out an application on her behalf for a well-known business school. Then, shortly before the national college entrance exams, her mentor intervened again, convincing her mother that a brighter future lay ahead for her daughter in science. Professor Song applied instead to Tsinghua University, China’s top science university, to study physics. She went on to study physics at Cornell University but transferred to Carnegie Mellon University, where she received an M.S. in computer science before settling at Berkeley to finally finish her Ph.D. in computer science. By then, she was focused on computer security.Professor Song drew attention while still a graduate student at Berkeley with pioneering work that showed a machine-learning algorithm can infer what someone is typing from the timing of their keystrokes picked up by eavesdropping on a network. Since then, she has been at the forefront of trustworthy A.I., including improving the resilience of machine-learning models themselves, the recursive blocks of computer code that learn to recognize patterns in the data they consume.Machine-learning models, as amazing as they are at identifying everything from tumors in X-ray images to words in slurred speech, remain disturbingly easy to fool. Professor Song and her students were the first ones to demonstrate that computer-vision systems could be fooled into identifying a stop sign as a 40-miles-per-hour speed limit sign simply by applying a few innocuous stickers to the sign. Examples of these altered traffic signs have been on exhibit at London’s Science Museum.“Her work on the stop sign was among the first to craft adversarial examples in the physical domain rather than just manipulating image pixels on a computer,” said Battista Biggio, an assistant professor at Italy’s University of Cagliari and one of the first people to study the vulnerabilities of such systems.Professor Song, who has taught at Berkeley for a dozen years, has been working to develop techniques and systems that not only can provide security to computer systems, but also privacy. She envisions a world of secure networks where individuals control their personal data and even derive income from it. She compares the world today to a time in human history when people did not have a clear notion of property rights. Once those rights were institutionalized and protected, she notes, it helped revolutionize economies.She recently started a company, Oasis Labs, that is building a platform that can give people the ability to control their data and audit how it is used. She believes that once data is viewed as property, it can propel the global economy in ways unseen before. “New business models can be built on this,” she said.Data, of course, is not like a physical object. If a person gives a friend an apple, then someone else cannot have that apple. But data is different, with a property that scientists call nonrivalry. People can give (or sell) as many copies as they want.Most people give away their data, signing it over to companies by clicking “accept,” not even bothering to read the fine print. Either people online accept the terms and participate in the digital world or they unplug — something that is not really an option for anyone operating in the global economy. Fortunes were built on that data, enriching a handful of entrepreneurs.“Our data has never been more at risk, and our need for new kinds of robust privacy solutions has never been greater,” said Guy Zyskind, co-founder and chief executive of Enigma, another company building a decentralized private computation protocol.When people go online, data is collected and stored on centralized servers that are vulnerable to attack. But Professor Song and her colleagues believe that by marrying specialized computer chips and blockchain technology, they can build a system that provides greater scalability and privacy protection.Some computer chips — those in most cellphones, for example — already incorporate a secure zone, called a trusted execution environment, that protects software from most kinds of attack. Professor Song’s group is working on enhancing the security of those zones by building an open-source secure enclave, Keystone. Within the secure enclave, bits of computer code, called smart contracts, allow data owners to control who has access to their data and how it is used.“You can actually have the integrity that the blockchain ledger provides and also you can have privacy or confidentiality for the smart contract execution that’s provided by the secure enclave,” said Professor Song, who speaks rapidly as if rushing to keep pace with her thoughts. “No central server ever sees the data.”Oasis Labs has been building a platform to support enterprises and developers. They have begun a pilot with Nebula Genomics, a direct-to-consumer gene-sequencing company, that offers whole genome sequencing reports on ancestry, wellness, and genetic traits with weekly updates. Using Oasis Labs’ privacy-preserving tools, Nebula customers will retain full control and ownership over their genomic data, while enabling Nebula to run specific analysis on the data without exposing the underlying information.Another application, called Kara, a collaboration with Dr. Robert Chang at the Stanford University School of Medicine, gives eye patients the option to share retina scans and other medical data with researchers who use the data to train machine-learning models to recognize disease.Part of the Kara project is studying what kind of incentives patients will find meaningful in return for contributing their data for medical research.“Her approach is unique from other data aggregators,” Dr. Chang said. “This project is really asking the important question — who really owns the data?”Someday, Professor Song believes, people will have an individual revenue stream from their data. It may not be significant on a monthly or even annual basis, but the fees that accumulate over the course of a lifetime from companies using personal data could contribute to retirement savings, for example. Or revenue from groups of people could be used to fund particular causes. The unlocking of data, meanwhile, could lead to improved services for consumers.“Today, companies are taking users’ data and essentially using it as a product; they monetize it,” Professor Song said. “The world can be very different if this is turned around and users maintain control of the data and get revenue from it.”Craig S. Smith is a former correspondent for the Times and now hosts the podcast Eye on A.I.",,"Discussion,"
240,https://www.reddit.com/r/datascience/comments/dwbvis/automating_machine_learning_for_mobile_games/,dwbvis,automating_machine_learning_for_mobile_games,bweber,0.6,1,2019-11-14 17:30:26,0,0,,,https://www.gamasutra.com/blogs/BenWeber/20191114/353773/Automating_Machine_Learning_for_MobileGames.php,"Projects,"
241,https://www.reddit.com/r/datascience/comments/dw6gwv/question_about_nlp_and_feature_selection/,dw6gwv,question_about_nlp_and_feature_selection,TheNumberOneDuder,0.76,2,2019-11-14 09:13:30,0,7,,"I'm working on a simple NLP project which involves the bag of words model.Basically I have 10,000 sentences I'm trying to classify.I'd like to use PCA on this data set, but there are 30,000+ features! (i.e. 30,000 words used in the sentences). If I delete columns where 95% of the entries are 0, then it's brought down to 250 features.This seems much more manageable, but do you think it might negatively affect my model (i.e. some uncommon words might be crucial for classification?)thanks.",,"Projects,"
242,https://www.reddit.com/r/datascience/comments/dw36tt/uber_pricing_algorithm/,dw36tt,uber_pricing_algorithm,da_chosen1,0.72,3,2019-11-14 04:02:19,0,4,,"I got interested in Uber's pricing algorithm, and I'm curious, does anyone know what algorithm they use? More broadly, what type of algorithm is appropriate to match supply and demand.",,"Discussion,"
243,https://www.reddit.com/r/datascience/comments/dw7iuh/virtual_environments_project_setup_and/,dw7iuh,virtual_environments_project_setup_and,ipagera,0.6,1,2019-11-14 11:09:52,0,3,,"Hi guys,I wasn't sure if I should post this in r/python, r/learningpython or here, but I guess my question intertwines with all of them.How do you guys set up small projects? Especially whenever you have a small dataset that you have randomly found on Kaggle or Google Datasets and you simply want to explore a bit. Do you always set up a virtual environment for every project and is there a quicker option?I read about Cookiecutter in a book about Django and I was wondering - do any data scientists/analysts use this for project setup?Thank you :)From an aspiring data scientist.",,
244,https://www.reddit.com/r/datascience/comments/dw2iqs/tips_for_attracting_diverse_candidates_to_fang/,dw2iqs,tips_for_attracting_diverse_candidates_to_fang,manoflogos,0.56,2,2019-11-14 03:07:07,0,37,,"I posted a data science role recently for a FANG role, however I'm seeing that nearly 90% of applicants are indian/chinese males. I have nothing against those people but I would very much like to increase our diversity top of funnel before we start offering interviews.I'm wondering what would be the best way to reach out to diverse candidates and encourage them to apply? Are there any outreach groups that I should cross-post the position?",,
245,https://www.reddit.com/r/datascience/comments/dvv5bc/building_my_project_portfolio_what_are_good/,dvv5bc,building_my_project_portfolio_what_are_good,tu_ta_shinda,0.89,13,2019-11-13 18:35:53,0,4,,"Hello data scientist. I am starting a masters program in the spring and want to get a jump on my career by building out a non-school work project portfolio. I have decided to get pretty good at using census data. Does anyone have sites which are especially good examples of how to visualize census data particularly census tracts, counties, states, and other spatial data? I have found some on the census site like this one  https://datamapper.geo.census.gov/map.html  but don't have the knowledge to know what a best practice is when I see it. I know this is not google and I don't need the links as much as the links with a description of why the visualization is a good example of what I can build toward over the next few years",,"Career,"
246,https://www.reddit.com/r/datascience/comments/dvurg1/softwareprograms_used_by_businesses/,dvurg1,softwareprograms_used_by_businesses,ProfNesbitt,0.9,14,2019-11-13 18:09:26,0,8,,"So I’ve been a data analyst for 10 years now with two separate companies and having a case of you don’t know what you don’t know when it comes to what sort of software is used by data analysts. My work has mainly been in retail sales analysis (Sales, shipments, margins, at the item and store levels, summaries of what’s working and what’s not sort of things).So the software I do/have used is: Alteryx primarily for combining and merging large sets of data to clean the data and get it into formats I can work with primarily in excel. Tableau I worked with at my old job for data visualization to track promotions and sales for automated reporting for our sales reps. And primarily I use excel pivot tables and macros to prepare data summaries for my analysis and for presentations.So my current situation is all the analyst I work with use what they know (myself included) and we all use the same software and nothing new gets used that might be better because we don’t know about it until we learn about it from a conference, or see it in another presentation or just do independent research into it. But the problem I’m coming across is good sources to keep up to date with these sorts of things.So I thought I would come here and ask other data analysts, what software or programs do you use day to day in your job that helped out a lot when you started using them? And what specific thing does each program do well and/or struggle with? Is mainly a data management tool or a data analysis one?Sorry if this is the wrong place for these sorts of questions.",,
247,https://www.reddit.com/r/datascience/comments/dvq8hp/what_software_should_i_use_for_data_visualisation/,dvq8hp,what_software_should_i_use_for_data_visualisation,WaveyJP,0.87,33,2019-11-13 12:05:11,0,24,,"I just started university and i want to take a year in industry in my 3rd year (So two years from now) Ive spoken to out careers  team and they recommend starting to build up my CV now. Currently I know the basics of Python (self learnt) and java (which we use in school) and Ive been collecting my expenditure from my student loans using excel. Should i expand to using python/R? Id suspect that I should use R to do DataVis, but that would be adding a 3rd language and im not advanced in my first two.Also what kinds of things should i be using my spending data for? like what would impress an employer?Edit: Thanks to everyone who answered, Ive decided as many have suggested to stick with start Stick with python and implement Seaborn and other good libraries that i can find as well as eventually picking up tableau once Ive settled into that since it (allegedly) isn't as intensive as learning a new language like R, though hopefully ill be able to find time to try out everything here",,"Education,"
248,https://www.reddit.com/r/datascience/comments/dw4n0o/how_do_i_interpret_varimp_values/,dw4n0o,how_do_i_interpret_varimp_values,mrdlau,0.67,1,2019-11-14 06:08:45,0,2,,"suppose I'm doing a logistic regression model for ""buy/not buy.""  My independent variables could be for example:  occupation, salary, and location.  After I fit my model, and I do a varImp to look at the 'variable importance', an example of what I would get might look something like this:Location-Texas: 100Occupation-Janitor:  95salary-$54,000: 80and so on and so forth for a few more variablesWhat is varImp actually calculating? If ""Location-Texas: 100"" is at the top, then it's ""the most important"", but what is the context of ""most important""?  Is it most important in predicting the postiive class?  Is it most important because it's the largest chunk of my data?  Is it just more influential?  I dont know what varIMP actually is telling me about my features.",,"Education,"
249,https://www.reddit.com/r/datascience/comments/dvz8zo/whats_your_dailyweekly_report_method/,dvz8zo,whats_your_dailyweekly_report_method,Northstat,0.81,3,2019-11-13 23:07:26,0,4,,"Each day I need to summarize the work I've done in a sprint framework.  I need to list what I've done, what I plan to do the next day and if there was anything blocking me or challenges that came up.  I also, personally, find this helpful as I am constantly switching contexts as I work on various projects each day.  I have been just hiding the code cells of ipython notebooks and converting to latex or sometimes just through a bunch of screenshots with commentary into a word/google doc.  I feel there might be a better way.  What do you use?",,"Discussion,"
250,https://www.reddit.com/r/datascience/comments/dvzjie/getting_started_resources_with_metric_design/,dvzjie,getting_started_resources_with_metric_design,i_am_baldilocks,0.76,2,2019-11-13 23:26:55,0,2,,"Hey r/datascience,I'm John, a grad student studying data science.  We have a final class project, and our group has decided to work on developing a score to quantify the environmental impact of a business to help inform and guide consumer decisions toward environmentally friendly purchases.  The problem has its roots in metric / KPI creation and design.  I want to approach it from a rigorous perspective and tackle the problem with best practices in mind.Does anyone have advice on resources for better understanding metric creation that might help guide this project?  I don't really know where to start.Thanks in advance - I appreciate your feedback.",,"Projects,"
251,https://www.reddit.com/r/datascience/comments/dvvjgh/need_advice_on_how_to_display_data/,dvvjgh,need_advice_on_how_to_display_data,buffyarav,1.0,4,2019-11-13 19:03:05,0,11,,"I'm a full stack developer and I recently got approached to design everything for their site. I couldn't get any information on the best way to do this. My client needs to display all the processed data for his client. I want to know whats the best way to do this? Should I just store the data in db and query the data on page per page basis? Is there any performance difference between different db engines. React vs php? another note is once the end user logs in, there are mostly charts. They have the option to click on charts to get more detailed view or select a side menu link to view specific filtered data. Any input is helpful.",,"Projects,"
252,https://www.reddit.com/r/datascience/comments/dv7mdc/if_you_torture_the_data_long_enough_it_will/,dv7mdc,if_you_torture_the_data_long_enough_it_will,mk4rim,0.98,1057,2019-11-12 10:20:56,0,35,,,,"Fun/Trivia,"
253,https://www.reddit.com/r/datascience/comments/dvxhlp/stuck_how_do_i_go_about_determining_a_products/,dvxhlp,stuck_how_do_i_go_about_determining_a_products,Zhultaka,0.67,1,2019-11-13 21:11:26,0,3,,"Hello!I'm currently struggling with a project I have at work where I need to figure out how much our clients pay for each product they consumed. Unfortunately, within my industry, we do not have any set product prices, so this means that each client determines how much each product is worth and pays us accordingly. On top of this issue, we do not have access to cost information for producing each product, nor are we able to survey our clients to figure out how much they are willing to pay for each product. The only thing we have available data-wise is the amount they have paid us and the number of products they consumed in each product category for the period (Data Contains Zeros/Null Values). Additionally, we are unable to link up payment amounts with product consumption dates due to a lag.So my question is, how do I go about producing an a la carte pricing menu for each product using historical payment/consumption data? I have tried running the data through an XGBoost model to determine feature_importance and weighting, but I feel like there may be a better way. Any thoughts?",,"Projects,"
254,https://www.reddit.com/r/datascience/comments/dvtxrm/help_with_printing_dataframe_columnsrows_in_the/,dvtxrm,help_with_printing_dataframe_columnsrows_in_the,w_savage,0.67,3,2019-11-13 17:10:44,0,3,,"Like the title suggests, is there anyway to print a relatively small dataframe(columns/rows) into a table? Right now it prints just as text in the console and its not very nice looking. I've used the tabulate library to make things a little nicer, but I would like an actual chart/table. See my table below. Thanks for your help!",,"Projects,"
255,https://www.reddit.com/r/datascience/comments/dvo1ep/why_do_we_need_experimental_data/,dvo1ep,why_do_we_need_experimental_data,arcxtriy,0.91,9,2019-11-13 08:08:46,0,15,,"I am an engineer in a data science company working on price optimisation.Every year we look at the historical data, try to predict people's elasticities and based on the them we set the prices. The historical data is mostly observational.What I don't get is why our economists want to run price experiments each year, I.e. give a certain group our calculated price plus or minus x%?! Isn't observational data very good for our modeling task? By explicitly setting the prices we somehow run experiments, don't we? Moreover, separating people into ""randomized"" groups afterwards to measure the average treatment effects, should be possible in my eyes.Many thanks in advance!",,
256,https://www.reddit.com/r/datascience/comments/dvor77/classical_stats_and_ds_jobseeker/,dvor77,classical_stats_and_ds_jobseeker,ice_shadow,0.86,5,2019-11-13 09:24:42,0,11,,"So I am primarily a classical biostatistician. Stuff like MLEs, bootstrap, GLMs, time series and hyp testing is right up my alley.However I am having trouble getting a job. Im in my final year of MS. My program normally does not have heavy programming emphasis. I feel I am at a huge disadvantage. However, I know R pretty well but nothing object oriented.I know next to nothing about Python, web scraping, APIs, data mining, SQL etc. Python and OOP drives me crazy. I am not too into that aspect of stats either. I like ML but still the mostly classical oriented parts like regularization, discriminant analysis, etc. Don’t really know how to make my own algorithms and stuff.I still want to be on the classical stats side of things but is my lack of CSey skills and DS knowledge holding me back?Where do I start if I am from the classical side and not good with Python, just to learn the bare minimum of DS that is expected for classical statisticians.I’m also still new to the field of stats and have no experience at all. Can’t do internships as most need you to be continuing in school. 0 experience whatsoever in fact in the work world. Basically i’ll be a fresh biostat MS grad without experience besides applied stats research.",,"Career,"
257,https://www.reddit.com/r/datascience/comments/dvg914/google_is_the_master_of_getting_free_training_data/,dvg914,google_is_the_master_of_getting_free_training_data,NazihKalo,0.92,30,2019-11-12 21:59:02,0,3,,"Google just one upped their reCaptcha source of training data with the Teachable Machine 2.0.It's basically creating transfer learned classifiers for you, no coding required. After training the model to classify images, audio you can export the model for direct implementation. However, the real achievement here is Google finding a new way to get free training data.Video Showcasing it:https://www.youtube.com/watch?v=T2qQGqZxkD0Here's the link to the product:https://g.co/teachablemachine",,"Discussion,"
258,https://www.reddit.com/r/datascience/comments/dvmifi/how_do_you_find_a_project/,dvmifi,how_do_you_find_a_project,chancedare,0.82,7,2019-11-13 05:40:45,0,5,,"I am am decently new to Data Science, and would love to find a fun pet project for my portfolio. However, I am having an extremely hard time finding something that I would be interested in and would have good portfolio impacts. What do you generally do when you want to find something to work on?",,"Projects,"
259,https://www.reddit.com/r/datascience/comments/dvrx0w/job_search_gone_cold/,dvrx0w,job_search_gone_cold,[deleted],0.57,1,2019-11-13 14:41:15,0,14,,"Hi redditors. I have been looking for a new job since about June. Initially I did all steps. Redid my cv. I got many many interviews. And currently I received a contract of 6 months. I am yet to join. Doing paperwork and gathering documents etc.Though I have not slowed down because I am trying to get a job in UK and getting visa sponsor is hard. So I am still hoping to do interviews and work on next plans.Sadly, using same cv but the amount of response in terms of calls and interviews has gone cold. I have no interviews lined up as opposed to 3 months ago when I used to do multiple interviews most days of the week. I don't know what's wrong. I am applying jobs the same way, same websites, even doing heavy networking on Linkedin.I would like to ask your advice on what I can do better. P. S. I am a data scientist. Looming for entry level jobs.",,"Job Search,"
260,https://www.reddit.com/r/datascience/comments/dvqjse/dataset_based_project/,dvqjse,dataset_based_project,astred121,0.33,0,2019-11-13 12:39:40,0,1,,"Hey guys, As a university project we were asked to build any software/app that will be getting its information from datasets, i tried thinking of something cool that i could be even developing it after the end of the project but i still can’t find something interesting, any cool ideas  ?",,
261,https://www.reddit.com/r/datascience/comments/dvt94y/need_an_experienced_data_scientist_or_related_to/,dvt94y,need_an_experienced_data_scientist_or_related_to,-ActionCat-,0.38,0,2019-11-13 16:23:17,0,3,,"I'm currently in my first year of college and I am required to write a short paper based on these questions answered by someone in the career I am planning on going into. If anyone would be willing to answer some questions about their career, it would be greatly appreciated.Questions:-What is your exact job title?-How long have you been in this career?-What education did you have to prepare you for your career?-How did you begin your career after receiving this education?-How many hours do you typically work in a week?-What is a typical day like for you?-What do you like and dislike about your work?-Do you continue to study more about this field to stay up-to-date? If so, how?-If you could start over, what, if anything, would you change about your career path?-How can newcomers establish themselves in a career that is being flooded by new graduates?-Finally, do you have any other advice for aspiring data scientists?",,"Career,"
262,https://www.reddit.com/r/datascience/comments/dvm4bs/an_article_about_the_social_impect_of_ai_written/,dvm4bs,an_article_about_the_social_impect_of_ai_written,LimarcAmbalina,1.0,4,2019-11-13 05:05:25,0,2,,,https://lionbridge.ai/articles/this-entire-article-was-written-by-an-ai-open-ai-gpt2/,"Discussion,"
263,https://www.reddit.com/r/datascience/comments/dvfff4/getting_further_in_your_career_why_relationships/,dvfff4,getting_further_in_your_career_why_relationships,dfphd,0.84,15,2019-11-12 21:03:45,0,10,,"I was listening to a podcast today, and they had a throwback episode to their first episode, aptly titled Solution to a Stalled Technical Career (disclaimer: I am in no way affiliated with this podcast).There are certainly many valuable insights in this podcast, and I highly recommend everyone listen to it, but there was one specific element of it that really hit home for me - especially looking back earlier in my career:When you are hired, you are primarily evaluated based on your technical skills. You get rewarded, reprimanded, yelled at, praised, etc., based on your ability to do the technical aspect of your work. And because of that, especially in technical roles, people start believing that it is their technical ability that will always get them promoted - even in latter stages of their career.The reality is that after your first promotion (from DS into something like a Lead DS or Senior DS role), the rest of your promotions are going to overwhelmingly be driven by relationships.Now, the more cynical people may hear that and dismiss it as how getting promoted is all about politics and about brown-nosing. The reality is much less depressing - and quite a bit more practical: relationships are how things get done in an organization. Without relationships, every initiative will die a quick, quiet death in its creator's desk. So as an employee, your ability to drive successful initiatives is directly tied to the relationships you are able to foster. And that ability will grow as you have relationships that are broader, stronger, and with more powerful people.So when organizations promote people who have built those relationships over those who haven't, what they are saying is ""I am going to promote people who will help the organization get stuff done"". And the higher up in the organization you are, the more likely it is that your ability to drive value for the organization will be measured by the scope and reach of your influence - which is basically your portfolio of relationships.For the record - relationships do not have to be friendships. These are working relationships - these are the people with which you have established a common ground that allows you to accelerate collaboration by anchoring on a layer of shared trust. How you build that can vary greatly - with some people it may require getting to know them personally, with others it may be purely a matter of convincing them that your work ethic matches theirs.(PS: The podcast also covers some great advice on behaviors that people can exercise to help build relationships - surprisingly simple, but in my opinion very accurate)",,
264,https://www.reddit.com/r/datascience/comments/dva3wn/why_i_dont_let_colleagues_and_bosses_say_that/,dva3wn,why_i_dont_let_colleagues_and_bosses_say_that,atruetoe,0.88,41,2019-11-12 14:40:13,0,6,,"Because it risks undermining my team's credibility when they have to come back and say that, in fact, the task will likely not be easy/simple.Because if it was, then you could do it yourself, or more likely, it would already be done.Because what looks simple (read: elegant) in the end is almost always because of quality work, not easy tasks.Because it unnecessarily makes expectations management harder.Because other people's jobs almost always look easier than they actually are.",,"Discussion,"
265,https://www.reddit.com/r/datascience/comments/dvoz1i/as_a_life_science_phd_what_should_i_be_focusing/,dvoz1i,as_a_life_science_phd_what_should_i_be_focusing,Pancake_on_toast,0.57,1,2019-11-13 09:48:46,0,4,,"Hi all,I am currently in the final year of my PhD. I am a structural biologist. My project is using cryo-electron microscopy to understand viral infection. This involves a huge amount of data processing. A chapter of my results will be on Python code I have written that uses Numpy, Pandas, Matplotlib and Math to model my viral proteins as vectors and calculate their flexibility according to lots of euler angles from an alignment program (can explain in more detail if needed but basically I have self taught myself python).Due to other projects and the need for file management of these huge datasets I have also taught myself Bash (i work in a terminal all the time anyway so this wasnt a big jump) and MATLAB.All of this is self taught and so my experience and knowledge is a bit all over the place and I have only learnt it as I have needed it type thing.I am looking at transitioning into data science after my PhD. I was wondering what you guys recommend for someone that has self-taught in a bit of a haphazard way. What have i likely just completely missed that I really should know?A big black hole in my CV at current is machine learning. I have done the tensorflow tutorials in python but that feels a bit like I am just jumping in the deep end. Is there a good lecture series for machine learning including just explaining basic terminology?Thanks for all your advice I really appreciate it. Just a panicking PhD student that doesn't feel good enough :).",,"Career,"
266,https://www.reddit.com/r/datascience/comments/dvb23e/dtplyr_hits_10_milestone_huge_update_for_people/,dvb23e,dtplyr_hits_10_milestone_huge_update_for_people,mertag770,0.91,16,2019-11-12 15:56:50,0,4,,,https://github.com/tidyverse/dtplyr/releases/tag/v1.0.0,"Tooling,"
267,https://www.reddit.com/r/rstats/comments/dvarjd/dtplyr_hits_10_milestone_huge_update_for_people/,dvarjd,dtplyr_hits_10_milestone_huge_update_for_people,TrueBirch,0.98,154,2019-11-12 15:34:04,0,69,,,https://github.com/tidyverse/dtplyr/releases/tag/v1.0.0,
268,https://www.reddit.com/r/datascience/comments/dv9mcl/whats_the_ugliesthackiestmost_unconventional/,dv9mcl,whats_the_ugliesthackiestmost_unconventional,vogt4nick,0.85,9,2019-11-12 13:57:18,0,9,,Title.,,"Discussion,"
269,https://www.reddit.com/r/datascience/comments/dv0njh/books_that_you_keep_going_back_to_or_read_on_the/,dv0njh,books_that_you_keep_going_back_to_or_read_on_the,SquareCurvesStudio,0.96,92,2019-11-12 00:04:34,0,37,,"To clarify, I'm wondering about any (unorthodox) books you personally find yourself going back to that relates in any way to the data science realm, except directly. Essentially, less of the technical and ""how-to"" kind of books, but more of something that opens your mind, changes/challenges your current perspective, makes you think outside-of-the-box, etc. I need something that's not really technical, as I have the books, pdf's, etc. that I found in the wiki and whatnot. But more importantly, it's because this would be a read during my commutes or on a plane, etc. where I wouldn't be complimenting it with any technology like a laptop or phone to reference some of the processes, functions, terminology, etc. So somewhat of an easy read, but also something that holds continuous value, in your opinion. Something that might not even be seen as a ""data science"" book, but has regardless, helped you in some way in the field.",,"Education,"
270,https://www.reddit.com/r/datascience/comments/dv94so/any_new_approaches_to_causal_inference_in_time/,dv94so,any_new_approaches_to_causal_inference_in_time,shaypal5,0.67,4,2019-11-12 13:11:08,0,0,,"Hey people, :)I've been really interested in the topic of causal inference in time series data the last year or so. I feel like I've surveyed most statistical approaches to the problem, and also new approaches coming from fields like chaos and information theory (this is also apparent in a literature review-y blog post I wrote about the topic).I did not, however, dig deep enough into ideas coming at this problem - specifically on time series data - from the field of machine learning, and so I'd love to hear about any you know about. This is especially interesting to me because of the complicated relation between predicators and causal drivers has gotten more attention in ML in recent years, I think.I can add a few contributions coming from ML to this problem in the context of non-temporal data:Judea Pearl, who is a prominent researcher in the field and who has developed the structural approach to casual inference, recently wrote a very interesting piece on causal inference tools and reflections on machine learning [Pearl, 2018]. He also wrote a thorough overview of the topic of causal inference [Pearl, 2009].David Lopez-Paz, a research scientist at Facebook AI Research, leads very interesting research on casual inference in general, and in the context of learning frameworks and deep learning specifically. Highlights include posing causal inference as a learning problem (specifically of classifying probability distributions), causal generative neural networks, incorporation of an adversarial framework for causal discovery and discovering causal signals in images.Krzysztof Chalupka has done some fascinating research in the intersection of deep learning and causal inference. Highlights include a deep-learning-based conditional independence test, causal feature learning, visual causal feature learning and causal regularization.Finally, [Dong et al. 2012] have used Multi-Step Granger Causality Method (MSGCM), a method developed to identify feedback loops embedded in biological networks using time-series experimental measurements, for the identification of feedback loops in neural networks.I would love your input!Shay",,"Discussion,"
271,https://www.reddit.com/r/datascience/comments/dve2wp/how_to_enter_the_field_of_football_analytics/,dve2wp,how_to_enter_the_field_of_football_analytics,Lockhartsaint,0.5,0,2019-11-12 19:30:56,0,16,,"Before I start, I would like to apologize if this isn't the correct subreddit to post this in. I didn't find any other suitable subreddits for this query.To begin with, let me paint a picture of who I am. I'm currently pursuing my Masters in EPITA, Paris in the field of Data Science and Analytics. I've been a fan of this sport since I was 12 years old, which is 13 odd years ago. Lately, I've been reading more and studying more about the sport; smaller nuances like in-depth tactics, analytical parameters and so on.In the dream of combining my passion for Data Science and Football, I've decided to get into Football Analytics. I would love to work for clubs or sports firms where I can helpUnfortunately, my college only allows me to take an internship position inside France because of my amateur French level. And I can't seem to find any information of which clubs in the Ligue 1 or so use Analytics and where and how can I apply for such positions.So far, I plan to send these football clubs an email with a cover letter and resume attached, but I'm not sure how effective this would be. I can't seem to find any concrete information on Football Analytics in France. So if anyone here knows how to or knows anyone who is in this field, I would love to get in touch with them.On the other hand, I'm currently doing to projects on my own. One is related to FPL and the other is related to transfers from 00/01 till 18/19 season. If anyone is interested, I'm open to discussions about them.PM me if you have any information regarding this or just want to talk about Football.tl;dr: I'm currently studying in Paris and I would like to know how to enter the field of Football Analytics in France.",,"Career,"
272,https://www.reddit.com/r/datascience/comments/dvcow1/webinar_on_open_source_for_data_science_and/,dvcow1,webinar_on_open_source_for_data_science_and,castanan2,0.5,0,2019-11-12 17:55:33,0,0,,,https://ibm.co/Register-Session1,"Discussion,"
273,https://www.reddit.com/r/datascience/comments/duyl3e/hows_ds_in_a_hospital_setting/,duyl3e,hows_ds_in_a_hospital_setting,monkeyunited,0.91,32,2019-11-11 21:39:16,0,31,,"Currently 2 years in healthcare consulting. Our clients are insurance companies so the nature of work is a lot more business-oriented. While this indirectly means patient health outcome is important to us, it rarely is the main focus of our work.I'm curious if I would have more impact to individuals if working in a hospital setting. I'm thinking works like readmission analysis, building database for health outcome (after X procedures, with Y drugs prescribed, how does Z measure changes through time...etc.), predicting health outcome for interventions, or even ad targeting for high suspect of certain type of conditions...etc. type of work. The problem is, I'm not sure if hospitals are hiring to do these types of projects.For those of you who work in hospital settings, what are your typical projects and which part of the hospital process do you play in?Edit: super appreciate all the responses. Definitely learned a lot and need some time to digest all the comments.",,"Career,"
274,https://www.reddit.com/r/datascience/comments/dvadcn/study_design_to_estimate_the_effects_of_several/,dvadcn,study_design_to_estimate_the_effects_of_several,cdlm89,0.67,1,2019-11-12 15:02:33,0,0,,"I have been tasked with designing a study for our sales team to estimate how different factors impact the success of prospects converting to the first stage of our sales pipeline. To provide some context, we are interested in reaching out to prospects to sell them something related to an “event” which we have an event date for.Concretely, we believe that there are at least four factors that will effect the probability of a prospect converting to stage one of our pipeline:Time until event (in months)Event monthState / provinceNumber of people attending the eventI say at least because these are the only factors that we have data for. Furthermore, the data are noisy and we cannot guarantee that the values of the factors are all correct. We can, however, estimate data quality by manually evaluating a random sample of the data and use Bayesian methods to quantify uncertainty in our accuracy estimates, but I’m not sure how we could incorporate this into the analysis (below).The motivation of this study is exploratory rather than confirmatory since we are not looking to estimate a treatment effect or validate a hypothesis - we “simply” want to model the conversion probability to estimate the effects of different factors on it, using the results of the model to rank prospects based on these factors. I can control which prospects are assigned to which salespeople so the study is in a sense experimental, with the measurement / experimental units being the prospect and the blocking factor being the salespeople (to control for experience and skill). I plan to randomly assign units to blocking factors using stratified sampling on event month since these events are seasonal - making the design a RCBD.I believe a multiple logistic regression or decision tree model would be appropriate for in this context. Ultimately, we would like to assess the impact of these factors on conversion probability to other stages of the pipeline with the final stage being the acquisition of new business, which I believe should be straightforward to do.Given the business constraints, I am able to to collect data over the course of 1-2 months, with our sales team contacting 200 prospects per month for an upper bound of n=400. There are likely to be other sources of bias / confounders such as:Previous exposure to our company and product offering (can control with adding this as an IV in our model though it will likely be corrected with the state / province)Non-response bias (what if we can’t get through to the prospects or the prospects are no longer in business?)Selection bias (we are only reaching out to prospects for which we have complete information for w.r.t. the 4 factors listed above)I would appreciate if anyone could provide me with some feedback on:Whether this RCDB is sufficient to estimate the effect of the factorsWhether the results are generalizable to other stages of the pipelineWhether or not these sources of bias are of sufficient concern and how I could address themThank you for any feedback / pointers to literature that you can provide!",https://www.reddit.com/r/statistics/comments/dva8f3/q_d_study_design_to_estimate_the_effects_of/,"Discussion,"
275,https://www.reddit.com/r/statistics/comments/dva8f3/q_d_study_design_to_estimate_the_effects_of/,dva8f3,q_d_study_design_to_estimate_the_effects_of,cdlm89,1.0,2,2019-11-12 14:51:04,0,0,,"I have been tasked with designing a study for our sales team to estimate how different factors impact the success of prospects converting to the first stage of our sales pipeline. To provide some context, we are interested in reaching out to prospects to sell them something related to an “event” which we have an event date for.Concretely, we believe that there are at least four factors that will effect the probability of a prospect converting to stage one of our pipeline:Time until event (in months)Event monthState / provinceNumber of people attending the eventI say at least because these are the only factors that we have data for. Furthermore, the data are noisy and we cannot guarantee that the values of the factors are all correct. We can, however, estimate data quality by manually evaluating a random sample of the data and use Bayesian methods to quantify uncertainty in our accuracy estimates, but I’m not sure how we could incorporate this into the analysis (below).The motivation of this study is exploratory rather than confirmatory since we are not looking to estimate a treatment effect or validate a hypothesis - we “simply” want to model the conversion probability to estimate the effects of different factors on it, using the results of the model to rank prospects based on these factors. I can control which prospects are assigned to which salespeople so the study is in a sense experimental, with the measurement / experimental units being the prospect and the blocking factor being the salespeople (to control for experience and skill). I plan to randomly assign units to blocking factors using stratified sampling on event month since these events are seasonal - making the design a RCBD.I believe a multiple logistic regression or decision tree model would be appropriate for in this context. Ultimately, we would like to assess the impact of these factors on conversion probability to other stages of the pipeline with the final stage being the acquisition of new business, which I believe should be straightforward to do.Given the business constraints, I am able to to collect data over the course of 1-2 months, with our sales team contacting 200 prospects per month for an upper bound of n=400. There are likely to be other sources of bias / confounders such as:Previous exposure to our company and product offering (can control with adding this as an IV in our model though it will likely be corrected with the state / province)Non-response bias (what if we can’t get through to the prospects or the prospects are no longer in business?)Selection bias (we are only reaching out to prospects for which we have complete information for w.r.t. the 4 factors listed above)I would appreciate if anyone could provide me with some feedback on:Whether this RCDB is sufficient to estimate the effect of the factorsWhether the results are generalizable to other stages of the pipelineWhether or not these sources of bias are of sufficient concern and how I could address themThank you for any feedback / pointers to literature that you can provide!",,"Discussion,"
276,https://www.reddit.com/r/datascience/comments/dv4o3f/good_freecheap_software/,dv4o3f,good_freecheap_software,HumanParaquat27,0.72,3,2019-11-12 05:10:42,0,4,,"What are the best programs I can use without paying a lot of money. Specifically I'm trying to find something that can blend data, run regressions, and some time series data. I'm also fairly amateur at this, if that's relevant. Is there anything that can help me or is this just wishful thinking?",,
277,https://www.reddit.com/r/datascience/comments/dudedh/ds_at_a_glance/,dudedh,ds_at_a_glance,Siba911,0.98,2023,2019-11-10 17:15:38,1,96,,,,"Fun/Trivia,"
278,https://www.reddit.com/r/datascience/comments/dv7ch6/tableau_vs_power_bi/,dv7ch6,tableau_vs_power_bi,ScandiSom,0.57,1,2019-11-12 09:48:53,0,14,,Pleas briefly state pros and cons according to your experience.,,"Discussion,"
279,https://www.reddit.com/r/datascience/comments/dv0a4n/productizing_analytics/,dv0a4n,productizing_analytics,coalcracker462,0.6,2,2019-11-11 23:37:55,0,2,,"As an Analytics Consultant, I'm constantly trying to think of other services to offer my clients instead of just working on glorified reporting projects.Beyond creating dashboards that can be repeated for multiple clients, are there any other analytic solutions that can be developed which can be easily 'productized'?Scalability is always tricky due to no two clients data never being the same, but this seems like an untapped area in our field.",,
280,https://www.reddit.com/r/datascience/comments/duzrsr/need_some_help_extracting_some_data_sort_of_a/,duzrsr,need_some_help_extracting_some_data_sort_of_a,Kuziel,0.67,1,2019-11-11 22:55:46,0,2,,"Hi guys, first time posting here so if it's the wrong sub let me know. I'm trying to work on a class project (video classification) using a 20bn dataset (here: https://20bn.com/datasets/jester/v1#download). I'm on Windows 10, trying to download and extract the data. The site says to use the following command ""cat 20bn-jester-v1-?? | tar zx"", and Powershell takes the command, but nothing happens. No error, and can't input any further commands. I thought maybe it would just take a long time, however I've waited about 10 minutes and nothing has happened. Any help/guidance would be greatly appreciated! Sorry for the horrible formatting ahead of time.",,
281,https://www.reddit.com/r/datascience/comments/dusw6e/searching_for_data/,dusw6e,searching_for_data,panon69,0.78,5,2019-11-11 15:11:09,0,11,,I am a looking to improve my data visualization skills. Any recommendations on where to find good data sets? Also I’m working with tableau to make visualizations (not sure if that changes anything).,,"Discussion,"
282,https://www.reddit.com/r/datascience/comments/duz2pc/getting_your_data_into_azure_a_data_explorer/,duz2pc,getting_your_data_into_azure_a_data_explorer,Daedalus90,0.33,0,2019-11-11 22:10:06,0,0,,,https://lastresortdev.com/2019/11/11/how-to-get-your-data-in-azure-data-explorer-for-dummies/,"Tooling,"
283,https://www.reddit.com/r/datascience/comments/duu38s/best_toolspractices_for_tracking_projectsissues/,duu38s,best_toolspractices_for_tracking_projectsissues,Omega037,1.0,1,2019-11-11 16:42:21,0,5,,"While my team has a system in place for tracking projects at the top level (i.e., portfolio for leadership), we don't have a standard system in place for tracking the sub-project details and issues.Right now, my personal tracking list is basically just Markdown a Jupyter notebook called Kanban Board, which is very simple but pretty lacking in terms of actual scheduling/tracking/sharing/visualizing.JIRA and Aha! are used by some of our dev teams, but I am not sure they are a good fit for Data Science work.  Alternatively, some teams in the business use SmartSheets or Microsoft Planner.  Or just really cumbersome, multi-sheet Excel files.",,
284,https://www.reddit.com/r/datascience/comments/dutk9m/ability_to_work_with_versioned_data_elle_woods/,dutk9m,ability_to_work_with_versioned_data_elle_woods,candleflame3,0.5,0,2019-11-11 16:03:41,0,3,,"I came across the line ""ability to work with versioned data"" as a one of the required competencies in a job ad.That ... didn't seem like a noteworthy ability at first glance, at least not to me.  Sounds like something that goes without saying for anyone with education and experience in data analysis.But what do I know.  So I googled around and found this general description of data versioning:https://library.stanford.edu/research/data-management-services/data-best-practices/data-versioningStill seems like a basic ""ability"" in the data analysis realm.Or am I missing some nuance?  Or is this just HR nonsense, throwing words into job ads that HR doesn't know the meaning of?The relevant Elle Woods line is here at 1:05:https://www.youtube.com/watch?v=rLcAQVgMTSY",,
285,https://www.reddit.com/r/datascience/comments/duqbad/extracting_data_from_scanned_documents/,duqbad,extracting_data_from_scanned_documents,selib,1.0,2,2019-11-11 10:56:32,0,4,,"Hey I was wondering if anyone has experience in extracting certain data from scanned documents. Such as addresses, named entities, contract duration, etc.I have been working with tesseract and some regex but I'm quickly reaching the limits of this approach I feel. What are some other approaches I could use for this task? (Note: The docuements are in German)",,
286,https://www.reddit.com/r/datascience/comments/dunkri/workflow_tools_for_model_pipelines/,dunkri,workflow_tools_for_model_pipelines,bweber,0.81,3,2019-11-11 06:03:43,0,0,,"I just published chapter 5 of ""Data Science in Production"". This is a lighter content chapter, so I wanted to share the majority of the text. The  omitted sections are only useful if you want to run managed cron or Airflow:https://medium.com/@bgweber/workflow-tools-for-model-pipelines-45030a93e9e0",,"Projects,"
287,https://www.reddit.com/r/datascience/comments/duqo2r/finding_hundreds_of_users_for_research_project/,duqo2r,finding_hundreds_of_users_for_research_project,FeldsparKnight,1.0,1,2019-11-11 11:35:09,0,7,,"I'm currently looking into conducting some machine learning research on Spotify data. Unfortunately there isn't a publicly available dataset, so I have to build my own.I'd have to build a small web app with a button that users click to authorise me to use certain bits of data (e.g. their favourite songs), as they have to consent.I'm confident I can get friends and family to participate in this, but my supervisor at uni recommended I get a hundred users if not more.Any ideas on where I might be able to find people that might participate, or online places I can share the link?EDIT: I'm looking to improve song recommendations using community detection or link prediction by mapping users and their libraries onto a graph and machine learning from it.",,
288,https://www.reddit.com/r/datascience/comments/ducfkc/would_a_health_data_science_msc_be_looked_at_as/,ducfkc,would_a_health_data_science_msc_be_looked_at_as,myobee,0.74,11,2019-11-10 15:59:45,0,17,,I’m a biochemistry graduate considering a health data science or bioinformatics masters degree as a bridge to get into data science. Would my masters degree hold up against applicants with a data science MSc?,,
289,https://www.reddit.com/r/datascience/comments/dumibf/what_types_of_isds_positions_are_currently/,dumibf,what_types_of_isds_positions_are_currently,Longboard4life246,0.67,1,2019-11-11 04:32:04,0,6,,can't seem to find too many and not sure what to search for. If anyone has articles or journals It'd be greatly appreciated.,,"Career,"
290,https://www.reddit.com/r/datascience/comments/dul3iy/survey_data_management/,dul3iy,survey_data_management,M5mtd,1.0,1,2019-11-11 02:40:35,0,4,,"I am Epi student who created a 70-question health survey which I will distribute later this semester or next. It is a paper survey and we estimate a sample size of 100-150. I need help in figuring out the the best system to use to keep track of the data  as it is  being collected. What are good systems? My first instinct is to create just a codebook and use excel, but I am wondering what else can be done, or how to do it more efficiently in Excel, or use this as a learning experience to discover other methods. I have a Mac, so I would prefer to use something besides Microsoft Access (I can run Windows on my Mac if needed ). I have access to SAS (I will use this for the primary statistical analysis), and have downloaded python and R, but I am not familiar with them, but I figure I could use this data to practice on them.  What are methods you have used in the past to manage and store survey data?",,"Projects,"
291,https://www.reddit.com/r/datascience/comments/duals9/weekly_entering_transitioning_thread_10_nov_2019/,duals9,weekly_entering_transitioning_thread_10_nov_2019,datascience-bot,0.78,9,2019-11-10 13:00:28,0,115,,"Bleep Bloop. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki. You can also search for past weekly threads.I am a bot created by the r/datascience moderators. I'm open source! You can review my source code on GitHub.",,"Discussion,"
292,https://www.reddit.com/r/datascience/comments/du1j0g/i_scraped_a_ton_of_data_from_a_popular_forum/,du1j0g,i_scraped_a_ton_of_data_from_a_popular_forum,SmartSpray,0.92,125,2019-11-09 21:50:13,0,46,,"To the best of my knowledge, this dataset doesn't exist yet. Also, I want to release my scraper cause why not. I think its a pretty good scraper and am proud of it :)I cross posted this on r/datasetshttps://www.reddit.com/r/datasets/comments/du525d/i_scraped_a_ton_of_data_from_a_popular_forum/EDIT: It doesn't look like I will be posting the data... I will consult my school's IP lawyer for one last ask. Stay updated on the scraper.",,"Discussion,"
293,https://www.reddit.com/r/datascience/comments/dufs8t/penalty_in_logistic_regression_possible/,dufs8t,penalty_in_logistic_regression_possible,failingstudent2,0.76,2,2019-11-10 20:11:03,0,8,,"Hi guys. Working on this dataset right now - https://www.kaggle.com/uciml/default-of-credit-card-clients-datasetBasically, the idea is to predict people that will default on loans. Right now, out of 30k rows, there is about 23k defaulters and 6k non-defaults.I'm training a logistic regression model in R, which gives me 81% of the bat, which I think is pretty okay. My plan moving forward is to create a better model through feature selection (p-values of original model) + ROC curve comparison.My question is that despite a high accuracy, my false negatives is pretty low. (ie. My model thinks this guy will pay back the loan, but he actually will not).Is there a way/hack to create a ""penalty"" of sorts to push my model towards having a lower accuracy (overall) but being better at predicting the false negatives?  (Or should I stick to playing around with thresholds?)",,"Projects,"
294,https://www.reddit.com/r/datascience/comments/duhzyy/transpose_table_by_expectation/,duhzyy,transpose_table_by_expectation,xyzabc123410000,1.0,1,2019-11-10 22:46:41,0,2,,Let's say there was a data set which had a column with a clothing item and another column which had price and another column with the store. And I needed to transpose this table by store. Would you put the store name along the top horizontal line of the table or would it go along the 1st column vertical?,,"Discussion,"
295,https://www.reddit.com/r/datascience/comments/duisux/which_visualization_to_choose/,duisux,which_visualization_to_choose,pm_me_n_wecantalk,0.25,0,2019-11-10 23:45:50,0,1,,"I am collecting bunch of data which may or may not give a specific data point. also each datapoint is independent from prevoius datapoint.so in such sitation where data point x is independent from data point x-1, what kind of visualization is the best?",,"Discussion,"
296,https://www.reddit.com/r/datascience/comments/dtu35r/what_is_the_future_of_data_science/,dtu35r,what_is_the_future_of_data_science,Sargaxon,0.89,98,2019-11-09 10:57:51,0,43,,"For example:What do you think, how will this field look like in the future?Will there be more job openings or less?How will it be paid?Will frameworks and libraries advance to a level where data science will not be a profession, but merely a skill?What will be expected of a data scientist?Which will be the dominating background field of knowledge (programmers, statisticians, mathematicians etc) for a data scientist?Which will be the essential skills of a data scientist?What will be some future new trends in data science?Or anything else what pops on your mind :)",,"Discussion,"
297,https://www.reddit.com/r/datascience/comments/du0vzk/data_science_project/,du0vzk,data_science_project,ironmagnesiumzinc,0.77,12,2019-11-09 21:00:26,0,11,,"I'm going to begin working on a final project for my data science masters over winter break and I've unfortunately never worked in the industry, so I don't know what employers/companies are looking for in graduates. What are some technologies/areas I could focus on that might look useful when I end up applying for jobs? To name a few: Docker, Graph Databases, APIs, machine learning, data mining, data organization.. which are most important?I'm thinking of creating a SQL database and API for my website. This might be ambitious though. Or maybe doing a Kaggle-type project could be good. Any ideas?Thanks!",,
298,https://www.reddit.com/r/datascience/comments/du8x85/project_for_cyber_security_company/,du8x85,project_for_cyber_security_company,xmagedo,0.67,1,2019-11-10 09:25:35,0,0,,"Hello guys, I have taking data science course for over a month now and I  eying one particular information cyber security company but I need to build an Api or project that can help me in the interview. Something tangible. Is there any suggestions or sample I can learn from? Something represent the security domain for beginner level if possible. I am learning Java spring boot and python for data science.Thank you",,"Discussion,"
299,https://www.reddit.com/r/datascience/comments/dty75m/inductive_vs_analytical_learning_symbolic_vs/,dty75m,inductive_vs_analytical_learning_symbolic_vs,dattud,0.8,8,2019-11-09 17:34:08,0,1,,"Can someone help me understand the difference. Based on my research, it seems like inductive, symbolic and concept learning seem to be similar? is that true? concept vs classification learning Symbolic vs statistical learning Inductive vs analytical learning",,
300,https://www.reddit.com/r/datascience/comments/du5as1/is_the_acap_certificate_worth_having/,du5as1,is_the_acap_certificate_worth_having,Hertigan,0.67,1,2019-11-10 02:56:31,0,1,,"I was looking for some certifications and CAP popped up, but I don't really meet the requirements to get it.Apparently there is an associate certificate for graduates (such as myself). I wanted to know if it makes any difference in the data science job market, or should I spend the $300 elsewhere?",,
301,https://www.reddit.com/r/datascience/comments/duc1uj/5_things_you_should_know_before_getting_into_data/,duc1uj,5_things_you_should_know_before_getting_into_data,weihong95,0.27,0,2019-11-10 15:25:28,0,7,,"According to the report from indeed, there is a 29% increase in demand for data scientists year over year.If you are one of the people who want to get into the hot industry - data science, I hope you can read this article.Therefore, you will know what is it like to become a data scientist before you are moving towards the direction.Link: https://towardsdatascience.com/5-things-you-should-know-before-getting-into-data-science-f4312f06ea73?source=friends_link&sk=cf37db26ff1f05af1069f42e99e728e6If you have other comments to add, feel free to comment below to let me know:)",,"Education,"
302,https://www.reddit.com/r/datascience/comments/du2uao/just_passed_microsofts_dp100_designing_and/,du2uao,just_passed_microsofts_dp100_designing_and,DS_throwitaway,0.53,1,2019-11-09 23:30:17,0,2,,"Title says it, just passed the exam (790/800) and earned the Certified Azure Data Scientist Associate. I spent about two days familiarizing myself with Azure as I had mainly used AWS previously. Exam felt fairly easy and balanced though it focused a lot on their ML Studio drag and drop product which I spent maybe 20 minutes looking at. There was a case study at the end with 5 questions. If you read the study it gives you the answers, just have to pay attention. There were 7 questions at the start that one you answered you couldn't go back or review which was awkward.",,
303,https://www.reddit.com/r/datascience/comments/dtgkck/does_regular_linear_or_logistic_regression_ever/,dtgkck,does_regular_linear_or_logistic_regression_ever,statistical_engineer,0.94,128,2019-11-08 15:59:52,0,98,,"In my couple of years of experience, I have only seen neural nets/deep learning and various tree ensemble methods in production.But I was wondering if simpler techniques are common?  With the kind of data that I come across, linear models are rarely successful.",,
304,https://www.reddit.com/r/datascience/comments/dtwnn3/is_it_possible_to_switch_career_from_sales/,dtwnn3,is_it_possible_to_switch_career_from_sales,lostonreddit9,0.64,3,2019-11-09 15:34:31,0,5,,"I am a graduate in electronics engineering and have been working as a sales service engineer in the electrical power industry for the past three years. I am thinking of a making a career switch to data analysis, please let me know if such a switch is possible and if yes what skills will I need to hone.Thank you",,
305,https://www.reddit.com/r/datascience/comments/dtp1rv/knime/,dtp1rv,knime,Stut8500,0.72,6,2019-11-09 02:07:26,0,16,,How many people use Knime for their pipelines and modeling/predicting?,,
306,https://www.reddit.com/r/datascience/comments/dt5eet/my_experience_of_6_data_science_interviews_in_the/,dt5eet,my_experience_of_6_data_science_interviews_in_the,Captain_Flashheart,0.98,289,2019-11-07 23:19:24,0,106,,"Months and months ago I was looking for a new job (and also fresh out of my masters) and wasn't quite sure on what to pick. I only did a few applications and most of them were to companies 2+ hours away. At the time I was planning to move regardless and the Utrecht/Amsterdam Area intrigued me. Here's my list, I hope this helps others. I included salary negotiation stuff, but bear in mind the payouts are meager compared to the US. All monetary amounts are in gross euros per month. I'm also keen to hear feedback.I posted this before on r/cscareerquestionsEU.Me: 4 internships (2.5ish years) + 1 year of experience as a software engineer/scientific programmer. BSc and MSc in CS.Company 1: Small Data Science consulting firm.I was referred by a friend. The interview was about 1 hour, with a consultant and an engineer. I got along great with the consultant, but not so much with the engineer who seemed hostile and did not read my resume - he started asking me questions about my current manager while I made it very clear I was currently finishing up my thesis (and didn't actually have one). They were growing out of their office, and simply couldn't afford anyone who could not directly be put on contracting. I did not get an offer. Questions they asked:Why did you change majors?What kind of projects have you done?Would you be willing to move into a data engineering role? (I said preferably not - shame on me)What kind of management style do you prefer?Company 2: Big Insurance / Bank.I connected well to both the recruiter and their main engineer. The PhD engineer was working from several hours away and was doing a lot of data engineering and devopsy engineering stuff and he basically needed a partner because he was the only engineer for their data science team. This was somewhat of a misrepresentation from the advert. Regardless it went well and they asked me for a salary indication- I asked for 3000/m. They felt this was too much and they were also not able to cover my train expenses (300-400 / month) to get to the office. The very nice recruiter mentioned they would have to offer it to the engineer too, who was travelling each day by his own means. I wasn't ready to drop my expectations for transport / salary so the decision to not move on was mutual.What kind of side projects have you done and are you working on (I showed them a side project for 5 mins)Company 3: Big Data Science Consulting firm.They immediately made it clear I could work for them but the offer was rather low (2650) however they have a very good lease deal and if I didn't like a car they also offered it as a flat pay-out, which would bump up that number to 3300 /month gross. I would be part of their data science team and could work for clients all over Europe so by far this would be the most interesting to start off my career. However, outside the car they had no scheme for public transport so I'd have to pay that out of my own pocket. I eventually received a second offer from them which was slightly higher, which I took.What kind of models have you worked on in school?What kind of work have you done for your last internship?What are your expectations of consulting?Company 4: Small Data Science consulting firm (direct competitor to #1).This remains the weirdest interview I have ever had. I was referred by two friends who independently also provided feedback and what my salary expectations should be (these kind of friends are nice). It turned out this company was actually two different companies, with a smaller one offering traineeships and a bigger one offering consulting services. The interviewer (also CEO of the traineeship) was blunt and hostile, and mentioned several times ""You should know this"", ""You listed your master on your profile and we've had others from the same university come by who knew it fine"",""I am only going to evaluate you for our traineeship because you don't have the skills to work as a consultant"", and ended with ""You don't have enough motivation to come and work here"". There were no coding or implementation-based questions. The interviewer was a guy coming from economics (I recall?) and had gained his DS knowledge from online course material. I left the building with a bit of a depressed feeling but also wondering wtf just happened. Questions:Why does Logistic Regression work well on NLP problems? (I explained, and then he said XGBoost was better and to use that instead - lol?)How does backprop work?How do SVMs work (once I started explaining I was interrupted and they said the question was too easy)How do ANNs workHow do CNNs workHow does gradient boosting workHow come you never finished your first bachelor?Do you regret switching majors?How many credits did you get in your first ever year at university (Honestly I couldn't recall, I gave them an estimate and said I didn't think this was relevant to the position)Company 5: Large online retailerI was referred by a friend and had a phone interview. That went fine and they gave me a salary indication afterwards: 3500/m. I then had to do a couple of IQ-style tests which took a couple of hours. Additionally, I had to work with a data set they provided and build a PoC or demonstrate my findings. I spent about 12 hours on this data science take-home test and really liked it. I went wild with lambda's.Finally I was invited to go on to their main office for four rounds of interviews. I was so excited that I didn't manage to sleep that night so you can imagine how that went.. for the first 2 rounds I passed my HR and engineering interview, but the last interview with two managers went worse. I still think I was pretty close to being let in and for about a week or so deliberated asking for another chance.Company 6: Big Consulting Firm (competitor of #3).I was referred by a friend who invited me over for coffee first. Within 24 hours a recruiter called me back and offered me a position as a Business Intelligence engineer, said they had a hiring freeze for their data science team but that they really liked my profile and were able to match #3 in salary (which was a joke anyway). I declined the offer.In all I have had mixed results. Small consulting firms are picky. Larger consulting firms are greedy. Glad I chose the company I did back in Spring, but the salary could be higher.",,"Job Search,"
307,https://www.reddit.com/r/datascience/comments/dtjuxp/i_wrote_a_python_framework_for_not_too_deep/,dtjuxp,i_wrote_a_python_framework_for_not_too_deep,Jdj8af,0.86,5,2019-11-08 19:52:09,0,0,,"Title says it all, just finished writing a framework for ""deep"" clustering based off of https://paperswithcode.com/paper/n2dnot-too-deep-clustering-via-clustering-the with the author's permission and help!DocumentationSource CodePypiWould love to have some feedback on how it could be made more useful!!",,
308,https://www.reddit.com/r/datascience/comments/dtm53k/my_idea_for_steps_required_to_automated_diagnosis/,dtm53k,my_idea_for_steps_required_to_automated_diagnosis,jim1564,0.4,0,2019-11-08 22:28:18,0,10,,"tl;dr: see this badly made diagramSteps:automate data gathering about someones health, so its cheap and fast enough for most people to do all of it periodically(like once a month), or at least most of it, bloodwork, scans, diseases already diagnosed, current treatments, etc, in specialized clinics built for this purpose of data gathering.This is the crucial step, if this is done, the rest will come more or less naturally. For this to be done, serious improvements in exam/tests automation are required, the less human work, the cheaper and faster, the better.everyone will slowly, increase their personal dataset with their health dataall of those personal datasets will feed into a huge central database with all the personal datasetsthis central database will be free and shared among researchers, obviously the data will be anonymized(things like person name, SSN etc will be removed) so the hit on privacy won't be as hugeThis will serve two purposes:The central dataset will be used by researchers using big data technology to generate PROPER science and understanding of the human body and diseases, with data-based models that actually predict disease behaviors with respectable accuracy. Current medicine models are pathetic, vague and hand wavy, because of lack of enough data to be analyzed.Using the insights and knowledge generated, those can be applied into the individual datasets, it would be possible to create end-user software that detects diseases and predicts future ones, then present treatments options or lifestyle choices in a user-friendly way, an obvious example: ""your chloresterol is a little high, that can turn into coronary heart disease in X years, please consider Y lifestyle changes and/or Z medication treatment"" This is an obvious example that most already know, but with the extensive coverage of the insights gained, a lot more obscure and unexpected interactions could be revealedThen doctors will be a lot less necessary, mostly for niche cases or giving the greenlight on the recommended actions by the software, until full blown software autonomy is viable.But again, the cheap full health data gathering is crucial, when this will be a reality nobody knows.Also, if theres already some research or material expanding on this idea, I would love to take a look.",,
309,https://www.reddit.com/r/datascience/comments/dtgoif/ai_and_climate_change_news/,dtgoif,ai_and_climate_change_news,craigspencersmith,0.54,1,2019-11-08 16:08:22,0,2,,"Friends, I'm a former NYT correspondent volunteering to help a group of scientists spread the word about their work. Read if you are interested:Scientists join forces to tackle climate change with AIA group of prominent scientists and engineers has released a sixty-page paper detailing how artificial intelligence can be used to fight climate change, as part of a broader initiative called Climate Change AI. The twenty-two person team includes some of the world’s leading AI and climate researchers, including Yoshua Bengio, winner of the 2019 Turing Award, and Felix Creutzig, a coordinating lead author of the United Nations’ IPCC Sixth Assessment Report.  After a preliminary announcement in June, the newly released paper is accompanied by graphics, interactive summaries, digital resources, and a discussion forum aimed at bringing together experts in AI and areas such as energy, agriculture, and disaster response.The paper focuses on machine learning, a powerful branch of artificial intelligence that can learn from data to find patterns and can optimize solutions much more quickly than humans. “Machine learning can be deployed to help reduce greenhouse gas emissions and build a society that is more resilient to climate change,” said David Rolnick, a postdoctoral fellow at the University of Pennsylvania and chair of Climate Change AI. “It can help design better batteries, control heating and cooling systems efficiently, track the effects of a changing climate using satellite imagery, and a lot more.”The authors emphasize that machine learning is only one piece of the puzzle, and that all applications require cooperation between many stakeholders. “Machine learning is not a silver bullet, but it can facilitate many climate change strategies from policy and engineering,” said Lynn Kaack, a postdoctoral researcher at ETH Zürich and co-chair of Climate Change AI. “It is important that machine learning experts work together with those who deeply understand the problems of climate change to make sure machine learning is applied where it can make a difference.”The Climate Change AI initiative was launched at a special workshop of the International Conference on Machine Learning, which brought together researchers, entrepreneurs, and investors from across the world. A series of similar events is planned, the next of which will be held in December at the leading AI conference Neural Information Processing Systems. “By serving as a nexus for collaboration between universities, companies, governments, and NGOs, we hope to empower meaningful work at the intersection of climate change and machine learning,” said Priya Donti, a PhD student at Carnegie Mellon University and co-chair of Climate Change AI. “We hope our work will inspire others to leverage their skills to tackle climate change -- we need all hands on deck.”For more information or to join the community, please visit the initiative’s website at www.climatechange.ai or contact David Rolnick at info@climatechange.ai.The paper “Tackling Climate Change with Machine Learning” was co-authored by David Rolnick, Priya L. Donti, Lynn H. Kaack, Kelly Kochanski, Alexandre Lacoste, Kris Sankaran, Andrew Slavin Ross, Nikola Milojevic-Dupont, Natasha Jaques, Anna Waldman-Brown, Alexandra Luccioni, Tegan Maharaj, Evan D. Sherwin, S. Karthik Mukkavilli, Konrad P. Kording, Carla Gomes, Andrew Y. Ng, Demis Hassabis, John C. Platt, Felix Creutzig, Jennifer Chayes, and Yoshua Bengio, and is available online at www.arxiv.org/abs/1906.05433.",https://www.reddit.com/user/craigspencersmith/comments/dsxtmc/ai_and_climate_change_news/,"Projects,"
310,https://www.reddit.com/user/craigspencersmith/comments/dsxtmc/ai_and_climate_change_news/,dsxtmc,ai_and_climate_change_news,craigspencersmith,0.75,4,2019-11-07 14:37:15,0,1,,"Friends, I'm a former NYT correspondent volunteering to help a group of scientists spread the word about their work. Read if you are interested:Scientists join forces to tackle climate change with AIA group of prominent scientists and engineers has released a sixty-page paper detailing how artificial intelligence can be used to fight climate change, as part of a broader initiative called Climate Change AI. The twenty-two person team includes some of the world’s leading AI and climate researchers, including Yoshua Bengio, winner of the 2019 Turing Award, and Felix Creutzig, a coordinating lead author of the United Nations’ IPCC Sixth Assessment Report.  After a preliminary announcement in June, the newly released paper is accompanied by graphics, interactive summaries, digital resources, and a discussion forum aimed at bringing together experts in AI and areas such as energy, agriculture, and disaster response.The paper focuses on machine learning, a powerful branch of artificial intelligence that can learn from data to find patterns and can optimize solutions much more quickly than humans. “Machine learning can be deployed to help reduce greenhouse gas emissions and build a society that is more resilient to climate change,” said David Rolnick, a postdoctoral fellow at the University of Pennsylvania and chair of Climate Change AI. “It can help design better batteries, control heating and cooling systems efficiently, track the effects of a changing climate using satellite imagery, and a lot more.”The authors emphasize that machine learning is only one piece of the puzzle, and that all applications require cooperation between many stakeholders. “Machine learning is not a silver bullet, but it can facilitate many climate change strategies from policy and engineering,” said Lynn Kaack, a postdoctoral researcher at ETH Zürich and co-chair of Climate Change AI. “It is important that machine learning experts work together with those who deeply understand the problems of climate change to make sure machine learning is applied where it can make a difference.”The Climate Change AI initiative was launched at a special workshop of the International Conference on Machine Learning, which brought together researchers, entrepreneurs, and investors from across the world. A series of similar events is planned, the next of which will be held in December at the leading AI conference Neural Information Processing Systems. “By serving as a nexus for collaboration between universities, companies, governments, and NGOs, we hope to empower meaningful work at the intersection of climate change and machine learning,” said Priya Donti, a PhD student at Carnegie Mellon University and co-chair of Climate Change AI. “We hope our work will inspire others to leverage their skills to tackle climate change -- we need all hands on deck.”For more information or to join the community, please visit the initiative’s website at www.climatechange.ai or contact David Rolnick at info@climatechange.ai.The paper “Tackling Climate Change with Machine Learning” was co-authored by David Rolnick, Priya L. Donti, Lynn H. Kaack, Kelly Kochanski, Alexandre Lacoste, Kris Sankaran, Andrew Slavin Ross, Nikola Milojevic-Dupont, Natasha Jaques, Anna Waldman-Brown, Alexandra Luccioni, Tegan Maharaj, Evan D. Sherwin, S. Karthik Mukkavilli, Konrad P. Kording, Carla Gomes, Andrew Y. Ng, Demis Hassabis, John C. Platt, Felix Creutzig, Jennifer Chayes, and Yoshua Bengio, and is available online at www.arxiv.org/abs/1906.05433.",,
311,https://www.reddit.com/r/datascience/comments/dtchve/workflow_progress_document_to_integrate_data/,dtchve,workflow_progress_document_to_integrate_data,NumesSanguis,0.81,3,2019-11-08 09:27:01,0,3,,"TL;DR: What is the best approach to keep an interactive document with the progress of a data science project? A Word / LibreOffice Writer turned fillable PDF? Webpage form? Other?A ML model that solves a problem no business needs is useless, therefore good communication between client-consultancy-data scientist is necessary.Working as a Data Scientist in a small startup, I want to streamline the communication between us and the consultancy team. The consultancy team interacts with different companies to understand their business needs and come-up with a data-driven product or insights. We as data scientist need to give feedback of what would be a plausible solution and develop those if the project continues.I want to keep a document per data science project that tracks the business insights the consultancy team gained (client's KPIs, problem statements, etc) and where the data specifics are written down (labels available, file formats, etc). Basically a central document that keeps track of the project's development accessible by both us and consultancy (less technically skilled).The workflow document would be filled in progressively as the projects moves on. Roughly my idea is to have sections like:Stuff that consultancy has to ask the client (data labels etc) and their business problem.Data Science considers which (proxy) variables a ML model could be trained for and what constraints the model would have.Consultancy determines if such (a) model(s) would give enough business value at what True Positive, FP, TN, FN rates and whether the client can live with the model constraints.Checklist before moving to deployment?I want this document to be easy to fill-in and standardized (not freely written text). Ideas I have:The most straightforward solution I could think of is to add fillable fields / selectable boxes to a Word document and turn it into a PDF (requires paid Adobe PDF for the fillable fields) / LibreOffice (free and powerful, but kinda ugly: https://www.linuxuprising.com/2019/02/how-to-create-fillable-pdf-forms-with.html)+ Easy to edit for non-technical people- Hard to trigger some code (necessary?) / document automatically updated by code- Easy to have multiple copies of the same file if people download, edit, but not upload againWebpage that is designed to be printer-friendly. Could host on some internet connected server / cloud?+ A lot of flexibility in styling+ Data can be automatically stored in a database+ Editable from a browser- More technical skill needed. Cannot be edited by consultancy and few resources online how to create a form that can be converted in a .pdf.- More time consumingAny advice on what is the best way to have a shared progress document with both consultancy and data scientist as audience?Any recommendations on what to include in such status document?p.s. Got inspired by the book: ""Data Science for Business: What You Need to Know about Data Mining and Data-Analytic Thinking""",,"Discussion,"
312,https://www.reddit.com/r/datascience/comments/dtj0zi/unusual_data_science_problem/,dtj0zi,unusual_data_science_problem,hiback,0.4,0,2019-11-08 18:53:45,0,4,,"Hi guys, my school project team is working on an interesting problem, the dataset is something like we have a number of products and we have past data on what products were included from the test and what were excluded from the test.I am researching algorithms to predict what products should be selected and what should be avoided from the next test. I have looked upon a few and I think classifier chains may be useful for this type of problem, but I need some help from people here to point me in right direction.",,"Discussion,"
313,https://www.reddit.com/r/datascience/comments/dt2udu/awesome_experiences_as_a_data_scientist_on_upwork/,dt2udu,awesome_experiences_as_a_data_scientist_on_upwork,mct2011,0.9,30,2019-11-07 20:31:18,0,11,,"Hey Reddit! I wanted to get feedback on this before I put it somewhere with my name on it. What are your thoughts?I am a data scientist at a bigger internet company. I work full-time and get good money. At night, I get my laptop and work as a data science consultant on Upwork. I love what I do, and since my day job pays all my bills, I could do it for almost free. In this article, I explain why I do it and why I would recommend you to do the same.Why am I working on Upwork?I always wanted to do my own thing, therefore I agreed with my employer to moonlight as a data science consultant. Cracking the ""find well-paying customers"" is not easy. The options that I knew, that would give me reasonable success were expensive. And especially, since I don't want to do it full time. I don't want to spend hundreds of Euros on Google Adwords to get a customer, that I don't want to charge. On websites like Upwork, you pay shares of what you earn. If you plan on not earning money, this seems to be a good deal.In the beginning, my main motivation was to get experience and reputation. Ideally, on the side and from home. The problems that we are facing in my day job are different from the ones that normal people have. And I wanted to know what these were. I was looking for small tasks that are generating a lot of value for the customers.What I learnt is that you meet amazing people on Upwork. It's the place where people come, that want to build a product in their most early stage. If you don't have money and you want an MVP, you will be trying to outsource it to the cheapest hire on the internet.The German young graduates whose startup skyrocketedOne of the founders of a food delivery startup reached out to me when their product was nothing but a Shopify website. They were planning on optimising their food buying process and posed me the problem: Given the data that we have, how many dishes we would sell in three days? I did the most simple ""model"" you could think of: a one-dimensional curve-fit. And it reduced their food waste by 20%. At least, that's what they told me at the time. By now, they are worth multiple millions.The mysterious traffic pattern on a Myanmarese flight comparison websiteThe CEO of a Myanmarese flight comparison website contacted me and asked for an analysis of website traffic data. It was different from my usual tasks because instead of a dataset, I got access to his Google Analytics account. I was asked to explain a sudden jump in traffic that did all seem to come from a single device type. Then, I forwarded him to an expert in website crawling.The guy who uses Instagram ads to price your product before you have itImagine you want to know the value of your product, but you don't have it yet. The way to go about this is to test it. You offer some early version of it or a promise of future access to your product. Then, you show your offer to different people at different prices. I met an English entrepreneur, who offered these kinds of analyses in a product. And he asked me to help him to set up a process for testing for significant differences.The airport KPI analysisThis doesn't quite fall into the category ""awesome people with an awesome product"", but it was one of the most confusing experiences. There was this person who asked me to run an analysis on KPIs of an airport. I don't know who he was, why he had the data, or even why he paid me for it. But it was fun!Go meet people!I have met extremely interesting people on Upwork, from different nationalities and different fields, but always passionate about their product. And I have seen that with just a couple of hours of work per job, I can create amazing value for many customers. In return, I got invaluable experiences.I would highly recommend anyone looking for work in the data science field to start here. There are so many people ranting about Upwork because of the international competition and price pressure. But if you are looking to grow your data science skills, or you are curious to get connected with startups and their founders, then I would highly recommend to check out these kinds of freelance websites.",,"Discussion,"
314,https://www.reddit.com/r/datascience/comments/dsr6j5/scene_from_narcos_my_gf_didnt_understand_what_was/,dsr6j5,scene_from_narcos_my_gf_didnt_understand_what_was,NazihKalo,0.9,563,2019-11-07 03:49:43,0,39,,,,"Fun/Trivia,"
315,https://www.reddit.com/r/datascience/comments/dszpos/deploy_machine_learning_models_with_django/,dszpos,deploy_machine_learning_models_with_django,pp314159,0.88,32,2019-11-07 17:00:14,0,8,,"I've created tutorial that shows how to create web service in Python and Django to serve multiple Machine Learning models. It is different (more advanced) from most of the tutorials available on the internet:it keeps information about many ML models in the web service. There can be several ML models available at the same endpoint with different versions. What is more, there can be many endpoint addresses defined.it stores information about requests sent to the ML models, this can be used later for model testing and audit.it has tests included for ML code and server code.it can run A/B tests between different versions of ML models.The tutorial is available at https://www.deploymachinelearning.comThe source code from the tutorial is available at https://github.com/pplonski/my_ml_service",,
316,https://www.reddit.com/r/datascience/comments/dt6ald/database_to_store_tbs_of_sensor_time_series_data/,dt6ald,database_to_store_tbs_of_sensor_time_series_data,Northstat,0.88,6,2019-11-08 00:22:52,0,20,,"I have 10 days of recording across 150 sensors saved in 5 minute HDF5 files.  Each file is about 1 million rows (lowest sample rate but there is higher) by 150 columns, one of which is timestamp.  There are about 3k of these files (so 3 billion rows x 150 columns at a minimum).  I need to be able to query by time (often disjoint, e.g., 10am-2pm each day) and apply various transformations (z-score, pca/ica, clustering, wavelet etc) on the resulting data before returning.  Currently I am getting all files and their write time (bash and python) and then using [write_time - 5minutes, write_time] as the window associated with that file.   I pull in all files that contain some portion of the larger window I'm looking for (often hours) and then concatenating the data and applying transformations.  I would like to just query a database for some time period and get the associated data or even better, just run the transformations somewhere in the database layer before returning.  What type of database or data storing system would be best suited for my data?",,"Discussion,"
317,https://www.reddit.com/r/datascience/comments/dtesnn/for_my_fellows_bros_who_want_to_use_their_gpus/,dtesnn,for_my_fellows_bros_who_want_to_use_their_gpus,django_free,0.36,0,2019-11-08 13:32:19,0,1,,,https://www.pugetsystems.com/labs/hpc/How-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-UPDATED-1419/,
318,https://www.reddit.com/r/datascience/comments/dt8fhk/output_of_keras_modellayer/,dt8fhk,output_of_keras_modellayer,DanielagainDaniel,0.76,2,2019-11-08 03:05:58,0,2,,"I'm training a binary classifier (CNN) in Keras which squishes to a single sigmoid in the final layer. I want to make sure that the output is actually ranging between 0 and 1 (or close to that), not just guessing only 1 or only 0 every time. How can I print this output from the final layer?",https://www.reddit.com/r/learnmachinelearning/comments/dt88h2/output_of_keras_modellayer/,"Education,"
319,https://www.reddit.com/r/learnmachinelearning/comments/dt88h2/output_of_keras_modellayer/,dt88h2,output_of_keras_modellayer,DanielagainDaniel,1.0,2,2019-11-08 02:50:36,0,4,,"I'm training a binary classifier (CNN) in Keras which squishes to a single sigmoid in the final layer. I want to make sure that the output is actually ranging between 0 and 1 (or close to that), not just guessing only 1 or only 0 every time. How can I print this output from the final layer?",,
320,https://www.reddit.com/r/datascience/comments/dt6e4i/r_announcing_the_release_of_stellargraph_version/,dt6e4i,r_announcing_the_release_of_stellargraph_version,StellarGraphLibrary,0.81,3,2019-11-08 00:30:02,0,0,,"StellarGraph is an open-source library implementing a variety of state-of-the-art graph machine learning algorithms. The project is delivered as part of CSIRO’s Data61.We are happy to announce the 0.8.1 release of the library, which extends StellarGraph capability by adding new algorithms and demos, enhancing interpretability via saliency maps for Graph Attention (GAT), and further simplifying graph machine learning workflows through standardised model APIs and arguments.This release, we’ve dealt with some bugs from the previous release and  introduced new features and enhancements. Some of these include:New directed GraphSAGE algorithm (a generalisation of GraphSAGE to directed graphs)New Attri2vec algorithmNew PPNP and APPNP algorithmsNew Graph Attention (GAT) saliency maps for interpreting node classification with Graph Attention NetworksAdded directed SampledBFS walks on directed graphsUnified API of GCN, GAT, GraphSAGE, and HinSAGE classes by adding build() method to GCN and GAT classesEnhanced unsupervised GraphSage speed up via multithreadingSupport of sparse generators in the GCN saliency map implementation.Unified activations and regularisation for GraphSAGE, HinSAGE, GCN and GATChanged from using keras to tensorflow.kerasWe’ve also added new demos using real-world datasets to show how StellarGraph can solve these tasks.Access the StellarGraph project and explore the new features on GitHub. StellarGraph is a Python 3 library.We welcome your feedback and contributions.With thanks, the StellarGraph team.",,"Tooling,"
321,https://www.reddit.com/r/datascience/comments/dt4ua9/thinking_of_buying_a_home_server_should_i_just/,dt4ua9,thinking_of_buying_a_home_server_should_i_just,Octosaurus,0.81,3,2019-11-07 22:42:08,0,19,,"I'm thinking of buying a GPU server to serve various models I use with various IoT devices and the like. I'm have some models running on some Pi's at the moment, but it's not easy to deal with and inference time can be a pain. Even more, training on GCP and AWS can be quite costly - especially when I want to train multiple models for comparative analyses or just to play around.Has anyone bought/built their own home server and ditched cloud servers? Should I just stick to cloud providers? What's your opinion? Any suggestions on home servers would be great :) Thanks for reading!",,"Discussion,"
322,https://www.reddit.com/r/datascience/comments/dtd3a8/does_skill_matter_or_degree_for_data_scientist_job/,dtd3a8,does_skill_matter_or_degree_for_data_scientist_job,Jbmannn,0.36,0,2019-11-08 10:36:25,0,15,,"Can a Drop out with Certificate in Data analysis, R programming and python get a decent job?",,
323,https://www.reddit.com/r/datascience/comments/dt7bbx/baysian_improved_surname_geocoding_model_in_python/,dt7bbx,baysian_improved_surname_geocoding_model_in_python,rekon32,0.5,0,2019-11-08 01:38:47,0,5,,Has anyone worked with a Baysian Improved Surname Geocoding model? I'm looking to see if anything has been written in Python... I found this but it seems like the installer has a broken link and hasn't been updated.,,"Discussion,"
324,https://www.reddit.com/r/datascience/comments/dt6z9l/deciding_between_2_offers_internship_or_fulltime/,dt6z9l,deciding_between_2_offers_internship_or_fulltime,germany221,0.6,1,2019-11-08 01:13:23,0,6,,"I have an offer for an internship with a top entertainment company, and a full time offer from a well known Healthcare company. The full time job is a little less money, but I would be able to live at home and would not need a new car. If I take the internship I will have to pay for an apartment and get a more reliable car for the highway. Despite all of that I am really still leaning towards the internship because of the experience and the name brand of the company. These are also my first job offers other than an unpaid internship so I am just interested to know if anyone else has ever taken an internship over a full time position and how it worked out in the end. I personally feel like doing this internship could open a lot of doors internally as well as strengthen my resume for future positions.",,"Job Search,"
325,https://www.reddit.com/r/datascience/comments/dt66zq/do_data_scientist_need_to_know_relational_algebra/,dt66zq,do_data_scientist_need_to_know_relational_algebra,JackIsNotInTheBox,0.6,1,2019-11-08 00:15:24,0,11,,"This is more for people who work on database engine and database R&D, no?",,"Education,"
326,https://www.reddit.com/r/datascience/comments/dsod6d/new_10000_ml_challenge_mapping_disaster_risk_from/,dsod6d,new_10000_ml_challenge_mapping_disaster_risk_from,dat-um,0.95,77,2019-11-07 00:09:11,0,5,,,https://www.drivendata.org/competitions/58/disaster-response-roof-type/,"Projects,"
327,https://www.reddit.com/r/datascience/comments/dt1zk0/not_sure_what_to_do_next_line_between_data/,dt1zk0,not_sure_what_to_do_next_line_between_data,Ignatus1217,0.6,1,2019-11-07 19:36:30,0,4,,"Found lots of really useful advice on this sub so I thought I’d give it a whirl myself.For context I have a masters degree in Neuroscience, about halfway through my course I was introduced to bioinformatics and data science and haven’t looked back. Competed a thesis on classifying Alzheimer’s from blood proteins and lipids in blood samples and learned R and Python. Fast forward 12 months, working for a SaaS company in digital health, have learned SQL, power BI and Tableau. Also learned HTML, CSS and the concepts of HTTPS. Most of this comes from self teaching myself some computer science and machine learning concepts. and being curious about how data is stored, transferred, accessed etc.  The devs in my company are very open and regularly let me look at work they are doing and talk me through parts of it. I even built a very small reporting website that cycles through the power BI iFrames of different reports in Angular with the help of some team members and really enjoyed it!We are currently running a large ML project, that I’m loving ,but I have found it very difficult to focus on what I should be learning next. I have really come to enjoy some concepts of web development and see potential to create and deploy web applications with ML models in frameworks like Django, but feel like I might be stretching myself very thin by dipping my toe into lots of different areas when I should just focus on developing my core data science skills?Sorry for the long rant, just looking for advice from any others in the community that have been on that line between data science and web development and whether it’s a viable career choice?",,"Discussion,"
328,https://www.reddit.com/r/datascience/comments/dsw9jv/what_are_the_challenges_faced_by_data_scientists/,dsw9jv,what_are_the_challenges_faced_by_data_scientists,psmlbhor,1.0,2,2019-11-07 12:10:34,0,10,,"I have seen that there are numerous tools out there to help with the data science workflows like RapidMiner, IBM cognos, dataRobot etc. As I haven't used any of those, I was wondering what challenges are faced by the users of these systems? I am thinking of starting a project that will fill in the shortcomings of these tools.",,"Discussion,"
329,https://www.reddit.com/r/datascience/comments/dsgv7r/compare_and_contrast_docker_containers_and/,dsgv7r,compare_and_contrast_docker_containers_and,ml_runway,0.94,87,2019-11-06 15:14:58,0,21,,"I use virtual environments all the time. For every new project I create a new conda environment. I am starting to do more ""production-level"" data science projects, and it seems the trend is to use Docker containers. Frankly, I am ignorant about them, and just starting to learn, literally just starting the tutorials today. I am a bit confused on the basic moves here: in Python, which has had virtual envs for a long time, what are the added benefits of using a Docker container?I can see if you are developing in C++ where the build process has been an unstandardized mess for decades: Docker containers could be a true life preserver. But in Python we have had virtual environments for many years:I send someone my environment specification, and they create the environment, and voila! Things just work. When would a Docker container be more helpful? When should you use one versus another versus both? Why would you use both: is that not redundant or overkill?Thanks for any help, pointers to videos or articles, as I start on containers.",,
330,https://www.reddit.com/r/datascience/comments/dsx3ir/pyinstaller_question/,dsx3ir,pyinstaller_question,RareIncrease,1.0,1,2019-11-07 13:33:31,0,8,,"I wrote a script that audits 2 databases and outputs an Excel file but in order to run, requires 3-4 Excel sheets to be in the same folder/filepath as the .py program. I ran it through PyInstaller so my colleagues can use it but idk how to get it to work after reading the docs.Do I send them the new folder PyInstaller makes and put the required Excel files in that same folder? How does that work?",,
331,https://www.reddit.com/r/datascience/comments/dssot4/advice_on_longitudinal_data/,dssot4,advice_on_longitudinal_data,WittyKap0,0.81,3,2019-11-07 05:52:46,0,8,,"I have some longitudinal data taken at roughly (but not exactly) regular intervals, maybe about 5 time points per object. The problem is that there is quite a bit of data missing not at random as well.You can think of it as a bunch of sensor readings or measurements taken e. g. around the middle of every month in a 6 month period, and having some measurements not captured for various reasons (communication failure, sensor fault, human error, etc)I'm wondering if anyone can suggest methods I can use to leverage the time dependencies besides treating each of the sensor readings as independent features or augmenting the features using their sum/difference/statistics etc?Are there any models that can be applied to this kind of data and how do you typically handle the misalignment in time (I'm less comfortable with interpolation/binning due to the low number of time samples)I'm sure this problem pops up a lot of the time in clinical settings as well.Look forward to hearing any thoughts you have",,
332,https://www.reddit.com/r/datascience/comments/dsq9lf/would_like_to_pay_one_or_two_data_scientists_to/,dsq9lf,would_like_to_pay_one_or_two_data_scientists_to,otterquestions,1.0,3,2019-11-07 02:36:43,0,4,,"Hi there,I'm working on a data visualisation/ charting tool for a little startup in Melbourne, Australia. Our end goal is to create a product that makes data on the internet more transparent and easier to understand, and we think one way to help us achieve that is to get some data scientists on board.Would anyone be interested in using our product for a small amount of money? In return, we're looking for some feedback and suggestions on how we could make it better for a data scientist.The product lets the user create live charts that can be embedded, shared and updated. Here's a link bigcrunch.io",,"Meta,"
333,https://www.reddit.com/r/datascience/comments/dsigps/to_phd_or_not_to_phd/,dsigps,to_phd_or_not_to_phd,Xayo,0.77,17,2019-11-06 17:12:51,0,14,,"Hello, about me:Age: 27Education: Just finished my masters in computer science with Top gradesCountry: Denmark, though lived and worked all over the Nordics and Germany before.Job experience:2 years full-time experience as a Software developer,multiple smaller projects and internships with respectable companies1 published paper (not peer-reviewed though)Multiple Teaching / Assistant Lecturer types of gigsI now have the opportunity of either obtaining a PhD in the field of DeepLearning, or go looking on the open job market as a Machine Learning Researcher / Engineer. A quick survey of 3 job applications landed me 2 offers, so finding a job does not seem to be a problem. Long-term I see myself in industry, though I'm really not sure if I should pursue my PhD first. In the teams that I have job offers from I would be the only person without a PhD, which does let me to believe that not obtaining one will hinder my career prospects later on. Overall I get the impression that everyone I work with on a daily basis, as well as many of my friends,  have a PhD, and I feel like I would be missing out majorly by not pursuing one at this point in my life. Going into industry now would be the easy choice, doing a PhD would be more hard work but has potentially a larger payoff later.What advice do more senior people in the field have?",,
334,https://www.reddit.com/r/datascience/comments/dsr9q8/makefile_doesnt_play_nicely_with_sql_what_are/,dsr9q8,makefile_doesnt_play_nicely_with_sql_what_are,Radon-Nikodym,0.4,0,2019-11-07 03:56:44,0,0,,"Makefile operates on file targets. Even if you use sqlite, if you store your outputs as tables in sqlite, then makefile can't see them.",,"Tooling,"
335,https://www.reddit.com/r/datascience/comments/dsho6z/should_i_continue_this_data_science_apprenticeship/,dsho6z,should_i_continue_this_data_science_apprenticeship,ABZ-Aaron,0.89,7,2019-11-06 16:16:27,0,5,,"I am currently working in an administrative Engineering job. My daily tasks typically involve installing software, and some software customization/troubleshooting (using a relatively unknown programming language).I am also doing a Graduate Apprenticeship in Data Science at a nearby University (this was offered to me for free so figured I may as well).Unfortunately, it's very hard to apply any of this to my job. I'm spending most the day working my job, then the evenings working on data science related stuff (learning Python, Stats, Maths, etc).I just wonder if I should drop out. It's a lot of work, and I feel constantly depressed wondering if it will ever really be worth the effort. I'm currently in my first year (4 years total).I really just need some advice, but don't know any data scientists to ask. Basically I don't want to spend 4 years doing this course, then find I've completely wasted my time and can't apply any of the skills I've learned. If I leave me job, I'll also need to drop out of the apprenticeship. Wondering if it will all be worth it is causing me a lot of depression/stress.I should also note that I am very interested in Data Science, and have a MSC in Neuroscience. There's also ways I could potentially apply what I'm learning to my job. However there are no data scientists in my team, so I feel a bit lost and lacking in direction.",,"Career,"
336,https://www.reddit.com/r/datascience/comments/ds5civ/a_book_on_data_scientists_thought_process/,ds5civ,a_book_on_data_scientists_thought_process,DoubleDual63,0.95,135,2019-11-05 21:50:47,0,22,,"Like a book not on all the theory behind all the different methods and models, but a book that is a collection of case studies of data scientists in all different domains approaching a problem and solving them? I think it would be nice to see how experienced professionals actually do things, test my understanding against their decisions, and hear some little advice and tips on what they found useful or not so useful in their careers. Kind of the reason I go to Reddit and other forums.",,"Discussion,"
337,https://www.reddit.com/r/datascience/comments/dsboph/data_set_way_too_big/,dsboph,data_set_way_too_big,TheNumberOneDuder,0.88,23,2019-11-06 06:17:00,0,28,,"I really want to do some analysis on the yelp review dataset. However, that file contains over 1.5 million reviews, and my computer is too slow to read it.Does anyone know of either a smaller database of reviews (200k-400k?) or a way to reduce the size of the dataset so I can actually use it? Thanks.",,"Tooling,"
338,https://www.reddit.com/r/datascience/comments/dsfl73/im_starting_a_msc_in_data_science_the_two/,dsfl73,im_starting_a_msc_in_data_science_the_two,DEBrOgLied,0.58,2,2019-11-06 13:25:30,0,10,,,,
339,https://www.reddit.com/r/datascience/comments/dsaks2/looking_for_presentation_on_four_central_concepts/,dsaks2,looking_for_presentation_on_four_central_concepts,pies_of_resistance,0.87,6,2019-11-06 04:35:11,0,2,,"I recall seeing a nicely-formatted presentation online about a year ago in which the author claimed there are four statistics concepts one everyone should know. One was bootstrap resampling to estimate SE of a stat, one was permutation to estimate null distrib of a stat...and I forget the other two.  Does anyone know what I’m talking about?  Thank you!",,
340,https://www.reddit.com/r/datascience/comments/drt0zi/business_undergrad_to_fortune_500_data_scientist/,drt0zi,business_undergrad_to_fortune_500_data_scientist,docobo170,0.93,335,2019-11-05 03:53:32,0,87,,"Hey r/datascience- with the mods permission/encouragement I thought I would try to give back by doing a write-up of my road from an undergraduate degree at a business school to a Fortune 500 Data Scientist role on a R&D team.TLDR; I spent a couple hours everyday for 2 years learning and doing analysis for fun, and found opportunities for data science in every aspect of my job until I had enough experience for someone to take a chance on me and hire meMy starting point:Degree- BBA from a top 50 school in Information Systems and Data AnalyticsRelevant Coursework- Intro to Statistics, Database Design, Intro to SQL, Applied Business Intelligence Tools (Alteryx, Qlik, Tableau), Intro to Data Visualization, Intro to Machine Learning in SAS, Web Application Development (Javascript/HTML), Intro to Mobile App Development (Swift)With these skills I was able to land a job as an analyst at a global consulting firm (i.e. Accenture/CapGemini, EY)Below is a roadmap of my first 2 years at my first job:First project on the job:Gathering requirements for a BI applicationHere I spent 4 hours everyday 7 days a week taking courses on Data Camp and reading books like Python for Dummies. I it took about 8 months to replace all of my excel work with Python and really learn enough to be useful on a team of business folks.With the skills from my first role I got a new project doing data cleansing, data munging, quality checks etc. using my existing SQL skills and new skills in Python. I was asked to do all this work in excel, but forced myself to do everything in Python both to learn and prove myself worthy of harder tasks.I took opportunities to do simple statistical testing in Python and when I saw opportunities to bolster my team's analysis by looking at things such as feature importance from a tree based model or setting up data correctly for a simple linear regression, I forced that work into our project by doing it on my own time and presenting it to my team.Slowly I became my team's go to general analytics and Python automation person. I used this internal reputation to get a new project on a team looking to implement some basic ML models at a client and needed someone who knew sklearn and could guide client analysts in doing things like walk-forward validation for time series models, and pointing out issues such as data leakage.On my own time I started to read books like ""Forecasting, Principles and Practice"" by Rob Hydnman and find dummy datasets on Kaggle to test concepts on. I took things a step further by creating dashboards of analysis I did for fun and putting together a small Tableau/Github portfolio, and adding a Personal Projects section to my resume. The portfolio work I kept private and would link it either in cold emails to hiring managers, or keep it handy in case I discussed a pet project during an interview.Finding a new jobJob titles I was searching for- Data Analyst, Associate Data ScientistNumber of cold applications over 3 months- ~60Number of first round phone interviews- 7Number of final rounds- 3Job offers- 2Almost every interview process followed this format:Phone screen with recruiter to discuss backgroundTake home technical exam, either SQL or Python, just general analysisPhone call with hiring managerOn site technical + meeting with hiring manager and teamMy pitch was that I was able to tie business problems to data science solutions, and could not only execute on problems as a data scientist using my technical skills but also present the results to the business and executives. I think this combination of soft and hard skills was the reason anyone even bothered to talk to me given my background.I think what got me the final offers was how I presented myself as willing to learn, giving evidence in the form of my pet projects, all of the books I've read and courses I took in my free time. After I received the offer, the head of the R&D group (a math PHD) said he liked my hustle and thought he could just teach me what I didn't know or point me to the right learning resources.For those of you looking to break in, I definitely think even if you're not someone with the perfect background, with enough time and study you can do it.With that being said, my next step as I move into this role will be applying to masters programs to shore up all of my quantitative deficiencies. I think if I want to thrive in this role and move up I'll need the quantitative foundation.I think you can teach yourself enough to get that first job, but more than that and you'll need to be exceptional at teaching yourself a lot of things! Unfortunately I learn much better in a class setting with homework assignments and structured learning!Ask me anything :)Resources used:DataCamp- All Data Science with Python courses, all SQL courses""Forecasting, Principles and Practice"" by Rob HydnmanStatistics for DummiesLinear Algebra for DummiesYoutube channels such as StatQuestReading various papers related to whatever dataset I was working on. Example- reading different clustering methods and how they differ, and how different distance metrics can influence themOther techniques:Find an online dataset and do an analysis. For example, I took geospatial data and did a network analysis using locations as nodes, which gave me an excuse to read papers on network clustering and the networkx python package",,
341,https://www.reddit.com/r/datascience/comments/dscu2i/query_on_how_clients_engage_with_data_science/,dscu2i,query_on_how_clients_engage_with_data_science,Ashtavakra85,1.0,1,2019-11-06 08:16:35,0,4,,"Hi,I have a query about how clients typically engage data science companies. Can a prospective client start a discussion with the company with just a signed NDA for open-ended/IP driven projects? Or are there any specific contract/agreement templates to follow?This is for a research project I'm working on. Any clarification will be appreciated. Thanks",,
342,https://www.reddit.com/r/datascience/comments/dse2wu/data_scientist_vs_data_analyst_title/,dse2wu,data_scientist_vs_data_analyst_title,Bardy_Bard,0.4,0,2019-11-06 10:42:33,0,7,,"Hi all, Looking for some career advice here: I am considering switching jobs from Data Scientist to Data Analyst in a different company. (These are all juniorish roles)The choice would be:Title change (possible)--> demotion(?)Pay --> same or slightly lessTechnical level of the job --> higherCareer development/path --> betterTeam Level --> higherIn your opinion does your title really matter for future jobs ?",,"Career,"
343,https://www.reddit.com/r/datascience/comments/ds7dju/data_quality/,ds7dju,data_quality,tacothecat,1.0,3,2019-11-06 00:17:42,0,6,,"What kind of data quality checks does your company utilize?  Checks for missing data, outliers, covariate shift, etc...?  What tools exist for this analysis?",,
344,https://www.reddit.com/r/datascience/comments/ds7oa5/has_anyone_applied_for_a_job_at_civis_analytics/,ds7oa5,has_anyone_applied_for_a_job_at_civis_analytics,myfriendscode,0.44,0,2019-11-06 00:40:41,0,3,,"I applied for an internship about a month ago and haven't heard anything... It's probably the top place I want to work next summer and I'm really bummed. I'm hoping that the hiring team takes a bit longer to reach out to candidates, and am wondering if anyone has experience with recruiters from Civis.",,"Job Search,"
345,https://www.reddit.com/r/datascience/comments/dry6xf/are_there_any_example_showcasing_the_use_of_ml/,dry6xf,are_there_any_example_showcasing_the_use_of_ml,Zenith_N,0.8,9,2019-11-05 13:02:17,0,12,,"example:I have 5 customers, I want to make sure I squeeze as much profit from each one without losing them to the competition.Are there any example in python showcasing how to go about solving this.",,"Education,"
346,https://www.reddit.com/r/datascience/comments/dsd7a6/what_techniques_to_use_when_data_is_bad_for/,dsd7a6,what_techniques_to_use_when_data_is_bad_for,datapim,0.25,0,2019-11-06 08:57:46,0,19,,"So one time I had to do linear regression on small set around 24 observations and I think 5 features.The thing is the results of regression showed that the independent variables were not significant, I tried removing some of them or taking squares but the model did not improve much.It was a sales data and the team wanted to know how price changes of different products affect sales on one product.So if linear regression fails in this, what other approach could I consider?",,"Discussion,"
347,https://www.reddit.com/r/datascience/comments/ds28k5/looking_for_a_data_set_of_pdfs_preferably_white/,ds28k5,looking_for_a_data_set_of_pdfs_preferably_white,redditrambler,0.75,2,2019-11-05 18:14:47,0,2,,,,
348,https://www.reddit.com/r/datascience/comments/ds5150/reaching_out_to_local_recreational_marijuana/,ds5150,reaching_out_to_local_recreational_marijuana,poolguy8,0.57,1,2019-11-05 21:28:09,0,9,,"A local marijuana dispensary has a very shoddy website which barely operates. They also collect 0 data on buyers. What I would like to implement is a customer system where each customer has the option to create an account.This account would provide us with: email, age, gender, etc. On top of that, account transactions could be linked to each individual, possibly even recommending similar products [marijuana strains and lineage are largely diverse]. All the product packaging has information about the company, terpenes content percentage, and its lineage.The possibilities are endless. I'm not exactly sure how I would begin to implement this and when I could see good results.My question is: What type of programs in python could best suggest other products based on previous information and similar customers? Also, how might I propose this idea to this owner?I plan on speaking with the owner telling him about marketing opportunities and what he could benefit by hiring me. I am a senior college student and want to gain real-life experience by taking on a new challenge.",,"Career,"
349,https://www.reddit.com/r/datascience/comments/drz48v/using_google_cloud_platform_with_a_team_colab/,drz48v,using_google_cloud_platform_with_a_team_colab,iwouldliketheoption,0.83,4,2019-11-05 14:26:37,0,5,,"I'm wondering whether anyone has made much use of the google cloud platform with a team.What i have is a lot of data coming in to google storage, which will then be pulled into bigquery. Then analysts are supposed to be able to able to investigate this data using google colab. I'm not currently seeing a nice way for this to all work together though, it seems as though Colab just works with google drive. For example, the authentication is done using a user account rather than a json service key, which isn't ideal.I can query data that's stored in bigquery from colab, but I'm currently unsure how this would typically be used within a team. Would you just have a bunch of google accounts and a shared Google Drive? Or is there a more sophisticated workflow that I'm missing.",,"Discussion,"
350,https://www.reddit.com/r/datascience/comments/drylds/how_locked_in_will_i_be_if_i_use_sagemaker/,drylds,how_locked_in_will_i_be_if_i_use_sagemaker,forsakenMule,0.8,3,2019-11-05 13:41:57,0,7,,"Some individuals in the company I work for have started aggressively promoting Sagemaker as the tool to use for training and deploying models.I am part of the data science team and has usually relied on our own custom built solution with EC2 instances to train and deploy models.I have limited knowledge about sagemaker for now but 2 things stand out when I started exploring it:quite easy to use as I don't have to worry too much about infrastructurehowever it seems that a some of their algorithms are proprietary (even though I am sure that 99% of their code base is coming from open source!!!), meaning it seems I can use them only with sagemaker.Am I correct to think that by using sagemaker built in algorithms, I am giving up on my freedom to download and deploy my model somewhere else even if the model itself has mostly been trained by open source algorithms?",,
351,https://www.reddit.com/r/datascience/comments/drde9q/looks_like_i_have_a_lot_of_studying_to_do/,drde9q,looks_like_i_have_a_lot_of_studying_to_do,da_chosen1,0.95,775,2019-11-04 06:51:15,0,79,,,,"Discussion,"
352,https://www.reddit.com/r/datascience/comments/ds23km/looking_for_a_dataset_of_images_with_different/,ds23km,looking_for_a_dataset_of_images_with_different,AlanRoofies,1.0,1,2019-11-05 18:05:12,0,10,,"Hello,I'm doing a project for university and i'm looking for a Dataset that contains different images where each image has different samples, each sample has a different exposure. (exposure bracketing), i want teach a neural network to merge the different exposures to get an hdr imageI have found this dataset : https://www2.cs.sfu.ca/~colour/data/funt_hdr/BUT, images look like this https://imgur.com/a/49CaGQiI need normal imagesif you have any idea where i can find one, that would be awesome !thank you in advance.EDIT:so, i found this dataset http://rit-mcsl.org/fairchild//HDRPS/HDRthumbs.htmleach image has one .EXR file for downloadI want to know how i can convert/extract that EXR File into multiple jpg or png files with different exposures",,"Projects,"
353,https://www.reddit.com/r/datascience/comments/drtfsp/what_decorators_do_you_use_in_python/,drtfsp,what_decorators_do_you_use_in_python,Radon-Nikodym,0.92,11,2019-11-05 04:26:42,0,6,,"Decorators are a pretty powerful tool. How do you apply them to data science for your workflow? Examples of generic ones that I've seen include caching, looping over files (ie load all csv's from a directory, apply function, and concat result), timing, logging. Interested in both useful decorators and cool decorators.",,"Discussion,"
354,https://www.reddit.com/r/datascience/comments/ds4ofx/do_i_need_ml_for_data_analyst/,ds4ofx,do_i_need_ml_for_data_analyst,JackIsNotInTheBox,0.38,0,2019-11-05 21:03:12,0,16,,"Hi guys, recent CS grad here. I don't have the luxury to learn nice-to-haves because I have to pay my debt soon. I'm currently studying for a data analyst jobs because let's be honest, true data scientist jobs require advanced degrees and years of experience.So I want to ask whether I require any machine learning or AI concepts such as regression analysis for a data analyst role.Here's the job description:A data analyst collects and stores data on sales numbers, market research, logistics, linguistics, or other behaviors. They bring technical expertise to ensure the quality and accuracy of that data, then process, design and present it in ways to help people, businesses, and organizations make better decisions.Bonus points if you have worked as a data analyst before! Thanks guys.",,"Job Search,"
355,https://www.reddit.com/r/datascience/comments/drrk7k/if_i_want_access_to_real_time_real_estate_data/,drrk7k,if_i_want_access_to_real_time_real_estate_data,ZamanMahmoudi,0.86,5,2019-11-05 02:04:25,0,3,,Hey guys I’m looking for an easy way to get access to real estate data across the entire United States. My understanding is that the MLS really locks this data down. Would it be beneficial to get my real estate license so I can access this data?,,
356,https://www.reddit.com/r/datascience/comments/dro8dm/course_with_certification_paying_worth/,dro8dm,course_with_certification_paying_worth,JoseChovi,0.81,6,2019-11-04 22:09:13,0,5,,Hi everyone!I am new doing courses and I have done one of Machine Learning with Python offered by IBM. But I have not paid so I can get the certification.Is this:  https://www.edx.org/es/course/machine-learning-with-python-for-edxIs worth pay this courses?,,"Career,"
357,https://www.reddit.com/r/datascience/comments/drpuuz/r_vs_python_for_data_viz/,drpuuz,r_vs_python_for_data_viz,exc99,0.86,5,2019-11-05 00:00:32,0,25,,"I know both languages fairly well and I want to start getting into Data Visualization. I tried learning a bit of Matplotlib but have been pretty lost throughout the entirety of my time learning. Out of R / Python, which is the best language for making data visualizations?",,"Discussion,"
358,https://www.reddit.com/r/datascience/comments/drpkoj/programming_practice_for_interviews/,drpkoj,programming_practice_for_interviews,forowned,0.67,3,2019-11-04 23:40:50,0,5,,"I'm not a software developer, nor I have a CS degree. I don't enjoy websites like hackerrank, they frustrate me because it's not really about programming, it's more about problem solving and/or maths. (Clarification: I know it's about programming. However, I see and enjoy programming as a tool for automation and solving real problems or interesting projects, rather than ""pointless"" or difficult to understand exercises).I may have some DS interviews coming in the next couple of weeks. Should I expect the same kind of problems (like hackerrank) in an interview for a DS position? I'm really bad at those and I wanted to start practising but my procrastination sky rockets when doing these exercises :(",,
359,https://www.reddit.com/r/datascience/comments/drkgxt/how_important_is_full_stack_data_science_where/,drkgxt,how_important_is_full_stack_data_science_where,Lostwhispers05,0.92,9,2019-11-04 18:00:14,0,11,,"One thing that's been equal parts challenging, fun, and terrifying about being one of the few 'data people' at a start-up is that you end up having to manage every conceivable aspect of said data.All the way from Data Engineering (establishing Data pipelines, communicating with your Devs about what the data collection process should entail, etc), right down to the front-end stuff like dynamic dashboards to explain the current story, and predictive modelling to make an informed judgement about what the best next moves might be.As an example, where I work, being able to tune some dials and squeeze out 1.5% more accuracy is vastly less important than being competent with AWS and understanding the back-end infrastructure well and being able to assist in the setting up or updating of a new pipeline if the need arises.What's the situation like for most of you guys?",,
360,https://www.reddit.com/r/datascience/comments/drkeao/i_just_released_a_python_package_cli_which_lets/,drkeao,i_just_released_a_python_package_cli_which_lets,minimaxir,0.9,7,2019-11-04 17:55:21,0,2,,"https://github.com/minimaxir/stylecloudThis is a project that's more fun than statistically rigorous for data science, but it's a way of presenting text data that might provide a bit of creative flare in a blog post/PowerPoint presentation!I also added short demos on how to create word clouds/styleclouds from Twitter and Reddit data, if you're interested in that. https://github.com/minimaxir/stylecloud-examples",,"Tooling,"
361,https://www.reddit.com/r/datascience/comments/driibn/data_scientist_looking_for_a_change/,driibn,data_scientist_looking_for_a_change,azzipog,0.92,10,2019-11-04 15:41:09,0,17,,"Cross post from r/cscareerquestionsBackground:I have been a data scientist for about 2 years now. I have a bachelors degree in Economics. I started out doing risk modeling for an insurance company. About 5 months ago, I was hired by a small consulting company. My role here is more of a machine learning engineer. I create machine learning systems to automate business processes. I am proficient in Python, SQL, and R.Current Job Issues:Machine learning is a hard field to do consulting work in. Most companies that have adequate data infrastructure already have a data science team. Those that don't have the appropriate infrastructure can't benefit from machine learning. As a result, I am getting little experience in my current role. So, I'm looking for a change. For every project I have, there are ~4 weeks of no work. Doing this time, I get certs and do research. Right now, I only have UIPath certification.General concerns about the field of Data Science:I live in a medium sized city on the east coast --  not a ton of data science jobs. Additionally, I don't enjoy the modeling aspects of the job nearly as much as the engineering. I understand most commonly used models, when to use them, their pitfalls, etc; however, my interest with them is very applied. I don't have any desire to develop new machine learning algorithms -- only using pre-existing tools to add business value.I would like to use machine learning as one of many tools to automate business processes.Future Steps:I'm thinking about leaving Machine Learning specific roles in favor of a Software developer role, but I don't know if I could close to my current pay $75k. I can take a slight pay cut, but not too significant.Questions:Could I get a decent job as a Python Software Developer with my current experience?Should I just try to get a machine learning engineer at a different company?Any other input?tl;drI like the engineering side of machine learning the most. In a dead end job. What should my next step be?",,
362,https://www.reddit.com/r/datascience/comments/drrhhl/curious_where_to_start_a_weather_model_for_a_zip/,drrhhl,curious_where_to_start_a_weather_model_for_a_zip,Toby16custom,1.0,1,2019-11-05 01:58:42,0,3,,"New to modelling as a concept, additionally Python. Been a data analyst for 5 yrs now in SAS/SQL and done mostly descriptive analytics so predictive is fresh to me.Came across a interesting problem for a radio contest:--Predict the first zero degree day this year for a specific city. --I've taken a look on Github and found some models for the temperature in the next 24H  but I am curious where to begin in adapting some of this code and pondering the problem on my own.Model target- daily temp (L)Data: Get some from NOAA around temp/location/precip/wind for variables?Would appreciate some direction and any sample code. Thanks",,"Projects,"
363,https://www.reddit.com/r/datascience/comments/drpdo4/i_made_an_app_for_field_data_collection/,drpdo4,i_made_an_app_for_field_data_collection,ahbou,1.0,1,2019-11-04 23:27:31,0,2,,Hi r/datascienceI'm currently building an app for Field data collection for almost a year and I just recently launched publicly.My goal is to allow anybody to collect all sorts of data points easily from the field and visualize them in a Map or as a List.Currently it's still a tiny tool but it does one thing and aims to  do it very well.Is the value proposition clear enough? What would you add/change/improve?I'll appreciate any feedback  🙏Homepage: https://todata.net,,"Tooling,"
364,https://www.reddit.com/r/datascience/comments/dro8ft/estimator_behavior_of_categorical_encoding/,dro8ft,estimator_behavior_of_categorical_encoding,jaredstufft,1.0,1,2019-11-04 22:09:20,0,2,,"Hi all,I'm doing some secondary research on different methods of encoding categorical data for use in machine learning/statistical models. I've found a few helpful blogs that do some simple benchmarking of standard metrics, but haven't found anything peer-reviewed yet. Some of these blog posts show some asymptotic behaviors and I'm wondering if there's anything more rigorous that has explored this.Thanks!Jared",,"Discussion,"
365,https://www.reddit.com/r/datascience/comments/dr5icl/how_do_you_calculate_your_impact_at_your_jobs/,dr5icl,how_do_you_calculate_your_impact_at_your_jobs,jirukulapati,0.93,75,2019-11-03 20:40:39,0,20,,"In terms of resume tips, a lot of people say you should describes your experience at a job as such:""Implemented (*insert solution*) to solve (*insert problem*) and reduce costs/time by (insert dollars/hours)"".How do you calculate how much time/money is saved through your solution?",,"Discussion,"
366,https://www.reddit.com/r/datascience/comments/drheu6/question_on_how_to_handle_financial_data_over_time/,drheu6,question_on_how_to_handle_financial_data_over_time,HobbesForPrez,1.0,2,2019-11-04 14:11:05,0,6,,"Good morning,I am working with a data set that incorporates financial information over time. Here is an example of a similar, simplified data set:Year# GuestsMoney Spent (total)Money Spent (avg per guest)196010$100$10196110$110$11196212$140$11.67............2018200$6500$32.502019210$7000$33.33My question is do I need to account for inflation? For example, according to the US Inflation Calculator, $100 in 1960 = $867.43. Would a more accurate representation of the data be something like this?Year# GuestsMoney Spent (total)Money Spent (avg per guest)196010$867.43$86.74196110$944.60$94.46196212$1190.27$99.19............2018200$6649.30$33.232019210$7000$33.33What do you think is the most accurate way to handle this sort of data? Present it as raw data as it was collected? Or incorporate inflation?",,"Discussion,"
367,https://www.reddit.com/r/datascience/comments/dr1xym/data_science_vs_business_intelligence_analytics/,dr1xym,data_science_vs_business_intelligence_analytics,dade305305,0.87,70,2019-11-03 16:33:07,0,34,,"Any insight into which of the two seems like it would be the most stable and in demand in the future? I know nobody has a crystal ball, but I'm looking for opinions.My background in either area is minimal. I took intro to stats and an applied stats grad course, I took an Excel class, macroeconomics and a couple of public finance classes. I have taken no programming courses, no calc, no SQL etc.I have a degree that is usually geared towards government work and I currently work for the federal government.I plan on staying in it for the rest of my career, but life doesn't always go the way you plan it. As such, I've always been a ""have a long term contingency plan"" type of guy, which is why I'm making this post. You want to go about re-skilling before you have to IMO.I make a good buck and I have the time, so the the resources needed to take the classes are not an issue. All that being said, which one appears to have more long term viability?Also, remember that I chose to go into government of my own volition so the one that pays the most is not going to be a major factor in my choice. ThanksEdit: Forgot to mention that I took a dedicated Access class too so I have some experience with databases.",,
368,https://www.reddit.com/r/datascience/comments/drg6md/imposter_syndrome_for_a_beginner/,drg6md,imposter_syndrome_for_a_beginner,sanelyinsanewoman,0.55,1,2019-11-04 12:12:15,0,9,,"Hello everyone,Is it common to feel the ""imposter syndrome"" when one begins their path in data science?I dived into this field because I indeed felt I have a great interest in playing around with data. My previous job was on the fence of data analysis, though I worked majorly on Excel with e-commerce data. With this work, I felt I wanna grow in this field and that is what made me to apply for a post-graduate degree in Data Science.However, after joining the course, I feel I don't understand much. The scatter plots and graphs make me go blank. The ML algos are way too confusing. I am giving in my best efforts, but I am doubtful whether I really belong here.Do most people feel the same in the beginning? Please share your experience. I am really in need of some motivation to get out of this supposed imposter syndrome.Thank you.",,"Education,"
369,https://www.reddit.com/r/datascience/comments/dqtg4y/using_docker_kubernetes_to_host_machine_learning/,dqtg4y,using_docker_kubernetes_to_host_machine_learning,bweber,0.96,180,2019-11-03 01:57:04,0,29,,"I just published chapter 4 of ""Data Science in Production"". Here's an excerpt: https://medium.com/@bgweber/using-docker-kubernetes-to-host-machine-learning-models-780a501fda49",,"Projects,"
370,https://www.reddit.com/r/datascience/comments/dqyhfz/data_analyst_career_path_for_the_next_51020_years/,dqyhfz,data_analyst_career_path_for_the_next_51020_years,squashnmerge,0.85,30,2019-11-03 11:11:30,0,19,,"I'm around one year into my career as a data analyst. What I've been noticing so far is that there are more and more products that can automate the tasks that we do. For example, libraries that reduces the need of writing statistical models from scratch to Google's AutoML that goes further by selecting a model for us automatically. We may not even need to write SQL queries anymore in the next few years.What would be the most prospective path for a data analyst given these circumstances? Do we need to pivot in the coming years? How can the current data analyst professionals retain their edge?",,
371,https://www.reddit.com/r/datascience/comments/dr8pfl/data_viz_question_fivethirtyeight/,dr8pfl,data_viz_question_fivethirtyeight,exc99,0.67,1,2019-11-04 00:29:21,0,3,,"Could someone point me in the right direction as to what kind of chart this is? I am trying to visualize something in a similar fashion: https://www.instagram.com/p/BuG9gksBqlM/Also, would creating a chart like this be possible in Python? Thanks.",,"Discussion,"
372,https://www.reddit.com/r/datascience/comments/dr16r2/anyone_have_any_research_or_found_opportunities/,dr16r2,anyone_have_any_research_or_found_opportunities,n7leadfarmer,1.0,5,2019-11-03 15:36:40,0,10,,"For those familiar, this seems to be a very ambiguous task that needs HITL (human in the loop) interaction, but my company is interested in taking the automation of this process in-house. I'd like to be involved in this transition, but there doesn't seem to be a lot of open source research on the matter.If it means anything, my strongest language is Python. The biggest issue I'm facing now is the cardinality of the descriptions that accompany each HTS code. There's a lot of overlap in both the codes and descriptions so I'm not sure of the best way to generate relationships.If more info is needed I can update the original post as we go.Thanks!",,
373,https://www.reddit.com/r/datascience/comments/dqv5d2/in_your_mind_whats_the_difference_between_a/,dqv5d2,in_your_mind_whats_the_difference_between_a,imightbemary,0.88,35,2019-11-03 04:24:28,0,11,,"I'm a DS manager and I'm in the process of rewriting the career ladders for my team. The ladders are super fuzzy right now, and I'd love to have something like Etsy's career competency matrix.Also worth noting: we also have analysts, who do analysis to support product teams as well as things like dashboarding, and ML engineers, who build models used in production. The DSes build models too, but it tends to be for things like predicting user churn or LTV.",,"Career,"
374,https://www.reddit.com/r/datascience/comments/dqvw8t/data_science_vs_product_manager_position_early/,dqvw8t,data_science_vs_product_manager_position_early,ZeroSum-,0.92,25,2019-11-03 05:40:08,0,18,,"Hi, I've been given some opportunities at my company to choose my next role. Currently working as an Analyst for the company for more than a year now and been the lead on a couple projects as well as done the analytics/automation tool building for my team.Basically I have the option to be a Data Scientist or PM. We have senior level members in both roles that will act as a mentor. My thought process is that it will be difficult to transition from a PM --> Data Scientist later on in my career rather than DS-->PM. There are available software engineer roles, but I'm currently not qualified to go into those positions.Eventually I would like to be in a management role, but feel that going for the data scientist route would provide a better technical foundation to become a better PM. My background (degree) was in Mathematics and most of my technical skills are self-taught.Any advice or opinions on what role would be best early on in a career would be appreciated.",,
375,https://www.reddit.com/r/datascience/comments/dqzh9f/weekly_entering_transitioning_thread_03_nov_2019/,dqzh9f,weekly_entering_transitioning_thread_03_nov_2019,datascience-bot,0.82,7,2019-11-03 13:00:28,0,125,,"Bleep Bloop. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki. You can also search for past weekly threads.I am a bot created by the r/datascience moderators. I'm open source! You can review my source code on GitHub.",,"Discussion,"
376,https://www.reddit.com/r/datascience/comments/dqtdhl/what_fiction_are_you_reading/,dqtdhl,what_fiction_are_you_reading,willmachineloveus,0.77,42,2019-11-03 01:50:58,0,52,,"Generally but of more interest to me now is fiction/sci-fi exploring society in a data rich, privacy poor (ie near future) environment. I read After On about a year back and was left wanting. I wish Lionel Shriver or Thomas Pynchon would explore these topics...",,
377,https://www.reddit.com/r/datascience/comments/dr6hak/data_science_curriculum_for_club/,dr6hak,data_science_curriculum_for_club,zytron11,0.6,1,2019-11-03 21:48:18,0,4,,"Hey all,I'm a CS student at university still, and I had some questions about building a non-intensive broad Data Science/Analytics curriculum for a club I'm in.The club is a business consulting group and we're trying to offer Data Analytics to our clients, but the catch is, no one in the club knows what it is lol.I was creating a 10 week curriculum for everyone in the club that's interested to teach people about Data Analytics and how to use it to help our clients.I was trying to build it in the focus of Business Intelligence, since that's the main way we'd be working with data and helping our clients gain better insights.So far this is what I've got, but I'm not sure how to continue from here with more advanced topics (I'm a noob myself lol).GOAL: Teach people how to analyze data and help companies gain insights from the data we collectWeek 0 “What is Data Analytics?” (short 30 min talk just gauging people’s interest)Value of data to companies, talk about good/bad data collection policiesWho is Data Analytics for, why bother, etcGet people to actually sign up and see when they want to have classes (after main meeting, on weekends, etc)Send out dev environment setup to people interested (simple script to install python and libraries if you have time, maybe create github to hold lesson plans and have people pull from there)Week 1 “Introduction to Data Analytics and python”First real workshop, have everyone get familiar with Google analytics and Python (with jupyter notebook!)Talk about tools such as Google Analytics, Tableau, LookerInsights and examples from certain casesReal world cases where DA has helped businesses grow and find weakpointsExplain rest of course curriculum and timeline, have everyone build their own DA projects with provided datasets (homework!! (keep it light though))Provide external resources outside the classWeek 2 “Data is messy”After everyone gets familiar with python, teach them how to use numpy and pandas to clean and wrangle dataTry to keep it interesting, don’t bore people with just like “okay this is how you use a numpy array”Maybe run a crash course through important stuff to know with linear algebra and python (matricies, etc)Give people homework to clean up a provided dataset for next workshopWeek 3 “What does it all mean?”Hopefully everyone did their HW, if not provide finished hw to work withShow how bundles of meaningless data can actually be transformed into insights related to business decisionsShow how to create meaningful reports with the data provided with Pandas and Jupyter NotebookIncorporate usage of these skills with customersNOTE: The people I'd be teaching would have no real programming experience, most of them are business majors with not much python experience.I was planning on doing an hour/hour and a half workshop a week to teach people, along with providing some notebooks for HW each week.Not really sure how I should continue with this, any help would be appreciated.",,"Education,"
378,https://www.reddit.com/r/datascience/comments/dr57ts/need_help_with_selecting_thesis_topic_for_data/,dr57ts,need_help_with_selecting_thesis_topic_for_data,kc_kamakazi,0.4,0,2019-11-03 20:20:42,0,4,,"I am doing a  data science course and I need to select a topic for my thesis. The topic should be such that the dataset is available and the work can be completed in 6 months. I am totally lost on what to work on, any suggestion will be really cool.",,"Projects,"
379,https://www.reddit.com/r/datascience/comments/dquzgs/which_certs_are_worth_it/,dquzgs,which_certs_are_worth_it,MedicalWafer,0.72,12,2019-11-03 04:08:45,0,9,,"I have a job developing user management features for a mid-size software company. No hard tech skills/experience. Should I learn HTML? SQL? A CompTIA cert? What is most useful for managing user data, and understanding how databases store such data?",,"Career,"
380,https://www.reddit.com/r/datascience/comments/dqvcyb/what_do_you_do_in_your_free_time_that_isnt_data/,dqvcyb,what_do_you_do_in_your_free_time_that_isnt_data,paywallpiker,0.91,9,2019-11-03 04:44:53,0,11,,"So it seems when i talk to my friends or coworkers in DS, the conversations tend to stay on projects, work, or research outside of work. We don’t tend to talk about non ds related things even when going out for drinksWhat do y’all do outside of the hard work that you do? Me personally I love doing improv and comedy.",,"Discussion,"
381,https://www.reddit.com/r/datascience/comments/dqf09j/netflix_releases_polynote_a_multilanguage/,dqf09j,netflix_releases_polynote_a_multilanguage,DS_throwitaway,0.98,557,2019-11-02 04:30:35,0,53,,,https://venturebeat-com.cdn.ampproject.org/c/s/venturebeat.com/2019/10/23/netflix-open-sources-polynote-to-simplify-data-science-and-machine-learning-workflows/amp/,
382,https://www.reddit.com/r/datascience/comments/dqrvvu/ckan_plugins_for_visualizing_data_in_ckan_web_gui/,dqrvvu,ckan_plugins_for_visualizing_data_in_ckan_web_gui,jimmyco2008,1.0,2,2019-11-02 23:53:04,0,1,,"I'm having a hard time finding any resources for visualizing datasets/resources within the CKAN (2.8) web gui. I found what seems to be an abandoned project under ckanext.There are of course the [built-in plugins]( https://docs.ckan.org/en/2.8/maintaining/data-viewer.html ) but what are you guys using? Surely there are some good alternatives, perhaps with more advanced charting/graphing options?",,"Discussion,"
383,https://www.reddit.com/r/datascience/comments/dqu5h2/how_web_crawling_benefit_data_science/,dqu5h2,how_web_crawling_benefit_data_science,weihong95,0.53,1,2019-11-03 02:55:29,0,4,,"You might be wondering, is web crawling even needed in data science?In this article, I am going to share how web crawling benefit data science in 3 real-world scenarios.Link: https://towardsdatascience.com/how-web-crawling-benefit-data-science-a6ff0bd4cd1?source=friends_link&sk=5c3da69b8cc5168d6d1d5cdc7c9d51c1I hope you will enjoy this article, and comment below if you have any thoughts to share!",,"Education,"
384,https://www.reddit.com/r/datascience/comments/dqaiqq/company_culture_rarely_changes_the_reason_behind/,dqaiqq,company_culture_rarely_changes_the_reason_behind,dfphd,0.97,192,2019-11-01 22:14:27,0,28,,"I've worked several jobs in my life, and one of the things that I have heard discussed, pitched, sold, bought at every one of them was their idea of a company culture.""We're a company focused on innovation and teamwork"".""We are a team that is committed to going above and beyond""Companies, teams and people will self-assign core values and philosophies as easily as they put on clothes, and there is a general feeling that if you say it enough times, that becomes your culture.But it isn't, and the very definition of company culture - the real definition - is the same reason why company culture rarely changes.The real company culture is the set of behaviors that get people hired and promoted*It's that simple. If you declare yourself an ""innovative culture"", but you promote the people who are most willing to defend the old way of doing things... you're not. If you declare yourself of being a high performing culture, but the people that work themselves to death get passed for promotions by the people who play politics, then you're just a political culture. If you declare yourself to be a company that believes in family values, but has VPs that demand their employees to work nights and weekends to meet deadlines... you get the point.Most importantly, because the people that exhibit these behaviors get hired and promoted faster than the people who don't, your organization will always put its future in the hands of the people who live that culture - the real culture. And that means that it will be incredibly rare for someone to be in a position of authority that is willing - let alone able - to challenge that culture. And that is because, by definition, what got them there is the culture.Why are you posting this?Because my current role is one of the few I've had where I have felt happy with the culture, and what it made me realize is that at several of my previous stops I subconsciously was waiting for the culture to change. In some cases, it was their viewpoints on work-life balance. At other stops, it was their commitment to data literacy.And those things never changed, and even after I have left and looked back several years later, they haven't changed. And this includes organizations that have had changes at the C-Suite level - several of them.If you are not happy with your company's culture today, you need to start looking for a new job yesterday, because you are on a ride that will make you more and more frustrated each day until you explode.And you don't need to do that to yourself. There are too many jobs out there, too many companies to subject yourself to a company culture that doesn't jive with you. More importantly, there are 100% companies out there with healthy cultures that can foster a good career for data scientists, regardless of what your personal preferences as far as work-life balance and everything else might be.Ok u/dfphd*, you mentioned something in the title something about changing company culture. How do you do that?*Note - this only works in a subset of cases:Live the values the company wants you to live when everyone outside your team is watching (i.e., get all your work done the way the company wants it done when people are looking)In private, conduct yourself (and your team if you have one) according to the values that you think the company should value and deliver outstanding results while doing so.You have a company that doesn't value innovation, but rather producing the same 1000 reports every day? Well, keep producing the same 1000 reports every day, but then in ninja mode, come up with an alternate solution that does away with the 1000 reports. And then implement it, and make everything better, and have a bunch of people give it glowing support.And then do it again and again and again and again until you start infecting people around you and they want to get some of that same positive feedback you're getting.Caveats:It works a hell of a lot better if you're an executive. Or at least like an upper-middle manager (e.g., Director).It is exhausting both for you and anyone who you may manage.If you ever slip up on your primary work, you will get crucified for spending any level of effort on this other stuff, so you need to be flawless.Even if you do everything right, it may not work.* This definition is stolen from the Manager Tools podcast - probably somewhat paraphrased.",,
385,https://www.reddit.com/r/datascience/comments/dqlwbo/can_finance_student_with_a_computer_science_minor/,dqlwbo,can_finance_student_with_a_computer_science_minor,Ultreak,0.75,2,2019-11-02 16:43:48,0,10,,"Hello, I am a Finance student who just recently got interested in becoming a Data Scientist after doing few courses for my Computer Science minor. Despite not having a computer science or statistics, and having unrelated degree such as finance, would it be plausible to land a job in this field assuming that I will be taking courses including Applied Algorithms, Data mining,  Machine Learning, etc. As to those wondering why don't I just change my major to Computer science, it's simply because I'm already half way done with my degree and I feel like it would be a waste if I just start everything over again. So yeah, I would like to hear your opinion on this, would it be reasonable if I want to land a job on Data science field with a finance degree.Thanks in advance.",,"Discussion,"
386,https://www.reddit.com/r/datascience/comments/dqxh4v/need_smart_people_and_ai_to_solve_a_major_problem/,dqxh4v,need_smart_people_and_ai_to_solve_a_major_problem,mursalleen,0.22,0,2019-11-03 08:58:25,0,1,,"I apologize in advance if this isn't the right subreddit for queries like this. But I know that you are just the right audience to help us tackle this issue.So, here it is:We have a problem and we need ideas from smart people to help us tackle this. So if you all could spare a few minutes and think about this one, you could save LIVES.I am working with the hardworking and important people government in my country in Southeast Asia.So, in my city we used to have a with a lot of crime. Terrorism.So to prevent it, we installed these 'checkposts' on several roads. They were like blocks to make cars go through, slowly, so the police could examine them closely and stop anyone if they seemed suspicious.The checkposts looked like this: https://www.samaa.tv/wp-content/uploads/digital_news/2011-12-20/police-night-check-posts-in-islamabad-9739.jpgand thishttp://www.infochangepakistan.net/Data/Sites/1/FolderGalleries/infn-pix-1-13.jpgWe also did major cleanup operations against terror organizations and gangs and terrorism dropped so much. There's barely any terrorism here anymore.So, we don't feel the need for extensive checkposts anymore.And the we are getting rid of the checkposts and we want to replace it with technology.So if any of you have any good ideas as to how that could be done, then that would be much appreciated.If you could engineer a solution, own an AI company or know someone who knows an AI company or know anyone that could help, we'd love to work with you.Remember: We need a replacement for checkposts so keep that in mind. The checkposts had a few policemen. They were there at night as well. So we need, through technology, pairs of eyes that can look at night. We also need some way to distinguish between suspicious cars. So it should have a way to check for explosives. Perhaps, radiation?I was thinking a whole network of cameras equipped with Artifiical Intelligence and Machine Learning, that can also monitor all the spectra of light coming out of cars, to see what was in the car and check for explosives, and all the cameras across the region communicate with each other and log in every face through facial recognition and every car and number plate they see.But, I'm still unsure about my idea.That's where I need smart people like you to pitch in their ideas. Remember, this is for the security of ordinary people and your good idea could save lives, so every idea is valued. Get in touch in the messages section here on reddit. THANK YOU.",,"Discussion,"
387,https://www.reddit.com/r/datascience/comments/dq7qbh/interview_prep_help_stats_heavy/,dq7qbh,interview_prep_help_stats_heavy,GreenerCar,0.91,36,2019-11-01 18:50:54,0,14,,"Hello I am in contact with Google for a data science position and the phone interview will be stats heavy. Can anyone recommend me some resources to go over the stat concepts of:Probability Hypothesis testing Stat modelsExample question: one product was discounted %10 this past weekend, was this promotion was successful ?Example question: describe a data science project you worked onExample question: what stats model would you fit to this data ?the rest will be problem solving, data and coding. I picked python as programming language.Many thanks.",,
388,https://www.reddit.com/r/datascience/comments/dq68kn/are_there_downsides_to_querying_sql_in_rpython/,dq68kn,are_there_downsides_to_querying_sql_in_rpython,oldmangandalfstyle,0.9,36,2019-11-01 17:03:14,0,47,,"I am new to the industry side of analytics and I find most interfaces for using SQL to be atrocious. But, in R for example I can query into an object and then manipulate with the tidyverse which is pretty efficient.Are there downsides to this I'm not seeing? With massive data pulls I understand this is not feasible after a certain point, but it seems Rstudio is so much more user friendly when applicable. I can't tell if I'm being lazy and resisting using a SQL software directly or if I am fine querying through R or Python.",,
389,https://www.reddit.com/r/datascience/comments/dqcya9/opinions_on_data_camps_insights_data_incubator/,dqcya9,opinions_on_data_camps_insights_data_incubator,isison,1.0,7,2019-11-02 01:23:40,0,4,,"I am wondering what are the opinions and common attitudes toward data camps (Insights Data Science, Data Incubator, etc.) today? Are they still as competitive and reputable as before? Are companies interested in hiring their graduates today?I am thinking about joining one of these. Just wondering if it's worth the time....",,"Career,"
390,https://www.reddit.com/r/datascience/comments/dqdmep/oss_great_expectations_just_released_a/,dqdmep,oss_great_expectations_just_released_a,superconductiveKyle,1.0,6,2019-11-02 02:20:50,0,2,,"Check out this really great tutorial/blog on how to implement the ""Self-Updating Data Dictionary"". Its pretty awesome for how low friction it is to implement. Solid tool to maintain transparency across the data engineering / data science team  and whoever else interacts with them.Read hereTheir Github",,"Tooling,"
391,https://www.reddit.com/r/datascience/comments/dpyr2l/has_anyone_transitioned_to_software_engineering/,dpyr2l,has_anyone_transitioned_to_software_engineering,Ballsfor11days,0.96,151,2019-11-01 04:18:28,0,47,,"How'd you do it?I'm toying with the idea for a few of reasons:The ""data science"" at my company devolved into more analytics than anything else. I've had to continue take courses outside of work to keep the actual data science skills fresh (stats, machine learning, deep learning) but barely get to apply them and it's a real bummer. At this point, I'm sure it'll be pretty hard to get into a ""real"" data science job if I try to transition. Though it seems that data science roles are becoming more product/marketing analytics which isn't too exciting, and I don't think I'm smart enough for the hardcore phd-level research scientist rolesI've had a lot of exposure to the data engineering side. ETLs, AWS infra, version control, various APIs, unit testing, pushing things to production, etc. and I find the process of building something from scratch and collaborating with the data engineers really funI want to be more on the back end and middle of the data spectrum. Pure modeling and analytics is the front-end, and I feel that only very mature companies have the infrastructure set up correctly for data science to be able to unlock its true potential. More job opportunities in the back end/middle for startup and growth stage companies, which i've been liking so farAs far as skill combinations go, software engineer + data guy seems like a pretty deadly combo for future successWhat's the best process to go about this? I'd consider myself decent at leetcode-easy problems and have a very basic understanding of cs fundamentals. Not sure if I should focus on leetcode, or building a complete application to showcase, or pick up another language (I'm 99% python, 1% Scala and JavaScript), or just edit my resume to highlight the engineering side of things and pray n' spray?I have a good relationship with the tech side in the company so I can explore possibilities there, but also would like to set myself up with a good foundation to transition to swe in 3-6 months so any guidance would be greatly appreciated!",,
392,https://www.reddit.com/r/datascience/comments/dqg67c/i_am_taking_a_bootcamp_data_analytics_program_and/,dqg67c,i_am_taking_a_bootcamp_data_analytics_program_and,ICanFakeLove,0.5,0,2019-11-02 06:39:11,0,11,,"First of all, I don't know if this is the right place to post this, if it isn't recommendations for subreddits to ask this would be greatly appreciated.As the title says I am starting a bootcamp program for data analytics. I have done a lot of research on jobs and it's something I am interested in.I want to take what i learn from this program and become a data scientist. Is that a job you look for with no experience (other than what i get from the program) or is this something you work up to being from say a data analyst?I understand that data analytics is something used virtually everywhere, I would prefer not to just help business's make more money. My goal is to see if I can help the world out a little bit with my training and education. I have seen that the CDC has a lot of open positions for Data Analysts. What are some other Examples of jobs in Data Analysis where I can do some good?Thanks for answering my stupid questions!",,"Career,"
393,https://www.reddit.com/r/datascience/comments/dqeygg/multivariable_calculus/,dqeygg,multivariable_calculus,therockhound,0.4,0,2019-11-02 04:25:16,0,12,,"Hey all,I recently converted over from a domain expert to a data scientist in the same industry and am starting to plan out what I should learn in my spare time. The goal is to learn things that will hopefully be useful in the near future, but will also make sure that I have the foundation I need to have a long career in ds.Never got around to taking multi-variable calc in college. Its been years since I took Calc I and II. I want to understand deep learning/optimization better, so knowing this material seems important. Any recommendations for resources of sufficient depth? Should I spend the time retaking the first two or would my time be better spent somewhere else (focus on comp sci or stats, etc.)?Thanks!",,"Education,"
394,https://www.reddit.com/r/datascience/comments/dpymvt/biggest_classifier/,dpymvt,biggest_classifier,SynbiosVyse,1.0,11,2019-11-01 04:07:42,0,10,,"I'm working on training a NN classifier with about 3,000 classes and over 100 million labelled observations. What's the biggest classifier you've ever worked on or seen? Do you have any rules of thumb to determine the number of obs you need per class and the corresponding size of the NN?",,
395,https://www.reddit.com/r/datascience/comments/dpmfiw/as_someone_working_with_data_what_are_the_most/,dpmfiw,as_someone_working_with_data_what_are_the_most,leenas9,0.96,126,2019-10-31 12:54:03,0,95,,"Data being such a critical (and now integral) part of our lives today, I'd be interested in learning about the fears of working with data.P.S. I definitely didn't try to time this with Halloween.",,"Discussion,"
396,https://www.reddit.com/r/datascience/comments/dq2m99/what_is_the_first_question_you_ask_to_see_if/,dq2m99,what_is_the_first_question_you_ask_to_see_if,shakakaZululu,0.47,0,2019-11-01 11:55:24,0,5,,,,"Meta,"
397,https://www.reddit.com/r/datascience/comments/dpvgq4/iso_best_way_to_make_a_dataset_available_to/,dpvgq4,iso_best_way_to_make_a_dataset_available_to,gregothegoat,1.0,2,2019-10-31 23:52:45,0,6,,The company I work for as Data Science Manager is sitting on what is probably the biggest and cleanest dataset in our market.We would be ready to make it public as long as users would accept some terms and conditions.I would like to avoid developing/maintaining a new service for this.Our Data Engineering team mentioned git LFS but it only handles 2 gbs max files at a time. Kaggle doesn’t offer the features our legal team requires. AWS Open Data only as a “license” field to specify the licence agreement for the dataset which far from ideal.Do you know a way/service to do it simply?,,
398,https://www.reddit.com/r/datascience/comments/dppflh/would_taking_a_data_engineering_job_be_a_good/,dppflh,would_taking_a_data_engineering_job_be_a_good,fuzzywunder,0.78,5,2019-10-31 16:49:45,0,12,,"I currently work as a statistician and have employed some data science techniques into my work. In use R, SQL, git and Azure Dev ops and I’ve also been doing a bit of data engineering work in SQL.I’ve been offered a potential move into a data engineer role. Although it isn’t exactly what I want to be doing (I would eventually like a data science role) it still looks very interesting and I thought it might be a good basis to keep developing my data science skills and programming skills.I have applied for a few data science roles but have been pipped to the post by other candidates because of my lack on experience in building ds models.So my questions is, is this a move in the right direction? Would having a really good understanding of data engineering help me to develop my data science career?In some places I’ve read that data engineering and data science cross over a lot so it sounds like it could be a good move.Any data engineers and data scientists out there that can offer any information?Thanks!",,
399,https://www.reddit.com/r/datascience/comments/dpuahd/which_cloud_platform_to_learn/,dpuahd,which_cloud_platform_to_learn,SimpleScribbler,0.75,2,2019-10-31 22:29:36,0,6,,"I am a data analyst who has so far worked exclusively on prem, but I'd like to get some professional development on either AWS, GCP or Azure.  From reading, it sounds like AWS is the established cloud giant, but that Azure and to some extent Google have some interesting data science and data engineering offerings.Any advice on which of the three a noob should start learning with an eye to the future?",,"Education,"
400,https://www.reddit.com/r/datascience/comments/dpv72l/does_anyone_have_experience_using_a_rand_model_to/,dpv72l,does_anyone_have_experience_using_a_rand_model_to,rekon32,0.67,1,2019-10-31 23:33:08,0,16,,"We have a SAS process that uses a RAND model to predict race/ethnicity based on first name, last name and longitude/latitude of address. Our process is manual and I want to streamline it. Does anyone have experience doing this using Python or R?EDIT: I found what I needed in Python",,"Projects,"
401,https://www.reddit.com/r/datascience/comments/dpuukb/trend_vs_interpolated_values/,dpuukb,trend_vs_interpolated_values,pragmatichuman,0.67,1,2019-10-31 23:08:06,0,4,,"I'm trying to figure out what the difference is between trend values and interpolated values in climate data. Sorry if this is a bit basic, I can't seem to find an answer. Can anyone help?",,
402,https://www.reddit.com/r/datascience/comments/dpkeby/what_is_the_name_of_this_type_of_data/,dpkeby,what_is_the_name_of_this_type_of_data,majhar_bd,0.6,3,2019-10-31 09:05:42,0,5,,https://  youtu.be/eP88FUL7d_8,,
403,https://www.reddit.com/r/datascience/comments/dpg17g/visa_data_science_hackerrank_test/,dpg17g,visa_data_science_hackerrank_test,kireeti_,0.76,9,2019-10-31 01:56:05,0,3,,I've got an online hackerrank test (100mins) for a data science position. There wasn't any information about what it would contain. I have already reached out to the recruiter but they didn't reply yet. Does anyone have an idea of what it would have?,,"Job Search,"
404,https://www.reddit.com/r/datascience/comments/dpoof0/best_way_to_graphically_visualize_my_data_is_any/,dpoof0,best_way_to_graphically_visualize_my_data_is_any,DaveUA,0.25,0,2019-10-31 15:55:58,0,19,,"I have this data set for example. What would be the best way to visually represent it?I have the following columnsStoreName, Account_Number, TripnumberSuch asStore    Account    Tripnumber
A            123         1
A            456         1
B            123         2
C            123         3
C            456         2
Would there be further processing needed as well?",,
405,https://www.reddit.com/r/datascience/comments/dp85wx/where_do_you_find_your_datasets/,dp85wx,where_do_you_find_your_datasets,root_j,0.89,37,2019-10-30 16:19:02,0,21,,"I am looking for reliable data set sources. Google Datasets used to be really great when it first launched, but it seems the only available datasets that meet my criteria are from Statista, which costs over $500 a year for access. It almost feels fake how accurate their proposed datasets are to my query, but nothing else seems to be available. Any suggestions on where I could find datasets related to Collaboration, Startups, Virtual and Augmented Realty, or Social Media usage?Thank you!",,"Discussion,"
406,https://www.reddit.com/r/datascience/comments/dpho7l/ab_testing_webpages_in_industry/,dpho7l,ab_testing_webpages_in_industry,Trodolfo-banderas,0.83,4,2019-10-31 04:06:17,0,5,,How do companies A/B test webpages? Do they use websites like optimizely or firebase where you insert page A and page B and it does it for you or do they actually go through the statistics of running A/B tests?,,"Education,"
407,https://www.reddit.com/r/datascience/comments/dpdlcd/data_is_unbiased/,dpdlcd,data_is_unbiased,Philnormous,0.67,4,2019-10-30 22:57:00,0,21,,"Overhead the quote below and wanted people to chime in on the data is unbiased topic.“Data in nature cannot be unbiased, because it would then just be homogenous. It would all be the same. It couldn't be 0 because that's a ‘0-bias’, and it couldn't be 1 because that's a ‘1-bias’ “",,"Discussion,"
408,https://www.reddit.com/r/datascience/comments/dp7uxt/the_history_of_data_a_critical_essay/,dp7uxt,the_history_of_data_a_critical_essay,gds506,0.67,3,2019-10-30 15:56:50,0,1,,,https://www.nature.com/articles/d41586-019-03062-w,"Meta,"
409,https://www.reddit.com/r/datascience/comments/dpdmar/hey_guys_newbie_question_here/,dpdmar,hey_guys_newbie_question_here,Jv-94,0.38,0,2019-10-30 22:58:53,0,5,,"Hey everyone, I know this might look like a stupid question but ilegit don't know the answer and couldn't find it with the regular googling, is there a name for those KPI's that are better the higher the number from those that are better the lower the number? A friend came up with the question and I didn't know what to answer",,
410,https://www.reddit.com/r/datascience/comments/dor406/opinions_on_data_science_at_consulting_companies/,dor406,opinions_on_data_science_at_consulting_companies,imadeitnice0518,0.98,142,2019-10-29 16:06:24,0,77,,What are people's opinions on working as a data scientist at consulting companies? I recently got into the final round of interviews at KPMG's Lighthouse Analytics group. I'm not sure I want to move forward because I haven't heard great things about working as a technical person at consulting companies.I should also mention that I'm hesitant to move forward because I have a job offer from the company I worked at over the summer and my deadline to decide is coming up.Any insights or advice would be awesome!,,"Discussion,"
411,https://www.reddit.com/r/datascience/comments/dp4jzm/google_brings_in_bert_to_improve_its_search/,dp4jzm,google_brings_in_bert_to_improve_its_search,ordinot,1.0,3,2019-10-30 10:53:38,0,1,,,https://techcrunch.com/2019/10/25/google-brings-in-bert-to-improve-its-search-results/,
412,https://www.reddit.com/r/datascience/comments/dp6guj/best_nlp_project_as_precursor_for_chatbot_project/,dp6guj,best_nlp_project_as_precursor_for_chatbot_project,paranoiddandroid,0.5,0,2019-10-30 14:05:20,0,3,,"I'm in a data science bootcamp and planning on creating a gift recommendation chatbot for my final project. However, we are tasked with completing an NLP project before our final and I figured I would get a head start on the types of workflows I'll be employing for my chatbot project. I'm planning on using Rasa with a spaCy NLU model. What types of projects would best prepare me for creating a chatbot? Something like sentiment or intent analysis? Exercises in NLU? Perhaps I should be training models on e-commerce text data and clustering to get a head start?I appreciate the advice, thanks.",,"Projects,"
413,https://www.reddit.com/r/datascience/comments/dowiw6/as_data_scientists_what_kinds_of_professional/,dowiw6,as_data_scientists_what_kinds_of_professional,scivet16,0.95,14,2019-10-29 22:24:51,0,2,,I just started a job as a Data Scientist a couple of months ago and my manager recently asked me to start thinking about how I want to develop professionally. So I'm curious how you guys go about these discussions - what kinds of things are important to you to develop your career? How do you expect your manager to facilitate that path? What do you ask to learn and get exposure to?,,"Career,"
414,https://www.reddit.com/r/datascience/comments/dp4j2m/anyone_heard_of_virtualitics_whats_your_opinion/,dp4j2m,anyone_heard_of_virtualitics_whats_your_opinion,iluve,1.0,1,2019-10-30 10:51:10,0,1,,"Came across this https://www.virtualitics.com/ and my first thoughts were that it looks like it's ""too good to be true"" and that it seems to offer that it can do everything? I'm trying to figure out what it actually does and find any reviews by people who actually use it as I'm curious. Is it just a visualisation platform with some ML gimmicks?",,"Discussion,"
415,https://www.reddit.com/r/datascience/comments/dp1ps2/remote_data_scientist_salary_vs_remote_full_stack/,dp1ps2,remote_data_scientist_salary_vs_remote_full_stack,hehe_okay,0.43,0,2019-10-30 05:08:42,0,2,,"Has anyone seen/have experience with salaries for both, as a fully remote Engineer in the US with ~years exp. I'm seeing around 150k being pretty high (I'm low 140s now). Was curious if I begin down the road or AI/Data Science / ML if I can break out past the 160+ mark. Any experience? Base salary + bonus",,
416,https://www.reddit.com/r/datascience/comments/dp08sk/interpretability_vs_performance_tradeoff/,dp08sk,interpretability_vs_performance_tradeoff,tacothecat,0.43,0,2019-10-30 03:00:14,0,24,,"I recently had a VP question my use of a gradient boosted model in place of GLMs to which he is accustomed.  He wanted to know how much ""better"" the model was in order to justify the perceived loss of interpretability.  I have no idea how to answer that question, besides showing things like double lift charts, improved loss metrics, etc.  How would you respond?",,
417,https://www.reddit.com/r/datascience/comments/doo8qc/flourish_data_visualisations/,doo8qc,flourish_data_visualisations,OddCap,0.9,16,2019-10-29 12:04:06,0,12,,There are many youtube videos out there with bar chart races. I am wondering if using Flourish is ok to produce these and upload to youtube? Are there any limitations?Thanks all,,"Discussion,"
418,https://www.reddit.com/r/datascience/comments/doot3g/what_current_trends_do_you_see_happening_now/,doot3g,what_current_trends_do_you_see_happening_now,Darkilluzion,0.73,10,2019-10-29 13:03:02,0,33,,"One my current fascinations is data derived from wearables.  Things like smart watches, VR etc. I think it’s such a big space and excited to see the data we’d be able to obtain from it.I don’t think the tech is quite there yet to obtain anything too groundbreaking, but once were able to properly implement tech akin to a symbiosis there will be so much we can learn, especially in the healthcare industry.",,
419,https://www.reddit.com/r/datascience/comments/dopwl0/applications_of_sentiment_analysis_in_companies/,dopwl0,applications_of_sentiment_analysis_in_companies,lucifer_1618,0.82,7,2019-10-29 14:36:08,0,8,,"Hola,I am curious about use cases of Sentiment Analysis in companies.Is it using classification algorithms on labelled data or VADER sentiment analysis on unlabelled text data?If it is labelled data, how is the data labelled? Mechanical Turk or just use pre-labelled data (Amazon, IMDb reviews)?How is the data collected? Company website + Social Media?End-goal of the project? Is it just gauge the overall sentiment or to take specific action on the product in question?A brief overview would be much appreciated.",,
420,https://www.reddit.com/r/datascience/comments/do8jkb/definitions_of_overfitting/,do8jkb,definitions_of_overfitting,MrTwiggy,0.94,76,2019-10-28 14:03:20,0,57,,"Recently came upon a paper (and blog post) that talk about how boosted models don't overfit:  https://jeremykun.com/2015/09/21/the-boosting-margin-or-why-boosting-doesnt-overfit/This made me curious though, because they seem to be using a similar, but different definition of overfitting than I typically use. I'm curious what other people tend to think of overfitting as. The two primary definitions I've seen:A model is overfitting when (during the course of training) the validation error begins to increase while the training error continues to decrease.A model is overfitting when (after training) the validation/test error is much larger than the training error.Personally, I see the 2nd definition as being more true to what overfitting actually is, and is also the more practical of the two. Overfitting is a tool that can be used to determine how to continue hyperparameter searching in the right direction (for example, introducing regularization if there is high overfitting). Whereas the first definition, seems more like a vanity point.It seems to me that it is spurious to make a claim like 'boosted models don't overfit' because that would imply that they don't ever need to be regularized in order to achieve the best performance, which seems patently false.EDIT: To clarify my position. I believe that #1 (validation error increasing during training) is an indicator that overfitting has occurred. So if you see #1, then you can probably say there is overfitting. However, if you don't see #1 (e.g. validation error doesn't increase during training), you cannot conclude that there is no overfitting. I'm curious if others agree with this?EDIT EDIT: Just to clarify a little further, as I may have been misleading in my post. I am not saying that #2 is the true definition of overfitting necessarily, but rather that it is one of the best estimators we have for a model's error variance (e.g. overfitting component). I added a comment below that gives what I think is the real mathematical definition of overfitting/underfitting is.",,"Discussion,"
421,https://www.reddit.com/r/datascience/comments/dojti4/hoping_to_gain_some_infoguidance_from_people_with/,dojti4,hoping_to_gain_some_infoguidance_from_people_with,oldpoz,0.89,7,2019-10-29 03:44:22,0,10,,"Hello! I have recently become interested in Data Analytics and am considering pursuing it as a career.  My background is in physics. Although I have been doing some of my own internet searching for information there is a lot out there to sift through.  So, I have the following questions:What are some good resources to learn more about the field and its applications? Is there a niche for Data Scientists/Analysts related to the field of physics/engineering? What courses might be applicable to my interests and what are some trustworthy resources for exploring them?Any insight or recommendations would be much appreciated! Thank you.",,
422,https://www.reddit.com/r/datascience/comments/doakx4/centralizing_your_companys_data_in_one/,doakx4,centralizing_your_companys_data_in_one,Lostwhispers05,0.93,45,2019-10-28 16:43:12,0,46,,"With all the various Cloud storage options and whatnot, what is your favoured option of storing everything in one place so it can be readily pulled for working with?At work, we store our Data in a MySQL DB (which is where info inputted into our products instantly go), and a CRM (we use Zoho CRM). Having to work with the 2 is a nightmare, which really highlights to me the need to be agile in drawing any info you need from your data. This is uniquely painful to me because I am so far one of the only people having to work with both sources.I'm curious about measures other people have taken to consolidate all their data in one place (for instance I'm trying to pull Zoho CRM data into MySQL) so it can be easily pulled (I'm trying to pull everything into Power BI for easy analysis).What options towards this end have you guys explored, and how successful have they been?",,
423,https://www.reddit.com/r/datascience/comments/dome2l/interesting_tv_rating_data/,dome2l,interesting_tv_rating_data,bestminipc,1.0,2,2019-10-29 08:20:58,0,4,,where is this site getting the rating data?https://www.ratingraph.com/tv_shows/the_bachelorette-116174/https://www.ratingraph.com/tv_shows/the_bachelor-110589/,,"Education,"
424,https://www.reddit.com/r/datascience/comments/dokya8/what_foundation_do_you_need_to_get_into_data/,dokya8,what_foundation_do_you_need_to_get_into_data,nericksx,0.72,3,2019-10-29 05:29:13,0,12,,"I've been a front-end developer for 20 years, but I'm looking into a career change and I'm wanting to enter the Data Analytics field. I have questions about what is the most efficient way to get trained. It seems like there are 3 options: 1) Get a Masters in Data Analytics, 2) do a 6 month boot camp (I like one from Dartmouth) , 3) take courses from a MOOC. I'm wondering what hiring managers look for. Is a degree necessary? Does a bootcamp certification program mean anything? Or is it just about an amazing portfolio, so MOOC can do the trick. Any insight is greatly appreciated!",,
425,https://www.reddit.com/r/datascience/comments/doawf2/factorscategoricals_in_sklearn_with_decision_trees/,doawf2,factorscategoricals_in_sklearn_with_decision_trees,jaredstufft,0.97,30,2019-10-28 17:06:19,0,14,,"Hi everyone,I'm looking for a solution for what I think is probably a common problem with categorical data in Sklearn. When it comes to model proto-typing, I am typically an R user but have been developing software in Python for about 7 years.I want to create a single decision tree for a task. The majority of the data are categorical features. The decision tree is going to be used by people rather than a machine, so keeping the depth of the tree limited is important.In R, we have the factor data type as a way to encode categorical features. When a split in the tree (using the rpart package) is made, it can take multiple factor levels into account for one split. For example, you might see a split being 'Browser = Chrome or IE or Firefox' where we essentially use one split for three levels of the factor.If we compare that to Sklearn - there is no factor data type. All the suggestions I've seen have been to use one-hot/dummy variables, which is fine... except, the same situation now takes three separate splits -- 'Browser = Chrome', 'Browser = IE', and 'Browser = Firefox'. Given that I need to keep the depth of the tree limited, this feels like an inefficient use of my depth 'budget'.However, Sklearn provides a more convenient hyperparameter tuning scheme, particularly for decision trees, and most of my colleagues are pretty much entirely Python users so I'd like to do this in Python so it's easier to share the work. Is there any other encoding method, package, or workflow that can help me solve this problem with Python/Sklearn? I know pandas has a 'categorical' data type, but IIRC it just maps the levels to a sequential integer, which has its own set of problems.",,"Discussion,"
426,https://www.reddit.com/r/datascience/comments/doadsg/good_resources_to_read_about_data_science/,doadsg,good_resources_to_read_about_data_science,LonzosJumpshot,0.95,28,2019-10-28 16:28:25,0,11,,"Hi r/datascienceI'm looking to potentially study Social Data Science or Business Analytics in the U.K for my masters one day in the future, but I don't have much experience/knowledge of data science (traditional economics undergraduate). I've been working on my programming skills, but I'm hoping to start reading to learn more about social data science as a whole.As such I'd like to get insights into data science topics of interest and what conversations are currently happening in the industry (preferably in the context of business and/or social sciences) that aren't just meaningless buzzwords.What are some good publications/journals/websites/blogs (etc) to read?",,
427,https://www.reddit.com/r/datascience/comments/dokhj0/need_help_with_understanding_how_to_run_a/,dokhj0,need_help_with_understanding_how_to_run_a,mrdlau,0.33,0,2019-10-29 04:44:02,0,5,,"I've been trying to learn tensor flow for the past couple days and I can't seem to figure the part of the code where you run the session.  i,e . ""With tf.Session() as sess: ....."" etc etcBasically, I'm following a standard MNIST tutorial I found online, but I'm trying to repurpose it with my own data as that will help me understand it better (and also, i dont work with image data that much, so I'm using a logistic regression type problem (predicting 0's and 1's).The part of the code that I dont get is this:        for epoch in range(hm_epochs):
            epoch_loss = 0
            for _ in range(int(mnist.train.num_examples/batch_size)):
                epoch_x, epoch_y = mnist.train.next_batch(batch_size)
                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})
                epoch_loss += c

            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)
This is after you set up all your layers, and after you initialize session and the global variables.I dont understand lines 3 through 5.what is ""_"" and what is mnist.train.num_examples/batch_size?what is mnist.train.next_batch(batch_size)?Basically, if I was using my own data (X_train, X_test, Y_train, _test, I dont know what to put in place of the ""mnist"" sections.in the tutorial, I dont think I saw ""mnist.train.num_examples"" or mnist.train.next_batch get declared anywhere, so I'm not sure where those came from.  Are these variables or are these methods off of the variables?Just for reference, here's the tutorial I'm following along onhttps://pythonprogramming.net/tensorflow-neural-network-session-machine-learning-tutorial/?completed=/tensorflow-deep-neural-network-machine-learning-tutorial/",,"Education,"
428,https://www.reddit.com/r/datascience/comments/do04nc/kaggles_2019_data_science_bowl_is_now_live/,do04nc,kaggles_2019_data_science_bowl_is_now_live,postscarce,0.99,184,2019-10-27 23:26:31,0,20,,,https://www.kaggle.com/c/data-science-bowl-2019,
429,https://www.reddit.com/r/datascience/comments/dogdnr/limitations_of_python_lists/,dogdnr,limitations_of_python_lists,helloreddits456464,0.33,0,2019-10-28 23:13:33,0,7,,"Apologies in advance if this is a stupid question.How far can you get programming in base python? For example, the run time on this code was 27 seconds and it's orders of magnitude higher than some smaller data sets that I've seen.df = [x**15 for x in range(10000000) ]print(sum(df))",,"Discussion,"
430,https://www.reddit.com/r/datascience/comments/dnmlyz/without_exec_buy_in_data_science_isnt_possible/,dnmlyz,without_exec_buy_in_data_science_isnt_possible,da_chosen1,0.97,612,2019-10-27 02:03:41,0,65,,,,"Education,"
431,https://www.reddit.com/r/datascience/comments/dnvs1e/colleague_has_generated_a_dangerous_ml_tool_help/,dnvs1e,colleague_has_generated_a_dangerous_ml_tool_help,Katdai2,0.73,14,2019-10-27 17:31:00,0,43,,"Hi all, I need help with a situation.I am the only data scientist in my company, and although I have a PhD specifically in applying data science in my domain area, I have only been at this company for 3 years.  I have a colleague who has been caught up in the “AI/ML” craze who is a hobbyist programmer. He received permission and has been working this year on interfacing with a certain database and creating a user interface for a ML process optimization tool. I was supposed to help with the “ML” part by helping guide him in how to curate and clean data, generate a model, and implement that model in a sustainable fashion.Instead, he has created his own version, a Frankenstein-ish ensemble of models that is completely uninterpretable. The data he used is unreliable and ripe with unstated assumptions and human interaction; it is not representative of the underlying truth and cannot be safely used to predict future performance the minute any changes arising from the current model are applied. Further, the application is such that problems mean explosions, not just loss of revenue. At best, he’s generated a poor model; at worse, a dangerous one.He’s already demonstrated this tool to management and the VP in charge of the process. He wants to move forward with field trials next month. I found out on Friday. What now?",,
432,https://www.reddit.com/r/datascience/comments/do1ajp/best_visualization_practice_multiple_plots_in_a/,do1ajp,best_visualization_practice_multiple_plots_in_a,feelosophy13,1.0,3,2019-10-28 01:06:11,0,4,,I have two plots: a box plot and a histogram.They are two different representations of the same data. Is it advisable to have them both on a single PowerPoint slide? Or should each plot have its own slide?Having both in the same slide is concise but possibly confusing. Having them in separate slides is clear but possibly redundant.Any thoughts?,,"Discussion,"
433,https://www.reddit.com/r/datascience/comments/do0qm6/need_advice_automizing_report_in_python/,do0qm6,need_advice_automizing_report_in_python,naxoasdf,0.76,2,2019-10-28 00:15:57,0,7,,"Hi, I'm doing a proyect that involves automizing an análisis report from large  Excel data, it's just a boring and repetitive task that involves making some plots AND graphs, I'm currently struggling on where to start, mainly bcause I'm totally new to programming, Python and data science. I've already done some courses on datacamp, plus some basic use of pandas AND seaborn libraries. But I'm currently not sure on where to start  AND what to use for making the report AND save each plot. Any Advice ir example you give me Is usefull as i,'m currently lost.",,
434,https://www.reddit.com/r/datascience/comments/dntzx1/im_looking_for_successfailure_stories_applying/,dntzx1,im_looking_for_successfailure_stories_applying,shaypal5,0.78,5,2019-10-27 15:28:08,0,4,,"Hey everyone! :)As the title says, I am looking for both success stories and disappointing failures of applications of modern unsupervised document embedding techniques on actual problems (as opposed to academic benchmarks, toy datasets, academic evaluation tasks, etc.). The main focus is naturally on industry uses for business/product problems, but I would also love to hear about cases from government bodies, non-profits, use in research (with empirical measurement and where document embedding is one of the tools, not the subject of research) and any other ""real life"" use. I would love to hear about your experience, but connecting me to people you know or even hinting me towards companies or projects you know used these techniques (or tried to) would also be of tremendous help.What's in it for you? Well, I'm preparing a talk for the data science track of the CodeteCON #KRK5 conference based on my literature review-y blog post on document embedding techniques, and while I feel I have a pretty good overview of the academic papers, benchmarks and SOTA status up until the most recent stuff to come out in the field at this point in time, I can't say the same for uses in the industry; I have a partial view from my experience in one ongoing project to actually use this, and experience shared by some of my data scientist friends (all in Israel, naturally) - most of it, so far, by the way, is that averaging (good) word embeddings is a very tough ""baseline"" to beat.This is why I thought reaching out to get a better sense of things in the industry world-wide, and enriching my talk with the status of actual successes and industry applications will give people attending my talk more value, and will serve my attempt to make my talk a status report on the topic.And (coming back to WIIFM) naturally (I think), I intend to share any (share-able) knowledge I accumulate not only in my talk, but also by adding a section dedicated to it to the aforementioned blog post, and maybe even by writing an extended post around it (if enough interesting trends and issues come up). So, hopefully, if you are (like me) interested in this, we might also end up getting, together, a nice overview of where the industry stands at the moment.What modern techniques (so no variants of bag-of-words or topic modeling techniques) am I talking about? These are the ones that I know of (I'd love to hear about others!):n-gram embeddingsAveraging word embeddings (including all variants, e.g. SIF)Sent2VecParagraph vectors (doc2vec)Doc2VecCSkip-thought vectorsFastSentQuick-thought vectorsWord Mover’s Embedding (WME)Sentence-BERT (SBERT)GPT/GPT2 (can also be supervised)Universal Sentence Encoder (can also be supervised)GenSen (can also be supervised)Thank you and cheers,Shay :)",,"Discussion,"
435,https://www.reddit.com/r/datascience/comments/dnsbdx/weekly_entering_transitioning_thread_27_oct_2019/,dnsbdx,weekly_entering_transitioning_thread_27_oct_2019,datascience-bot,0.78,7,2019-10-27 13:00:28,0,149,,"Bleep Bloop. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki. You can also search for past weekly threads.I am a bot created by the r/datascience moderators. I'm open source! You can review my source code on GitHub.",,"Discussion,"
436,https://www.reddit.com/r/datascience/comments/dny6zz/how_to_code_neat_machine_learning_pipelines/,dny6zz,how_to_code_neat_machine_learning_pipelines,GChe,0.75,2,2019-10-27 20:21:48,0,0,,,https://www.neuraxio.com/en/blog/neuraxle/2019/10/26/neat-machine-learning-pipelines.html,"Tooling,"
437,https://www.reddit.com/r/MachinesLearn/comments/dnlulq/how_to_code_neat_machine_learning_pipelines/,dnlulq,how_to_code_neat_machine_learning_pipelines,GChe,0.92,31,2019-10-27 01:54:14,0,3,,,https://www.neuraxio.com/en/blog/neuraxle/2019/10/26/neat-machine-learning-pipelines.html,"EXPLAINED,"
438,https://www.reddit.com/r/datascience/comments/dnxdgd/question_about_data_storage/,dnxdgd,question_about_data_storage,TheNumberOneDuder,1.0,2,2019-10-27 19:23:24,0,5,,"Hi all,I've recently become interested in data science. I've got a data set with 100,000 data points. It's a single JSON file. I was wondering what you guys think is the best way to store this data ... should I convert it to a sql database? Convert it into a python data frame (I'll be doing analysis in python). Is there any way I can store the file remotely so others can query from it to?Thanks.",,"Tooling,"
439,https://www.reddit.com/r/datascience/comments/dni47i/does_anyone_else_notice_this_happening_with_data/,dni47i,does_anyone_else_notice_this_happening_with_data,j9jjrrrj2,0.82,83,2019-10-26 20:58:22,0,97,,"So, I currently work in business intelligence with a team of about 15 people and we support many departments in the company. About 8 or 9 months ago, the word came down from the top that DATA SCIENCE was going to be the hip new thing that everyone in BI was going to learn and master to help push the business forward. The idea was to create bootcamps led by senior data scientists to help develop new data scientists. Our leaders have been pushing managers to encourage us to go into these programs, but i've been pushing back big time saying a bootcamp is not going to work because it takes years to master these skills needed to be a good data scientist. I did have a chance to speak with the project manager and a couple leads in the program and I asked how important math was in this program and the response I got was you just need to know Stats 101 and you should be fine. I had asked about linear algebra and I got kind of a little bit of silence on the phone and someone said you don't need to know math at that level. Is it normal for companies to underestimate how much work is actually required to do data science? I mean, the math alone is some serious stuff. From what I could gather, a lot of the program is geared towards learning to write the code in python using existing models, tuning those models, but not really getting deep enough to understand all the math going on in the background. Isn't this kind of dangerous to make predictions of data without understanding all of the math going on in the background?",,"Discussion,"
440,https://www.reddit.com/r/datascience/comments/dnlzn5/what_are_some_great_examples_of_feature/,dnlzn5,what_are_some_great_examples_of_feature,BombBurper,1.0,10,2019-10-27 02:08:10,0,11,,I understand that feature engineering is probably the most important thing when it comes to the accuracy of your model. I'm looking to compile a large list of resources and instances where people have used creativity in examining relationships between their features like creating a new one that greatly improves the accuracy.Basically I want more examples of this so that I can improve my feature engineering,,
441,https://www.reddit.com/r/datascience/comments/dnqio8/help_with_a_new_data_pipeline_architecture/,dnqio8,help_with_a_new_data_pipeline_architecture,dreisel,1.0,1,2019-10-27 09:08:32,0,2,,"Hi guys,We are about to create our first data pipeline. I have a background in programming and l’ll like to hear what more experience people will suggest.Our goal: We have a k8s cluster which emit allot of logs, 90% of them are debugging logs but the other 10% are user events, for example user logged in, user logged out and user viewed page X.We need a way to display our users story, break down by sessions, (sessions are calculated by time on inactivity) and for each session we want to show how many page visited etc..We use fluentD to collect logs and send them forward in the pipeline.The catch is, that we want to display the data in realtime, thus if a new session is created we want to display it as fast is possible (indicating that this is an ongoing session) alongside ""old"" sessions (120 days).This part got me a bit lost, I read about tolls like spark that can pretty much do it but I’m missing the part of how to query the result in realtime alongside old passed sessions..Thanks!!",,"Discussion,"
442,https://www.reddit.com/r/datascience/comments/dn5uxq/amazon_data_scienceml_interview_questions/,dn5uxq,amazon_data_scienceml_interview_questions,abbey_chup_bakchod,0.98,334,2019-10-26 01:39:44,0,99,,"I've been trying to learn some fundamentals of data science and machine learning recently when I ran into this medium article about Amazon interview questions. I think I can answer some of the ML and probability questions but others just fly off the top of my head. What do you all think ?How does a logistic regression model know what the coefficients are?Difference between convex and non-convex cost function; what does it mean when a cost function is non-convex?Is random weight assignment better than assigning same weights to the units in the hidden layer?Given a bar plot and imagine you are pouring water from the top, how to qualify how much water can be kept in the bar chart?What is Overfitting?How would the change of prime membership fee would affect the market?Why is gradient checking important?Describe Tree, SVM, Random forest and boosting. Talk about their advantage and disadvantages.How do you weight 9 marbles three times on a balance scale to select the heaviest one?Find the cumulative sum of top 10 most profitable products of the last 6 month for customers in Seattle.Describe the criterion for a particular model selection. Why is dimension reduction important?What are the assumptions for logistic and linear regression?If you can build a perfect (100% accuracy) classification model to predict some customer behaviour, what will be the problem in application?The probability that item an item at location A is 0.6 , and 0.8 at location B. What is the probability that item would be found on Amazon website?Given a ‘csv’ file with ID and Quantity columns, 50million records and size of data as 2 GBs, write a program in any language of your choice to aggregate the QUANTITY column.Implement circular queue using an array.When you have a time series data by monthly, it has large data records, how will you find out significant difference between this month and previous months values?Compare Lasso and Ridge Regression.What’s the difference between MLE and MAP inference?Given a function with inputs — an array with N randomly sorted numbers, and an int K, return output in an array with the K largest numbers.When users are navigating through the Amazon website, they are performing several actions. What is the best way to model if their next action would be a purchase?Estimate the disease probability in one city given the probability is very low national wide. Randomly asked 1000 person in this city, with all negative response(NO disease). What is the probability of disease in this city?Describe SVM.How does K-means work? What kind of distance metric would you choose? What if different features have different dynamic range?What is boosting?How many topic modeling techniques do you know of?Formulate LSI and LDA techniques.What are generative and discriminative algorithms? What are their strengths and weaknesses? Which type of algorithms are usually used and why?”",,
443,https://www.reddit.com/r/datascience/comments/dnob5b/how_can_i_plot_a_network_from_a_correlation_matrix/,dnob5b,how_can_i_plot_a_network_from_a_correlation_matrix,blureglades,0.25,0,2019-10-27 04:45:53,0,6,,"Hello friends! I do hope my message finds you all well. I'm currently struggling trying to plot a correlation matrix as a network, to subsequently detect communities inside of it. What can I do to approach this? Thanks in advance.",,"Projects,"
444,https://www.reddit.com/r/datascience/comments/dnenrf/tranistion_advice_from_ml_engineer_bianalytics/,dnenrf,tranistion_advice_from_ml_engineer_bianalytics,darosati,0.72,3,2019-10-26 16:36:29,0,5,,"Hello there!I am working at a new job doing BI and analytics product development as a software engineer. Previously I had been doing ML startups in computer vision and nlp and that is my educational background. Though there is some basic cross over that I have a lot of knowledge in such as time series analysis and statistics - the tech stack (data warehouses/ adhoc querying ) and domain (cohort analysis, BI) is very unfamiliar to me.Can anyone recommend any resources for getting familiar with the domain and the tech stack? I need a comprehensive overview of product/customer analytics and resources about modern approaches to analytics architecture and infrastructure (appropriate for startups with limited resources).Thanks!",,
445,https://www.reddit.com/r/datascience/comments/dmzk3l/my_job_search/,dmzk3l,my_job_search,jbulka,0.94,126,2019-10-25 18:05:44,0,47,,"Hey everyone! Just thought I'd give people an idea of what the job search looks like when trying to get into data science. I applied for mainly data scientist positions, but also some senior data analyst positions (and this was the position I ended up accepting). Here's my background and the results of my job applications:Education/Skills: BA in Math and Economics, now mastering out of a quantitative social science PhD program. During my program, I've developed considerable expertise in econometrics and causal inference. I taught myself SQL and machine learning during the job search, and have used Python for about 4 years now. However, I have no industry experience.Applications: ~200-300 applications, if I had to guess.Calls back: 15Take-home data assignments: 4Second round phone interviews: 7Onsite interviews: 3Offers: 1In all, it took me about 3 months to find a job. And I'm very pleased with the offer! It's also worth noting that I was ghosted by 4 out of the 15 firms that called me back, including one that called me back after the final round interview and wanted to set up ""next steps."" My advice to any job seekers is to leverage your industry contacts, send out as many applications as possible, and don't get discouraged!",,"Job Search,"
446,https://www.reddit.com/r/datascience/comments/dnbbc9/how_do_you_deal_with_feature_importances_in_a/,dnbbc9,how_do_you_deal_with_feature_importances_in_a,DiogenicOrder,1.0,4,2019-10-26 10:49:53,0,22,,"I'm working with data which has a lot of categorical (nominal) predictors such as ZIP codes, reference numbers and such. If I one hot encode them, I'm really doubting the ability of forests/trees to pick the proper feature importances or the usual PCA to pick up on what amount of variance is captured by the categoricals because both methods are quite inefficient in sparse settings.What do you gals & guys advise me to do, how do you deal with that at work?Thanks",,
447,https://www.reddit.com/r/datascience/comments/dndrno/has_anyone_tried_using_365_data_sciences_365_data/,dndrno,has_anyone_tried_using_365_data_sciences_365_data,Pryxkiran,0.6,2,2019-10-26 15:20:01,0,1,,,,"Education,"
448,https://www.reddit.com/r/datascience/comments/dmy2yj/anything_similar_to_these_tidy_tuesday/,dmy2yj,anything_similar_to_these_tidy_tuesday,S1R_R34L,0.89,33,2019-10-25 16:17:46,0,5,,"https://www.youtube.com/user/safe4democracyBasically looking for videos where someone goes through the entire process of cleaning and analyzing some dataset. These Tidy Tuesday screencasts are a perfect example of what I'm thinking of, but they're with R, not Python.",,
449,https://www.reddit.com/r/datascience/comments/dmzurw/for_applicants_types_of_experience_ranked/,dmzurw,for_applicants_types_of_experience_ranked,dfphd,0.83,19,2019-10-25 18:26:13,0,4,,"I've seen multiple questions that get down to the following question: what type of experience is best? Should i take a class or write a paper? Should I do a side project or focus more on my work projects?This is my personal ranking - it's not universal by any means - but it should give you a decent idea of what matters most in the eyes of hiring managers in industry (academia and pure research is a different beast).There are two rankings - a primary ranking based on the results of the work, and a secondary ranking based on the source of the work.Primary ranking based on output:Generated profit/revenue or reduced cost.Led to an organizational change (process, decision making, policy, etc.) without a provable impact.Created a product (website, app, etc.) that can be accessed by a hiring manager.Logic behind the primary rankings rankings:Generating actual value - profit, revenue, etc. - is very difficult to do regardless of where you want to do it. Whether it's monetizing your own app, or convincing a company that you interned with to purchase differently, etc., it's very difficult to get to that stage. And that is because not only do you need a good idea, a good problem, and a good solution, but you also need to work through all the other external forces out there to make value happen. That means you need to influence decision makers, customers, colleagues, leaders, etc. so that what you thought of actually materializes real value.Short of that, you have work that led to change, but where that change isn't easy to tie to real $ value. This happens often - you build a model that makes it easier for people to do a task. So that saves them time - but does that actually increase their productivity? Well, it depends on what they do with their free time. Maybe they now spend their free time dicking around on reddit. Who knows. However, this is the type of experience that show you can go through all of the stages of getting something to actually get deployed - which is, in a lot of cases, the hardest part of the data science process.Lastly, you have experience that created a publicly available product. It's unclear whether this product will generate value or not, but at least a tangible product allows others to easily evaluate the quality of your work. It is fundamentally different than just talking about what you did - you can actually show others what you did.Anything below that is going to be looked at as low value experience. That is, if you worked on something that didn't generate value, no one uses, and no one can actually see, it might as well have never happened. We all have projects of this type - so it's nothing to be embarrassed about, but you want to make sure that you lead the conversation with the projects which are higher quality experience based on output.This is also why most hiring managers tend to disregard personal projects - because very few of them actually provide value. And if they don't provide value to someone, they are very difficult to actually evaluate.Secondary ranking based on type of experience:Work projectResearch projectCapstone projectPersonal projectClassroom projectLogic behind the secondary rankings:To me, there are a couple of things that I feel a data scientist needs to be able to do in order to be successful:Work with other people - including some who will be unnecessarily difficult to deal withGet answers to problems even when the answers are uglyKnow how to change the answer without changing the question - i.e., learning how to change their approach without abandoning the original intent/problem statement.Work experience is generally the only type of experience that covers all three. You can't escape organizational red tape, you have to get an answer to problems, and you can't just switch the problem statement at your convenience so that you can get a nice answer. Other, higher-up people in the organization can influence how fixed problem statements are, but you cannot unilaterally go change the rules to make your answer pretty.Research has two gaps: sometimes you can get away with doing research on your own and avoid others, and you often get to choose and frame your research work to be something you can actually solve. Really good research experience (which would be on par with work experience) would be projects where you have to work with other people (especially cross-departmental work), and projects where the research statement isn't flexible, e.g., when a funding agency asked for a specific solution and you can't bend that to suit your needs.Capstone projects can have gaps across the board. A lot of times you work on them alone, you get to decide what you want to do and bend the definition as you see fit to get a cool capstone project out of it, and to get nice, elegant solutions out of it. There are too many moving pieces to ever get caught in a situation where the project you're working on will just require you to power through some really painful, soul crushing stuff.Personal projects share all of those issues, but to a greater degree. The worst part is that they are 100% optional - you don't even need to do this work, so it's very likely that you will self select only into projects that you know you can solve. I would say there are absolutely good personal projects - but those will be the ones that include ugly, gross steps that no one would normally want to do. Like scraping and cleaning gross data. Or doing a bunch of non-sophisticated data manipulation to cover big gaps in data.Classroom projects are the worst because they are like personal projects only that on top of that you get expert opinion for a professor to steer you away from infeasible projects. So again, you will self select into projects that can be solved, and you can likely fudge them as needed to make sure they are solvable.",,
450,https://www.reddit.com/r/datascience/comments/dn7kc6/how_can_i_solidify_an_understanding_of_data/,dn7kc6,how_can_i_solidify_an_understanding_of_data,FlyingKanga,0.67,2,2019-10-26 04:05:03,0,12,,"I graduated from computer science last semester and have been thrown into a data science project with no hands on experience. I have a vague idea of everything by doing subjects in AI/ML, statistics, linear algebra but never did a data science subject. What would be the best way to solidify an understanding of data science?I'm mainly confused about which tech I should look at that I see popping around like Hadoop/Spark, Jupyter notebooks, some kinda AWS databases. Once I know what I need to use for my project, I can just learn as I go.",,"Discussion,"
451,https://www.reddit.com/r/datascience/comments/dmoht4/quick_notes_on_applying_to_entrylevel_analystds/,dmoht4,quick_notes_on_applying_to_entrylevel_analystds,CWHzz,0.96,235,2019-10-25 01:03:53,0,55,,"Hey allJust wanted to share three quick pointers I think might be valuable as someone who got an entry level analyst role on a data science team at a start-up and is now hiring for one:Data cleaning, data cleaning, data cleaning: These are the golden words on the resume. Most companies today are trying to apply ML to really complicated real-world problems, which means messy data. If you talk about experience where you have cleaned messy real-world data in detail, that will put you ahead of other candidates.Generic Projects: We all know them: housing price regression, MNIST, the flower one, Twitter sentiment analyses, MovieLens recommendation system, etc. Having done these isn't bad necessarily, but to someone with who has been around the block of online machine learning courses, these aren't all that impressive. Filling out your resume with original, even if they are relatively simple, projects and models that incorporate data cleaning is much more attention-grabbing.Why??: I don't really mind people who message me on LinkedIn, deduce my work email or go to the effort of writing cover letters but you aren't really doing much for yourself if all you are saying is ""Hey I saw the job, I think I am qualified, can I have the job?"". That is what everyone who is applying is saying, you're just being more annoying about it. If you look into our company, even just regurgitate our mission statement in your cover letter, it at least shows you aren't just spraying and praying. I would be more likely to consider someone less qualified who communicated why they want this job, not just a job.Cheers, feel free to yell at me in the comments. Don't DM me about the job.",,
452,https://www.reddit.com/r/datascience/comments/dn12h7/where_to_find_info_on_how_to_actually_structure/,dn12h7,where_to_find_info_on_how_to_actually_structure,familytreebeard,0.74,7,2019-10-25 19:52:27,0,8,,"I have seen hundreds of blogs addressing pandas ""tricks"" or ""functions you need to know"", but have had less success in figuring out how to structure the code best to avoid errors and to make it obvious how you got the data from point A to point B. Does anyone have any advice on how that should be done? As an example, I typically find myself in the same data wrangling scenario, and despite knowing how to solve the problem with various pandas commands, I'm never sure if the script is laid out in the most readable way.Let's say you have a long script that has one goal: take multiple tables of data from somewhere clean them, then combine all the data into some output table of interest. Along the way, you  do various operations (merge, drop, rename, map, filter, aggregate, whatever) and you end up with a final csv table.Common ""programming tips"" tell you to make everything modular (""functions should only do one thing"", ""functions should be small"", etc.). The problem is, I'm not convinced that data science lends itself to this practice as well as a large codebase for software development. When getting data from point A (raw) to point B (tidy), depending on the complexity of the operations along the way, I will often come back to the script to find where I've accidentally duplicated something during a merge, or dropped something I wanted to keep, or omitted some important data. It seems that in cases like this, I want to see everything in a line, i.e.Merge table 1 and 2 on this columnGroupby these columns and keep only columns X and Y.Use function f on columns X and Y to get column Z.Merge table 3 into this tableetc.When everything is modularized, it feels like you have to go hunting in a list of tiny functions all defined somewhere below your main() to see what all happened along the way.The point of all this is, are there some standard practices out there that are not for ""programming in python"", but rather for ""wrangling data in python using pretty much only pandas and that's it"" because usually, all I see out there is yet another person telling me the function signature for DataFrame.groupby or some such thing we have all read more than we need by this point. On the other hand, if you look at the high-level code organization, you'll get into repo folder structure, with setup, requirements, tests and the like, which is a bit far on the other side of the spectrum (not to say it isn't important, too). But where are the examples of the best way to script wrangling of raw tables A, B, and C into tidy table D, and the way to structure your script to do that? I'm looking for some advice from someone who isn't teaching about ""why pandas is useful"" nor ""how to to keep your software project team organized while developing your 5 million-line code base""Any hints would be great.",,"Discussion,"
453,https://www.reddit.com/r/datascience/comments/dmj401/i_know_python_and_r_pretty_well_lately_im_seeing/,dmj401,i_know_python_and_r_pretty_well_lately_im_seeing,childishnemo,0.96,191,2019-10-24 18:47:27,0,61,,Why? Is it for database management? What are the applications for Java as a data scientist?,,
454,https://www.reddit.com/r/datascience/comments/dmr5kz/is_a_research_paper_worth_the_trouble/,dmr5kz,is_a_research_paper_worth_the_trouble,da_chosen1,0.94,15,2019-10-25 04:47:07,0,24,,"I'm in the last year of my master's program and my professor asked me if I wanted to co-author a research paper. The topic is identifying fraud in sequence data using Hidden Markov and RNN. For those of you that published research papers, were the benefits worth the trouble?  How did it help your career trajectory?The research is not required?Lastly, any thoughts on specializing in HMM and RNN?Update:  I decided to write the paper. Thanks for the help and advice.",,"Discussion,"
455,https://www.reddit.com/r/datascience/comments/dmjimc/curing_hiv_this_is_where_you_come_in/,dmjimc,curing_hiv_this_is_where_you_come_in,dr_ish,0.89,85,2019-10-24 19:17:08,0,13,,"I’m a viral immunologist at amfAR, The Foundation for AIDS Research. Our job is to cure HIV…. Which means we give money to scientists we think can help us achieve our goal. I’ve been working on an idea the past year to bring in data scientists to analyze existing HIV datasets to find predictors that could be useful in developing a cure. The idea has finally come to fruition in the form of this request for proposals.I’d love your help to energize HIV cure research with the new data science approaches being developed in other fields. So if you are interested in $150K/year to analyze your heart out and help us find a cure, consider applying. If you need help finding an HIV cure researcher to partner with, email/message/dm me.",,"Projects,"
456,https://www.reddit.com/r/datascience/comments/dn0ahb/data_incubator_semifinalist_challenge/,dn0ahb,data_incubator_semifinalist_challenge,_twang,1.0,1,2019-10-25 18:57:35,0,2,,"Just received an email I was chosen as a semi-finalist for the Data Incubator Data Science Fellowship. I imagine this is pretty common so I’m not getting super excited yet. For folks who have gone through the challenges, what can i broadly expect? I’m not interested in any specifics—just if brushing up on SQL or something similar would be a good idea while I wait for the challenge to drop.Thanks, gang!",,"Discussion,"
457,https://www.reddit.com/r/datascience/comments/dmsflt/looking_for_an_app_which_would_allow_to_track_and/,dmsflt,looking_for_an_app_which_would_allow_to_track_and,zemaitis_android,0.88,6,2019-10-25 06:45:36,0,4,,"Question for those of you who are obsessed with data collection and aggregation. Is there some platform that has web and mobile apps where I would be able to register account, create separate categories and track some sort of data values daily, then aggregate them to data sets and see data in a graph?Data would be inputted by me via web or mobile app. For example I would have a category where I log my going to bed time, waking up time. Or another category where I log my expenses. I know that there are dozens of apps out there to track each thing that I want, but my idea is to have all data centralized in one place instead of using 20 apps.I could build something like that for myself, but was just wondering maybe there is a solution good enough out there already?Here is an example of what I want: https://exist.io/blog/custom-tracking/ and https://exist.io/about/custom-tags/Problem with exist is that it seems to be quite limited for custom data input. All I can input is a custom tag, no actual customvalues. Also I can access data for the last 30 days only.",,
458,https://www.reddit.com/r/datascience/comments/dmvyip/tooling_to_find_correlations_or_patterns_in_large/,dmvyip,tooling_to_find_correlations_or_patterns_in_large,Aldun,0.75,2,2019-10-25 13:14:32,0,9,,"I'm looking for tooling or software that allows me to input large datasets and find patterns or correlations in them to gain new insights. I'm a developer with no prior data science knowledge, so being able to use existing tooling as a first step would be great.The usecase I'm looking at is this: I have datasets from many different processes in a manufacturing factory, like how long a machine has ran, what temperatures and other settings have been used etc. What I would like to do is gather all this data, feed it into a system (potentially with AI?), to find new insights, patterns or correlations that we can then use to improve our processes.Does anyone have some pointers for me where to look in terms of tooling, software or anything else that could help me?Thanks!",,"Tooling,"
459,https://www.reddit.com/r/datascience/comments/dmy933/statistical_modeling_and_boundary_conditions/,dmy933,statistical_modeling_and_boundary_conditions,StefanIstas89,1.0,1,2019-10-25 16:30:35,0,7,,"HelloI want to develop a statistical model to estimate pressure on an object. I am new on this and just started reading literature. I am thinking to develop a boundary condition for the normal (original, undeformed) object and then apply an interpolation and a curve fitting solution for all conditions between maximum and minimum states of deformation. I have data for various (random) loads and deformations of the object from testing set. I just need to define its maximum force (load) and its maximum deformation and the same done for minimum states. Those are going to be my limits and all states in between will be interpolated to give me the loads and deformations. The zero state will be the boundary condition assigned to its original undeformed state. The undefromed state will be defined by a mesh generation or contour defined from edges.The material is a nonlinear viscoelastic one.I need suggestions, references anything.Thanks for your time, reading this.",,"Projects,"
460,https://www.reddit.com/r/datascience/comments/dmroo4/where_do_you_get_quandl_quality_data_but_for_free/,dmroo4,where_do_you_get_quandl_quality_data_but_for_free,Quippykisset,0.4,0,2019-10-25 05:35:58,0,3,,,,
461,https://www.reddit.com/r/datascience/comments/dmivdq/as_a_data_scientist_should_i_learn_c/,dmivdq,as_a_data_scientist_should_i_learn_c,john-c34,0.69,6,2019-10-24 18:29:38,0,31,,"I am trying to get inference time down for a Machine Vision model that I am building in tf2 in order to run it in real time (I also need the model to run on device, either laptop or mobile phone). Porting the model to tensorflow JS from python and running the model in the browser helped, but it's still not quite fast enough. From what I have been reading, aside from a change in architecture and further optimizing my code, I should consider porting to C++ (I guess caffe would be the framework of choice here). This solution would of course first require me to learn C++...So my question is this: as a Data Scientist with a focus on Machine Vision, should I be learning C++? Furthermore, are there particular areas of ML where C++ is particularly useful?",,"Tooling,"
462,https://www.reddit.com/r/datascience/comments/dmkzaf/finding_motivation_for_data_science/,dmkzaf,finding_motivation_for_data_science,toselx,0.72,3,2019-10-24 20:59:25,0,16,,I've almost completed my first semester into a Master of Data Science from a marketing/arts background and I'm finding the transition really difficult. The content is fine but it's really difficult to apply what I've learnt towards assignments without making quite a few errors.I quite enjoy what I'm learning and when I finally understand something or debug a code I feel great. But in general I am starting to feel unmotivated and questioning my degree. Have any of you ever felt this way? I could really do with some tips or recommendations.,,"Discussion,"
463,https://www.reddit.com/r/datascience/comments/dm7xxd/how_important_is_it_to_get_a_jobexperience_right/,dm7xxd,how_important_is_it_to_get_a_jobexperience_right,zeebeezoo,0.89,77,2019-10-24 01:39:21,0,84,,"I graduated from college last September with a degree in Data Science, but no experience since I didn't get to do an Internship (I did work on some group and solo projects though). I'm now debating between taking a year out to travel a bit or launching straight into a job!So my question is would taking time out after college affect my ability to get work as a data scientist, given that I have no experience? I'm worried that if I do take off for a year it will be a lot more difficult to find a job since there will be people coming fresh out of college while I've been out for a year.EDIT:Thanks very much for all the replies! It's really helpful to get all the pros and cons. I can really weigh up the decision much better now, so I'm very grateful.I should just say that if I were to take a year out it would be to teach in China and take time off during the year to travel from there, so at least it wouldn't be a completely empty gap on my CV. Also as some have suggested I would  dedicate time to doing some projects and keeping my skills up to scratch during the year.",,"Career,"
464,https://www.reddit.com/r/datascience/comments/dmol1g/data_science_awareness_courses_for_a_senior/,dmol1g,data_science_awareness_courses_for_a_senior,teacher9876,0.5,0,2019-10-25 01:10:06,0,4,,"A friend is in senior / mid-level management position with a healthcare company. There has been a lot of talk at his work place about opportunities with data analytics / data sciences / artificial intelligence. Is there a high level course that leads to awareness about these issues? The idea is not necessarily to learn coding. But, it is to understand these topics and have better awareness of how to navigate the use of these technologies in his firm.  Please suggest.",,"Education,"
465,https://www.reddit.com/r/datascience/comments/dmd66a/question_how_to_model_and_compare_muscle_synergy/,dmd66a,question_how_to_model_and_compare_muscle_synergy,stats_nerd21,0.9,7,2019-10-24 09:56:37,0,5,,"I am a PhD student doing research on motor control of arms for stroke patients.The patients (along with healthy controls) performed a series of task-oriented arm-movements using an anti-gravity exoskeleton arm. The exoskeleton arm had 4 joints total: 2 joints each at the elbow and shoulder. The angular displacement of each joint was constantly recorded in time-series format, and the 4 corresponding angular-velocities were also calculated and recorded in time-series format.Our goals for the current project are two-fold:Find a meaningful measure of movement synergy for each patientFind a way to compare the synergies of different subjects- to see how stroke patients compare to healthy subjectsWe achieved Goal 1 by using Principal Component Analysis.Unsurprisingly, angular velocities of shoulder and elbow joints during task-oriented movements were correlated and the first 2 PCs always explained over 80% of the variance.On average:-PC1 explains 56.5% of the variance in the dataPC2 explains 26.5% of the variance in the dataPC3 explains 11.9% of the variance in the dataWe noticed differences in the distribution of PC1 weights in Healthy vs Stroke-affected subjects (plot of PC1 weight distributions). Stroke patients with limited mobility tend to move their arms differently from healthy subjects during their goal-oriented tasks to compensate for their motor limitations. So the differences in PC weight distributions were not surprising. We concluded that the first 2/3 Principal Components from the motion data are a reasonable way to quantify movement synergy for a subject.For Goal 2 (finding a way to compare the synergies of different subjects), we are at a loss of ideas at the moment. Each subject is defined by 2 or 3 vectors (Principal Components), and we cannot figure out how to measure the difference between subjects without losing valuable info about those subjects. It is possible to compare the difference between 2 vectors (by finding the euclidean distance between them or find the angles between them), But the problem is that this would leave us with 2/3 values indicating the differences between 2 subjects, depending on whether we use 2/3 PCs, and no way to summarize that into one value indicating subject similarity.Any suggestions on how to approach this will be highly appreciated. Also, if anyone can think of another sub where I may be able to get an answer, I would appreciate suggestions on that as well. I am currently posting about this on reddit and Crossvalidated. Thank you",https://www.reddit.com/r/statistics/comments/dmd5p4/question_how_to_model_and_compare_muscle_synergy/,"Projects,"
466,https://www.reddit.com/r/statistics/comments/dmd5p4/question_how_to_model_and_compare_muscle_synergy/,dmd5p4,question_how_to_model_and_compare_muscle_synergy,stats_nerd21,1.0,1,2019-10-24 09:55:11,0,3,,"I am a PhD student doing research on motor control of arms for stroke patients.The patients (along with healthy controls) performed a series of task-oriented arm-movements using an anti-gravity exoskeleton arm. The exoskeleton arm had 4 joints total: 2 joints each at the elbow and shoulder. The angular displacement of each joint was constantly recorded in time-series format, and the 4 corresponding angular-velocities were also calculated and recorded in time-series format.Our goals for the current project are two-fold:Find a meaningful measure of movement synergy for each patientFind a way to compare the synergies of different subjects- to see how stroke patients compare to healthy subjectsWe achieved Goal 1 by using Principal Component Analysis.Unsurprisingly, angular velocities of shoulder and elbow joints during task-oriented movements were correlated and the first 2 PCs always explained over 80% of the variance.On average:-PC1 explains 56.5% of the variance in the dataPC2 explains 26.5% of the variance in the dataPC3 explains 11.9% of the variance in the dataWe noticed differences in the distribution of PC1 weights in Healthy vs Stroke-affected subjects (plot of PC1 weight distributions). Stroke patients with limited mobility tend to move their arms differently from healthy subjects during their goal-oriented tasks to compensate for their motor limitations. So the differences in PC weight distributions were not surprising. We concluded that the first 2/3 Principal Components from the motion data are a reasonable way to quantify movement synergy for a subject.For Goal 2 (finding a way to compare the synergies of different subjects), we are at a loss of ideas at the moment. Each subject is defined by 2 or 3 vectors (Principal Components), and we cannot figure out how to measure the difference between subjects without losing valuable info about those subjects. It is possible to compare the difference between 2 vectors (by finding the euclidean distance between them or find the angles between them), But the problem is that this would leave us with 2/3 values indicating the differences between 2 subjects, depending on whether we use 2/3 PCs, and no way to summarize that into one value indicating subject similarity.Any suggestions on how to approach this will be highly appreciated. Also, if anyone can think of another sub where I may be able to get an answer, I would appreciate suggestions on that as well. I am currently posting about this on reddit and Crossvalidated. Thank you",,"Question,"
467,https://www.reddit.com/r/datascience/comments/dmp3by/is_data_scientistdata_analyst_a_bad_career_if_i/,dmp3by,is_data_scientistdata_analyst_a_bad_career_if_i,numbersloth,0.29,0,2019-10-25 01:47:59,0,10,,,,"Career,"
468,https://www.reddit.com/r/datascience/comments/dmhwah/my_acf_and_pacf_plots_are_similar_what_does_this/,dmhwah,my_acf_and_pacf_plots_are_similar_what_does_this,vigbig,0.5,0,2019-10-24 17:19:48,0,12,,"am new to ARIMA here.I am  implementing ARIMA on some sales data and these are my ACF and PACF  plots without differencing. I am using SPSS btw.Even when put under nat log , both are quite similar .however when d = 1.I thought now I have stationarised the time series. I took p=5, d=1,q=1 and did trial and error on (5,1,0) (0,1,1) and (5,1,1)However  , after using expert modeler (an option where SPSS automatically finds  the right p,d and q values). It gave (1,0,1) and this had the least BIC  value.So where did I go wrong ?  Did I need to difference in the first place ? What should I do if my ACF  and PACF plots are similar ? Should I interpret p ,d and q values  differently in that case ?Also ,  another thing : the p test on the Ljung box test for all models i have  tested for aima on (including the one on expert modeler) above 0.05 i.e.  not statistically significant. i.e. it failed the white noise test.Time series of the data i am using here",,"Discussion,"
469,https://www.reddit.com/r/datascience/comments/dmdsn8/is_it_important_to_have_side_projects/,dmdsn8,is_it_important_to_have_side_projects,halien69,0.71,3,2019-10-24 11:13:06,0,24,,"I've been a Mid-level Data Scientist with a private company for almost 2 years, however I'm looking to either get a more senior role in my company (which I think impossible) or another more senior position (with better salary) in a year or 2.The thing is that all the work/code I've done is propriety, and thus I can't have an updated portfolio on github. So what I want to know, how important is it for me to have side projects like say Kaggle? I don't have much free time (as for the first time in more than a decade I have a hobby), but I think over a year I can get a few projects done.",,
470,https://www.reddit.com/r/datascience/comments/dlvliq/this_is_a_fascinating_read_about_how_the_wright/,dlvliq,this_is_a_fascinating_read_about_how_the_wright,leenas9,0.86,144,2019-10-23 09:09:01,0,44,,"Interestingly, they corrected the Smeaton coefficient that was in use for hundreds of years.""Smeaton’s coefficient to calculate the density of air. After running over 50 simulations using their wind tunnels, the brothers determined its value to be 0.0033, and not 0.005. ""They also used the data from wind tunnels to design wings with better lift-to-drag ratio and used them to build their 1902 flying machine, which performed significantly better than their previous gliders.  https://humansofdata.atlan.com/2019/07/historical-humans-of-data-the-wright-brothers/",,"Fun/Trivia,"
471,https://www.reddit.com/r/datascience/comments/dmauep/2_means_ttest_with_skewed_sample_distributions/,dmauep,2_means_ttest_with_skewed_sample_distributions,sang89,1.0,3,2019-10-24 05:44:15,0,6,,"Hello, a beginner level t-test below, would appreciate some help.I am trying to analyze AB test results for user engagement (total time spent on site) for control and treatment samples. The sample distributions are heavily right skewed as you would expect- most people spend a few minutes on the site while some heavy users spend longer.  The treatment size is 10% of the population with total sample size ~ 50000..I am thinking i need a 2-sample t-test (unpaired) since different users are assigned into control and treatment.The first task is to identify the metric- total time per user aggregated over days OR total time per day aggregated over users.... Do you guys have any tips on how to choose this? Also, am i right in thinking I need to sample ~10% of the both variations so my samples are of equal size?Importantly,  my plots don't seem to be satisfying the assumptions for a t-test, i.e. normal distribution and equal variance ...any tips?thanks in advance..",,"Discussion,"
472,https://www.reddit.com/r/datascience/comments/dlg1rf/i_made_a_chrome_extension_to_make_web_scraping/,dlg1rf,i_made_a_chrome_extension_to_make_web_scraping,welanes,0.98,669,2019-10-22 12:36:38,0,71,,"Hey all,I've just spent the last 9 weeks building what I hope is the simplest way to scrape data from a webpage: Simplescraper.All you gotta do is click on the data you want, give it a name and then view results. If all goes well your data is waiting for you to download in csv or Json format. There's also cloud scraping built in for bigger jobs.There are dozens of web scrapers out there but none of them seem to nail ease of use and a good UI. Hopefully it brings value to some of you 🤞.Edit: Grateful for the positive response. The element/css selector still ain't 100%, tutorial videos need to be created and there's still more than a few bugs - all will be improved in the next version. I've removed the limit from cloud scraping until the weekend so it's infinite credits for errbody. Throw whatever you have at it! And if you find a page where the extension just utterly fails do let me know in the comments and I'll get to it.",,
473,https://www.reddit.com/r/datascience/comments/dm23qf/req_review_of_bayesian_methods_for_hackers/,dm23qf,req_review_of_bayesian_methods_for_hackers,heckeop,1.0,2,2019-10-23 18:54:02,0,4,,"Would greatly appreciate a review of Chapter 1. Specifically,Julia conventionsGen conventions (model definition, inference)I haven't gotten around to porting matplotlib configs yet, so don't mind the default plot settings.EDIT: Direct Github link swapped for an nbviewer link, as per bots' suggestions.",,"Education,"
474,https://www.reddit.com/r/datascience/comments/dm2vsf/precision_recall_sensitivity_specifity/,dm2vsf,precision_recall_sensitivity_specifity,da_chosen1,0.4,0,2019-10-23 19:49:04,0,4,,"Doesn't anyone have any tips or tricks to remember the difference between Precision, Recall, Sensitivity, Specificity? I understand the concept behind these metrics, but I always find myself looking them up to remember the differences.",,"Discussion,"
475,https://www.reddit.com/r/datascience/comments/dm0d7d/can_you_recommend_a_good_powerful_tool_for_data/,dm0d7d,can_you_recommend_a_good_powerful_tool_for_data,ddmmatias,0.67,1,2019-10-23 16:49:09,0,1,,"Not sure if data science is the right subreddit for this, but I'm most certain this crew will know the answer.In my job we have a HUGE mySQL database that pulls data from over 200 different places (each into its own table), and then starts processing that into intermediate tables, based on rule engines and some complex logic.After processing everything we end up with a set of 10 tables with millions of records that we filter to be used on our different services. All of this is managed by a middleware of different technologies, living in different places, worked by different teams, etc.What I'm looking for is a good tool or even a good approach to make regular health checks during development and some live checks on production in each table from the first ones to the already processed ones. Where I can:- I can create different queries.- Add assertions to those queries.- Organize this into folders and subfolders- Be able to schedule executions. (besides running them manually of course)- Have some sort of metafilters to design some test swuites for specific areas of the business.- Have a good reporting system, UI, or something that we can put up on a monitor in the office to make sure our data is healthy all the times, after deploys, etc.Can you recommend a tool for this or should I create one?",,"Tooling,"
476,https://www.reddit.com/r/datascience/comments/dlznxj/help_with_intuitive_understanding_of_neural/,dlznxj,help_with_intuitive_understanding_of_neural,mrdlau,1.0,1,2019-10-23 15:55:44,0,5,,"I’ve been reading quite a bit of tutorials on ANN recently and I feel like I still don’t have a firm intuitive sense of how they work. I understand the input nodes and the first set of weights are aggregated in a linear combination fashion and the result is then applied a function( sigmoid, relu, tanh etc). I don’t think I understand the role of the activation function and what it does.  Everything I read, it explains it as ‘applying non-linearity’ to it, but I still don’t know what that means.  To me,  it just transforms it to a new number, possibly [-1,1], which goes through another set of linear combination and then applied another function. Can someone explain this to me? I don’t know if there is a simpler way to explain this...but what is it doing that can help you get closer to the output?Another question I have,  whatis the benefit of adding additional hidden layers or nodes in the hidden layers.  How does that potentially help with the prediction?  Like,  what is the benefit of having multiple layers(and as a result multiple activation function)? If you have a a single layer, won’t the backprop eventually still get to the same result as multiple layers(but maybe require more iterations?)?Appreciate more context and explanation.Thank you!",,
477,https://www.reddit.com/r/datascience/comments/dlybzn/how_to_visualise_two_networks_maintaining_the/,dlybzn,how_to_visualise_two_networks_maintaining_the,sendnoodles_jimjam,0.33,0,2019-10-23 14:07:14,0,0,,"I have two networks of >2000 nodes of the same dataset but in different conditions, where the two networks share >1500 nodes.  Is it possible to show the difference in network structure but maintain the positions of the shared nodes, to allow readers to better understand the changes?",,"Projects,"
478,https://www.reddit.com/r/datascience/comments/dlxc63/understanding_roc_curve_without_classification/,dlxc63,understanding_roc_curve_without_classification,rotavator,0.5,0,2019-10-23 12:31:42,0,5,,"Hi all,I am working on a risk prediction model to understand an individual's risk of developing a disease. I have labelled outcomes as 0 (healthy controls), and 1 (diseased individuals). I have fit a logistic regression model with my risk factors as predictors, then used it to predict the outcome in my test set.I have not forced my algorithm to classify these individuals with or without disease (assigning 0 or 1), as I am just trying to differentiate between the two groups. From a medical perspective, it makes sense that there are individuals with elevated risk who will not develop disease, whereas there are individuals without elevated risk that will develop the disease.When plotting my predicted values between the two groups, I am able to see quite clear distinction between the two groups. When plotting AUROC, I am getting a high value, near 0.85. I am having trouble understanding the AUROC in this context though, because I have not forced the algorithm to classify individuals with/without the disease. I understand that my model is still able to differentiate between the two groups, but I then do not understand exactly what the AUROC is telling me without the actual true/false positive and true/false negative values. Can anyone help clarify this?Thanks!",,"Projects,"
479,https://www.reddit.com/r/datascience/comments/dm11u4/why_does_sparks_ml_libs_are_missing_a_regression/,dm11u4,why_does_sparks_ml_libs_are_missing_a_regression,znihilist,0.17,0,2019-10-23 17:39:11,0,0,,Feels weirdly missing considering that we have a classification method.,,
480,https://www.reddit.com/r/datascience/comments/dls7tc/retraining_a_model_deployed_in_production/,dls7tc,retraining_a_model_deployed_in_production,tums_antacid,0.75,2,2019-10-23 03:38:44,0,8,,I have a regression model which is almost ready to be deployed. The model will be used to predict a semiconductor device performance parameter at 80C using testing data from 3 intermediate temperatures. The goal is to save costs by eliminating the testing at 80C. I also have setup a process to execute real test at 80C in a small randomized population of the device. This real test data will be compared to the predictions from the model.What do you think is a good way to retrain this regression model? Right now I am leaning toward an offline method where the new real test data is added to the training data-set and the model is entirely retrained on this bigger data-set.  We don't expect the material performance at 80C to vary over time hence the offline method. Is this a reasonable approach?,,"Discussion,"
481,https://www.reddit.com/r/datascience/comments/dlgsl0/misapplication_of_business_analytics/,dlgsl0,misapplication_of_business_analytics,CladDinosaur,0.92,10,2019-10-22 13:51:13,0,11,,"Hi everyone,I'm doing a project for school for case studies in misapplication of business analytics. Was wondering if anyone had some cases to share? Thanks!",,
482,https://www.reddit.com/r/datascience/comments/dlo19c/where_can_i_find_the_best_discussion_about_the/,dlo19c,where_can_i_find_the_best_discussion_about_the,urlwolf,0.33,0,2019-10-22 22:36:49,0,1,,,,"Discussion,"
483,https://www.reddit.com/r/datascience/comments/dlnqh7/languages_for_data_scientist/,dlnqh7,languages_for_data_scientist,taeshay,0.5,0,2019-10-22 22:17:08,0,17,,"What is the most used language(s) in data science? I'm currently a sophomore in college failing my Python programming classes haha because I have a already bad background in Python, but I heard Python is a big one too.",,"Education,"
484,https://www.reddit.com/r/datascience/comments/dl473r/are_concepts_of_topology_relevant_to_data/,dl473r,are_concepts_of_topology_relevant_to_data,algebruhhhh,0.92,115,2019-10-21 19:52:52,0,19,,"I’m thinking about concepts like persistent homology and sheaves. Do you guys regularly think about these? Are they just niche ideas made by mathematicians?Edit:if anyone can recommend important TDA papers, I’d appreciate it.",,
485,https://www.reddit.com/r/datascience/comments/dlm7b3/how_does_facebook_people_you_may_know_algorithm/,dlm7b3,how_does_facebook_people_you_may_know_algorithm,NYCambition21,0.6,1,2019-10-22 20:35:01,0,2,,"I just saw today that there was someone that was recommended to me that I have no mutual friends with.Now given the fact that Facebook also didn’t LET me see this person’s friends list, that may be why.The only explanation is that this person is friends with a mutual friend. This friend of mine is from another city who just recently moved here so my friend would have no other mutual friends with me. But even with my friend, I still can’t see his friend list.So my only guess is that this “recommended person” is mutual friends with him but I just can’t see their “friendship” on Facebook.",,
486,https://www.reddit.com/r/datascience/comments/dkz1yn/a_question_on_heteroscedasticity/,dkz1yn,a_question_on_heteroscedasticity,AssWaffle2000,0.94,74,2019-10-21 13:20:33,0,29,,"I'm doing a project where the goal is to predict revenue of a movie. I am using linear regression and there are two assumptions that I have not yet fulfilled:Normality. I have tried using log transformations on the revenue variable. This ensures normality but significantly reduced the R-squared value. However I am ignoring this assumption due to the fact that non-normality is not concerning when the number of samples are high.Homoscedasticity. A residual plot indicated the presence of heteroscedasticity (horizontal funnel shaped graph). I assume this is because of the presence of statistical outliers, but these cannot be removed. I have tried weighted regression and Huber regression but they do not resolve heteroscedasticity, nor do they have better performance than OLS regression.https://imgur.com/a/hGC3HYpI understood that heteroscedasticity only affects standard errors. I'm by all means a beginner but I still don't know if I can safely ignore this assumption, if all I care about is the R-squared value?",,
487,https://www.reddit.com/r/datascience/comments/dl30vj/multi_linear_regression_vs_mixed_linear_model/,dl30vj,multi_linear_regression_vs_mixed_linear_model,shlotchky,0.89,15,2019-10-21 18:29:18,0,2,,"This may come down to semantics, but I am having a hard time finding a place online where this is clearly spelled out.I am personally familiar with mixed linear models, using BLUPs and BLUEs, etc. However at my new job there is an industry standard of using a type of model reliant on multi linear regression (at least that is what various industry blogs say).Is mixed linear model a type of multi linear regression? Are they totally separate? Can somebody help explain the difference of these two to me please?",,
488,https://www.reddit.com/r/datascience/comments/dl7gln/what_are_the_main_flawsproblems_of_the_wlurank/,dl7gln,what_are_the_main_flawsproblems_of_the_wlurank,bestminipc,0.77,5,2019-10-21 23:41:40,0,0,,"https://taxprof.typepad.com/taxprof_blog/2019/07/2019-meta-ranking-of-flagship-us-law-reviews.htmlhttps://blogs.uoregon.edu/bcnewell/meta-ranking/what are the main flaws of the 'wluRank' and 'wlu(IF)Rank ' metric that is used here?what's the best ranking of laws reviews, and why?",,"Education,"
489,https://www.reddit.com/r/datascience/comments/dl3ato/remote_data_scientists/,dl3ato,remote_data_scientists,1st_parry,0.7,4,2019-10-21 18:48:42,0,8,,How do you like your job? Are the work life benefits as you expected?,,
490,https://www.reddit.com/r/datascience/comments/dksk1n/is_data_science_a_job_where_you_are_isolated_for/,dksk1n,is_data_science_a_job_where_you_are_isolated_for,monclays,0.87,68,2019-10-21 02:35:05,0,44,,"I am an aspiring data science currently in school learning to code. I find myself spending hours by myself coding, and realize I hate isolating myself for too long of periods of times. Society has increasingly become an isolating place, and I think I wouldn't be able to stand a career where I was alone in silence for too long. Before I get too far pursuing a data science degree, I wanted to get some opinions on whether it is a social job or not? How often do you interact with coworkers/management etc. Are there many team projects?",,"Discussion,"
491,https://www.reddit.com/r/datascience/comments/dl3zr2/question_on_model_implementation/,dl3zr2,question_on_model_implementation,ChebWhiskey,1.0,3,2019-10-21 19:37:49,0,4,,"Thanks in advance for the information.Currently, my company uses a REST API Java front-end with PostgreSQL back-end to implement models that my team has constructed. We have a team of IT contractors that do the actual programming work involved with the front and back ends of the API, as our team has little to no experience with standing up a service like this.However, we’ve found it incredibly difficult to communicate all of the intricacies of the calculations being expected of the service and have found that with contractors rotating in and out regularly that we constantly have to re-train our contractors on how the service is supposed to work. In addition, without a focused team maintaining the code base, the service is fragile and the code is a bit spaghetti-like. Also we’ve seen that when teaching new developers the system, that past developers didn’t implement them exactly the way we asked, but instead a way that passed our QA tests, so the new contractors get confused when they see an inconsistency.We have started to feel like it would be better from a quality standpoint for our team to not only handle the data acquisition, model design, modeling, and testing but also the actual build of the API itself. Our team doesn’t have a tremendous amount of Java experience, but we learn very quickly and feel that since we have such a close relationship to the model itself, that we could design and build a product that ultimately works better in the long term. However, we’re worried about the post-production “run” issues with taking on an entire API service ourselves.Surely others must feel the same pain when implementing their models. How do others actually deal with model implementation? Do you rely on an IT team to do it or do you stand it up? Do you use something other than Java/PostgreSQL? Any advice with a problem like this?Thanks for taking the time to read this. Genuinely curious how others go about solving these problems.",,
492,https://www.reddit.com/r/datascience/comments/dk9eq3/i_taught_a_one_day_course_on_numpy_and_linear/,dk9eq3,i_taught_a_one_day_course_on_numpy_and_linear,ADGEfficiency,0.98,575,2019-10-19 22:43:00,0,45,,A one day course introducing NumPy and linear algebra I taught at Data Science Retreat.The course is split into three notebooks:vector.ipynb - single dimension arraysmatrix.ipynb - two dimensional arraystensor.ipynb - n dimensional arrays,,"Education,"
493,https://www.reddit.com/r/datascience/comments/dkidq4/data_science_medicine_any_book_recommendations/,dkidq4,data_science_medicine_any_book_recommendations,TheSSVids,0.89,20,2019-10-20 13:22:09,0,18,,"Hello everyone! I am a medical student, but after seeing so much progress and potential within the data science field, I thought that there has to be an overlap between medicine and data science where the medical field could benefit greatly (e.g machine learning and diagnostics). With that in mind, do you have any recommendations on (introductory) books on data science, that you feel relates back to medicine? Thanks in advance!",,
494,https://www.reddit.com/r/datascience/comments/dkippp/weekly_entering_transitioning_thread_20_oct_2019/,dkippp,weekly_entering_transitioning_thread_20_oct_2019,datascience-bot,1.0,11,2019-10-20 14:00:28,0,111,,"Bleep Bloop. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki. You can also search for past weekly threads.I am a bot created by the r/datascience moderators. I'm open source! You can review my source code on GitHub.",,"Discussion,"
495,https://www.reddit.com/r/datascience/comments/dknhx8/additional_compensation_ds_salaries/,dknhx8,additional_compensation_ds_salaries,Siba911,0.33,0,2019-10-20 20:23:50,0,11,,"I’m currently in the military and am currently enrolled in GT’s online Analytics program. I’m trying to switch over my branch so I can work in the Army’s equivalent of Operations Research/Data Science.I’m looking at having about 3yrs of experience as an Analyst and a Master’s in Analytics when I get out. My background in Army so far has been primarily a combat role with the last few years working in Finance/Budgeting.As everyone knows, the military offers a lot of benefits, and by the time I plan to get out I’ll need to be compensated about $115K to maintain the same standard of living in lieu of losing those benefits as well. I’ve seen this as the median salary a few times for DS roles and sometimes a little lower.For one, is a DS role with that kind of pay even realistic for me, and next, I am not familiar the civilian work world and are there usually bonuses/benefits or anything tied to these sort of jobs?I know DS pay related questions are sort of annoying, but it’s just a necessary one for me because I have four kids to support and TRICARE  and no tax on 15% of my pay are huge benefits. Any input is appreciated, I just want to know how to plan out and what to expect in my next 4-5 years.",,"Discussion,"
496,https://www.reddit.com/r/datascience/comments/dkhxcp/how_to_run_python_code_for_multiple_inputs/,dkhxcp,how_to_run_python_code_for_multiple_inputs,baniyalbawa,1.0,2,2019-10-20 12:29:11,0,6,,"So been working on a RESUME FILTERING project.using various modules from NLP and the code is ready for extracting useful information such as name,email address, work experience from the CV. But as of now it can only input one CV at a time. I want that we can input multiple CVs and the code to run parallely and save the extracted information in a file. Please help as m lost on what to do next",,
497,https://www.reddit.com/r/datascience/comments/dkd839/efficiently_inspecting_large_datasets/,dkd839,efficiently_inspecting_large_datasets,iGot2Fly,1.0,6,2019-10-20 03:50:54,0,18,,"What is the most efficient way of inspecting large datasets? I'm in the position now where I am regularly doing data 'intakes' for a research organization. This often includes combining multiple from multiple years into as few as possible. Each year could have over 1 million records, and they can be in various formats, but mostly CSVs. For example, if 15 years have the same schema, I will combine into a single table. The final destination for the data is Azure SQL databases.Common tasks I am trying to do are:Read and compare headers to see which years have what columns and to inspect if any are missingExamine each column to determine data types, and searching for non-numerical data in numerical columnsBasic summary statistics to compare data from each year and identify outlier columns which could be in errorI'm new to data science, but I've been trying to do most of this in Python with Pandas. I do know some SQL as well. I don't know any other languages, but am open to learning. I've been looking at R and Julia. I've been having trouble trying to figure out how to program to inspect these datasets. I'm trying to make everything as automated as I can, looping through files.Does anyone have any advice for handling these datasets and performing these tasks. Is there any great tools or libraries out there that you would recommend? Thanks!",,"Projects,"
498,https://www.reddit.com/r/datascience/comments/dk3f0q/asked_to_give_presentation_on_marketing_mix/,dk3f0q,asked_to_give_presentation_on_marketing_mix,ad_tech89,0.94,51,2019-10-19 14:56:51,0,37,,The local college has a data science bootcamp and I was asked to teach a session on what a marketing mix model is. Since that's what I do at work at an ad agency.  so i'd like your opinion on the presentation deckIntroductionA) What is a MMM?  High overview descriptionB) What questions can it answerc) how can the results be used in business/marketingMethodologyA) Process flow of a marketing mix model- data collection to variable transformation to multivariable regression to outputB) Overview of the various factors used.  Dependent vs independent. Marketing vs macroC)  Definitions of all the effects/variable transformations- basically a terminology list definig things like seasonality and halo effectD) How a multivariable regression worksE)  How we know its accurateResultsA) what the  output looks likeB) turning that output into ROIC)  A Contribution waterfall illustrating how all the effects add into total salesD) A optimization simulation graphic showing how ROI is then used for simulationsConclusion slideAm I missing anything?,,"Career,"
499,https://www.reddit.com/r/datascience/comments/dkaas7/text_mining_i_have_100000_sentences_with_10000/,dkaas7,text_mining_i_have_100000_sentences_with_10000,RaddestOfComrades,0.85,5,2019-10-19 23:52:57,0,6,,"I am only a hobbyist with data, so I’m not always familiar with the best way to go about things. I have Jeopardy questions and their associated category (which is my label). As anyone who watches the show knows, many categories overlap. I would like to reduce the number of categories/labels. Are there specific considerations I should have in mind or techniques I should consider?",,
500,https://www.reddit.com/r/datascience/comments/dkbwa0/whats_a_cheaper_computer_with_a_bunch_of_ram_youd/,dkbwa0,whats_a_cheaper_computer_with_a_bunch_of_ram_youd,Quippykisset,0.44,0,2019-10-20 01:58:19,0,7,,,,
501,https://www.reddit.com/r/datascience/comments/dkdglm/math_vs_coding_data_science/,dkdglm,math_vs_coding_data_science,weihong95,0.43,0,2019-10-20 04:11:42,0,0,,"If I know the entire math logic for machine learning algorithms, but I could not code well, do I stand a chance to enter the data science field?If I just barely know the math behind those machine learning algorithms, but I can code well, am I qualified enough to be a data scientist?If you are considering to switch to the data science field, and you would want to know to focus on Mathematics or Programming, this article is for you.Link: https://towardsdatascience.com/math-vs-coding-data-science-43e216b4f671?source=friends_link&sk=0407c058d61ad5b963870f02455b104dI hope you will like it and comment below if you have other thoughts that you would like to add on!",,"Career,"
502,https://www.reddit.com/r/datascience/comments/dkdcz2/i_added_over_5_eth_1000_usd_in_code_bounties_to/,dkdcz2,i_added_over_5_eth_1000_usd_in_code_bounties_to,notadamking,0.33,0,2019-10-20 04:02:55,0,1,,,https://gitcoin.co/profile/notadamking/active,"Projects,"
503,https://www.reddit.com/r/datascience/comments/djlniu/interesting_labor_market_demand_casual_inference/,djlniu,interesting_labor_market_demand_casual_inference,BudgetShaman,0.89,64,2019-10-18 12:40:27,0,21,,"So I've been reading several posts about how statistics is in demand and that we're in a crunch to find talent as it relates to analytics/BI/data science (I know that's a wide cast net).I went to LinkedIn to perform a simple analysis and I noticed that the job market in the DFW area doesn't reflect this same ""demand"". Effectively, there appears to be a greater demand for the keyword ""finance"" at the mid senior to executive level compared to other key words such as business intelligence, statistics, or analytics. I even noticed a similar trend with key phrases such as SQL and Python, but combining the two lead to fewer results. Several potential explanations:1.) The skill set for analytics is what is in demand, not a full fledged position solely responsible for the carryout of said discipline2.) Most analytics jobs in demand are entry level and/or haven't matured enough to stratify through the ranks up to the executive team3.) LinkedIn isn't the best place to understand labor market demand data, nor are all of the positions posted online4.) Data analytics are still bifurcated between IT (data engineers, data warehouse developers) and the business (data analysts, FP&A, operations)5.) The demand for sophisticated statistical knowledge is overplayed or misunderstood in the business world (read I did not say machine learning or data science)Obviously without a more elegant analysis ironically using statistical inference, this all seems to be causality.I'm observing these trends as I work in FP&A and am considering what my future entails. I'm a finance/BI manager and controller all rolled into one, which leaves me with an opportunity to delve deeper into a statistics program or to pursue a traditional business masters degree with a quantitative bend.Wondering if anyone has any insight or opinions related to the labor market demands and how the business media is pushing the analytics drive? Is it concerning that I can't find ""statistics"" frequently used as a key phrase? Is it alarming that it seems business as usual is still going strong in the DFW market?",,"Discussion,"
504,https://www.reddit.com/r/datascience/comments/djszqi/dagitty_causal_dag_software/,djszqi,dagitty_causal_dag_software,jaredstufft,0.81,3,2019-10-18 22:02:35,0,0,,"Hey everyone,I found this cool web app called DAGitty that helps you create DAGs for causal inference. It helps you with backdoor/frontdoor criterion and finding confounders for a given DAG (assuming the DAG is correct). It's pretty cool IMO!Has anyone found anything similar?",,"Tooling,"
505,https://www.reddit.com/r/datascience/comments/djat26/how_much_time_do_you_put_into_reading_research/,djat26,how_much_time_do_you_put_into_reading_research,[deleted],0.92,83,2019-10-17 20:51:42,0,61,,"Those of you working as data scientists, how much time do you put into reading research papers both at work and on your own time? Whats the split?",,
506,https://www.reddit.com/r/datascience/comments/dj65nj/so_its_often_said_that_to_break_into_ds_requires/,dj65nj,so_its_often_said_that_to_break_into_ds_requires,asylumsforthefeeling,0.92,109,2019-10-17 15:08:11,0,88,,"I mean, let's assume I came prepared for the job with fluency in the most in-demand skills: SQL, Statistics, proficiency in R and Python, data modeling, etc. Could I get a job with just those skills, or would I STILL probably need a master's?",,"Career,"
507,https://www.reddit.com/r/datascience/comments/djgcxo/learning_to_rank_project_to_enhance_your_career/,djgcxo,learning_to_rank_project_to_enhance_your_career,xyz_TrashMan_zyx,0.63,5,2019-10-18 03:45:32,0,18,,"I am working a Learning to Rank solution for a major travel company. Using Keras and TensorFlow, I have a basic RankNet solution. All is fine, however dealing with massive amounts of data using PySpark is new to me and I want a side project for the weekends to try out new models, and to create an open source initiative for Learning To Rank for product search and for web search.Call me Naive but I want to build an end to end search appliance that uses Spark, Keras, and maybe PyTorch, and a handful of learning to rank approaches to real world problems like web search. I know you can use ElasticSearch and that's great but you can use a learning to rank approach as well.I'd like to get my hands on large data sources, and work together with a virtual team, meeting online every couple weeks to go over progress on a distributed open source Learning To Rank github project.Any takers?",,"Networking,"
508,https://www.reddit.com/r/datascience/comments/dizbcz/i_built_chatstats_an_app_to_create_visualizations/,dizbcz,i_built_chatstats_an_app_to_create_visualizations,stalf,0.94,357,2019-10-17 03:36:52,0,65,,,https://i.imgur.com/1gmKEiz.jpg,"Projects,"
509,https://www.reddit.com/r/datascience/comments/djjq4o/anyone_want_to_chime_in_on_this_relatively/,djjq4o,anyone_want_to_chime_in_on_this_relatively,[deleted],0.67,1,2019-10-18 08:56:32,0,6,,,https://www.reddit.com/r/MachineLearning/comments/djc7dq/d_should_you_standardize_your_numerical_features/,
510,https://www.reddit.com/r/datascience/comments/dj9qvb/imbalanced_targets_for_regression/,dj9qvb,imbalanced_targets_for_regression,rrthirumulu,0.88,6,2019-10-17 19:34:39,0,17,,"Anyone ever dealt with imbalanced targets when fitting a regression model? For example, I am trying to predict order values for customers coming to a website and most customers do not purchase.  I know about techniques for dealing with imbalanced classification but haven't found much on regression for imbalanced targets.",,"Education,"
511,https://www.reddit.com/r/datascience/comments/dj5ylt/how_to_do_feature_selection_in_a_given_situation/,dj5ylt,how_to_do_feature_selection_in_a_given_situation,RosmarysBabyBjorn,1.0,7,2019-10-17 14:51:54,0,4,,"It seems like everyone has a different method for feature selection. Some folks use domain knowledge to select features that have a conceptual link with the dependent variable (domain knowledge being either advice from SMEs about which features matter most or the data scientist's own knowledge of the field). Others use statistical methods to select features (e.g., correlation matrices, traditional one-to-one statistical tests, regression coefficients). Finally, some use computational methods such as autoML or techniques like random forest which implicitly do autoML by cycling through combinations of features. Is there a heuristic to determine when to use which feature selection method? I'm sure the answer is that a hybrid approach is best. But surely there are situations where it makes sense to lean in one direction.",,"Discussion,"
512,https://www.reddit.com/r/datascience/comments/dj19a8/how_on_earth_do_companies_expect_someone_to_know/,dj19a8,how_on_earth_do_companies_expect_someone_to_know,asylumsforthefeeling,0.66,16,2019-10-17 06:28:09,0,43,,"Seriously. So many companies I've looked into expect you to have thorough, in-depth and masterful knowledge and skills in areas of statistical modeling, neural networking, programming, etc. And I don't just mean have enough skill to make yourself feel impressed by your own abilities. I'm talking like having the skills a senior software developer at a company.Like, what? Why do they make breaking into DS so damn complicated and hard? Are they purposely trying to weed out those who have practical experience from those who have experience AND a Master's degree?",,"Discussion,"
513,https://www.reddit.com/r/datascience/comments/diu5dv/multiprocessing_vs_threading_in_python_what_every/,diu5dv,multiprocessing_vs_threading_in_python_what_every,SkullTech101,0.94,76,2019-10-16 21:13:38,0,14,,,https://sumit-ghosh.com/articles/multiprocessing-vs-threading-python-data-science/,
514,https://www.reddit.com/r/datascience/comments/diwnkb/career_advice_in_ml_and_how_to_read_research/,diwnkb,career_advice_in_ml_and_how_to_read_research,deep_ak,0.87,37,2019-10-17 00:05:17,0,10,,Here I have made notes of the Deep Learning CS230 Lecture given by Andrew Ngon how to navigate a career in ML/DL and how to read research papers.https://deeps.site/blog/2019/10/14/reading-research-papers-career-advice/The one hour lecture has been summarised into concise 5 minutes read to save out on your time withvisualisations to enrich the delivered content.Hope it helps you to build on top of Andrew's insights and save time.,,"Career,"
515,https://www.reddit.com/r/datascience/comments/dj9490/so_i_know_theres_a_dedicated_sub_for_it_but_posts/,dj9490,so_i_know_theres_a_dedicated_sub_for_it_but_posts,asylumsforthefeeling,0.54,1,2019-10-17 18:50:13,0,3,,I know that BI tends to focus on the reporting of past business experiences and decisions while DS can focus on predictive analytics and future business decisions. But I just didn't know if people actually have a career in just BI and what mobility from entry level positions in that field is like.,,"Career,"
516,https://www.reddit.com/r/datascience/comments/dijadz/an_easy_guide_for_choosing_visual_graphs/,dijadz,an_easy_guide_for_choosing_visual_graphs,vulpinecode,0.97,989,2019-10-16 05:16:23,0,35,,,,"Education,"
517,https://www.reddit.com/r/webexpert/comments/dij8kt/an_easy_guide_for_choosing_visual_graphs/,dij8kt,an_easy_guide_for_choosing_visual_graphs,lokendra15,0.99,168,2019-10-16 05:12:14,0,3,,,,
518,https://www.reddit.com/r/datascience/comments/diufp0/are_there_other_thinkers_with_different_ideas_in/,diufp0,are_there_other_thinkers_with_different_ideas_in,CatOfGrey,0.96,22,2019-10-16 21:32:53,0,15,,"I'm looking through some old books, including the classic ""The Visual Display of Quantitative Information"".It got me wondering:  are there any alternate viewpoints, critics, some other perspectives in the world of data science, that have new ideas on presentation of data?What else should I be reading and learning about in this area?",,"Discussion,"
519,https://www.reddit.com/r/datascience/comments/disqg5/optimizers_in_neural_networks_explained_the_math/,disqg5,optimizers_in_neural_networks_explained_the_math,permalip,0.89,19,2019-10-16 19:35:25,0,0,,,https://mlfromscratch.com/optimizers-explained/,"Discussion,"
520,https://www.reddit.com/r/datascience/comments/dipri2/a_guide_to_web_scraping_without_getting_blocked/,dipri2,a_guide_to_web_scraping_without_getting_blocked,BobbyTaylor_,0.66,24,2019-10-16 16:04:48,0,9,,,https://www.scrapingbee.com/blog/web-scraping-without-getting-blocked,"Education,"
521,https://www.reddit.com/r/datascience/comments/dizjbr/seeking_post_comic_of_data_common_data_mistakes/,dizjbr,seeking_post_comic_of_data_common_data_mistakes,ALonelyPlatypus,0.67,1,2019-10-17 03:55:18,0,3,,A couple months back there was a comic posted here that visually explained the top data mistakes.I hate to be a bother but does anybody have a link to that post? I’ve tried a few searches but have yet to find the right keyword.,,"Discussion,"
522,https://www.reddit.com/r/datascience/comments/dif0wi/doing_data_science_on_your_own_can_be_frustrated/,dif0wi,doing_data_science_on_your_own_can_be_frustrated,MeanTemperature,0.95,139,2019-10-15 23:44:55,0,67,,"So basically I started my own little DS project with a good friend (using twitter data). The Problem is he is kind of lazy and doesn’t take the problem as seriously as me (doesn’t have a quantitative background).Which is why I’m looking for collaborators motivated to do DIY-projects. The main point of the project shall be to gain practical experience with datascience projects and methods (maybe in the form of Blog Posts) as well as all the surrounding stuff like git and issues when collaborating.I plan working on the project ~10 to 20 hrs a week. I contribute a background in quantitative research, advanced stats (such as SEM and stuff), basic data analysis and psychology (masters degree) and as well as project management. I am experienced in R, SPSS and am getting into python and Java right now.I know this is an unusual idea but maybe I could spark someone’s interest for shared projects. I think that splitting the boring stuff will take us quicker to the exciting stuff and cool insights.Feel free to pm me or answer here.EDIT: Sorry for the typo in the title. I mean frustrating of course, not frustrated.",,
523,https://www.reddit.com/r/datascience/comments/diwleg/an_interesting_idea/,diwleg,an_interesting_idea,schlammybb,0.25,0,2019-10-17 00:01:25,0,1,,"Stereo audio in video helps create an immersive experience, and often you can tell when audio is recorded and overlaid on top of video content. What if you could train a neural network to modify pre-recorded audio to sync up with the visual input from a video. Has this been done already?",,
524,https://www.reddit.com/r/datascience/comments/dihp0e/would_you_consider_this_a_bait_and_switch/,dihp0e,would_you_consider_this_a_bait_and_switch,fread9999,0.94,13,2019-10-16 03:06:09,0,16,,I was hired to manage a data science team focused on modeling and analysis . I was expecting predictive modeling from the interviewInstead the company has had me automate all their reporting processes with alteryx and revamping the formatting of their tableau dashboardsDo you think this is big enough of a job description change to complain ? How would you handle it ?,,
525,https://www.reddit.com/r/datascience/comments/dibkt1/alternative_methods_to_associations_rule_mining/,dibkt1,alternative_methods_to_associations_rule_mining,mrdlau,0.93,25,2019-10-15 19:52:21,0,15,,"I’ve been pretty deep into association rule mining using market basket analysis style technique to figure out “if someone buys {x,y}, then they will also buy {z}”.Besides the market basket approach(using support, confidence, lift etc), are there any other ‘machine learning’ deep learning methodologies that can be used for this type of problem?I’m looking to try something different just to compare results  and try something new",,
526,https://www.reddit.com/r/datascience/comments/di4pcp/if_you_work_with_a_data_team_ide_love_to_know_the/,di4pcp,if_you_work_with_a_data_team_ide_love_to_know_the,leenas9,0.97,116,2019-10-15 10:11:14,0,49,,"Hi everyone,I am trying to understand the working and collaboration dynamics of data teams. I'd love to learn about some first-hand experiences/challenges that you may have faced. Or if you can point me towards any resources.",,"Discussion,"
527,https://www.reddit.com/r/datascience/comments/dic7z8/regression_analysis_for_30k_products_help/,dic7z8,regression_analysis_for_30k_products_help,itslit96,0.73,11,2019-10-15 20:36:16,0,25,,"Hi all, I need some assistance with a current work project I am taking on. I work for a company that has over 30k items, and I am being tasked with updating MRP mins and maxes but first I think it is necessary to find the trends of the products (using past 3 years) which I have obtained from SAP we use. I need some guidance on the most efficient way to create a regression on each item for the past 36 months, is there a way to apply a regression analysis to an entire data set? Or any recommendations on how to appropriately forecast future sales based on the historical data I have.I'd appreciate any help, thanks !!",,"Projects,"
528,https://www.reddit.com/r/datascience/comments/dihvyh/project_portfolio/,dihvyh,project_portfolio,gingaslaya2,1.0,1,2019-10-16 03:21:28,0,2,,"Heyo! I’m an MIS major currently working at a great internship.  I would like to add some reports and other things I have built to my portfolio. Problem is, those items have sensitive company data. How can I add PBIX files/screenshots without giving away company data? Thanks in advance!",,"Projects,"
529,https://www.reddit.com/r/datascience/comments/dihlec/instagram_followers_scraping/,dihlec,instagram_followers_scraping,sideshowbog,0.33,0,2019-10-16 02:58:26,0,4,,I've read many articles that were saying that IG's API can't show followers. So I was thinking about getting those followers to DB by scraping from browser and parsing those who dont follow back for example. And after that I would perform many operations with them. I don't have much experience with it scraping tho. What language would be the best to do it? I was thinking about doing it with Node.js  and Puppeteer or maybe Java with Selenium.,,"Projects,"
530,https://www.reddit.com/r/datascience/comments/di87e6/question_about_how_to_construct_an_arima_time/,di87e6,question_about_how_to_construct_an_arima_time,Zenith_N,1.0,7,2019-10-15 15:51:35,0,9,,"So just so i am clear.When ever I want to add regressors (extra features) aside from the time series that I am trying to predict:1- predict the future numbers for the regressor(s) - eg. ""Weather"" using a model  --- this would be my future values to include later on in the ARIMA mdoel.2- When creating the ARIMA model for for my original time series add the exogenous variable as the second feature while matching the same timeline for example: timeseries one = Sales and time series 2 (exogenous == Weather), (making sure that this matches the time frame eg. January 2010 to December 2010 for both Sales and Weather.3- When making forecasting using the ARIMA model I add the ""predicted"" values for ""Weather"" that I had already forecasted in step ""1"", and add that as the second regressor while matching the n_periods I want to predict for ""Sales"".Is that correct ?Thank you",,"Discussion,"
531,https://www.reddit.com/r/datascience/comments/di087w/dataset_to_detect_inappropriate_contentnudity/,di087w,dataset_to_detect_inappropriate_contentnudity,Nike_Zoldyck,0.87,29,2019-10-15 03:00:59,0,11,,"I'm looking for some information on how the content filtering works in Facebook, Instagram etc to flag nudity, violence, offensive or toxic comments,religious and racial stereotypes etc. I wasn't able to find any scientific papers about the inner workings or the use of deep learning or Computer vision for it. I'm fairly new to CV and i'm hoping for some guidance on a data set , perhaps for detecting inappropriate content on T-shirts in retail. Any suggestions on how to go about searching or to create a dataset and what to keep in mind? Any algorithms to focus on like yolov3 or faster RCNN to read the text on the t-shirts and understand the context of it would also be extremely helpful",,"Discussion,"
532,https://www.reddit.com/r/datascience/comments/di5cf3/facebook_prophet_forecasting_trend_prediction_how/,di5cf3,facebook_prophet_forecasting_trend_prediction_how,Scutterbum,1.0,6,2019-10-15 11:25:07,0,9,,"I've been following along with some Prophet tutorials, and I'm always wondering what the point of the 'plot_components` function is for. The confidence band for the predicted trend always goes in both directions, up and down.For example in these three examples, from three different tutorials, the predicted trend could go up or down. It's just looks like a wild guess.Am I interpreting this correctly? Why do I need this time series package to analyse trends if I can just guess it myself?Sample tutorial from facebook themselves: https://facebook.github.io/prophet/docs/quick_start.html#python-apiNote: I am completely new to time series so I may not be understanding some aspect of these plots.",,"Tooling,"
533,https://www.reddit.com/r/datascience/comments/dib68q/need_help_source_of_python_syntax_for_common/,dib68q,need_help_source_of_python_syntax_for_common,superbconfusion,0.5,0,2019-10-15 19:24:32,0,9,,"Hey guys!I have an interview next week and there's a 45 minute live coding section on modern data science techniques. Fine. The only problem is I've been using R for all my data science for the past couple of years.Is there anywhere I can find this is one easy place?Let me know if this should be in entering and transitioning. I'm already a data scientist so felt I could post it onto the main group.Worth noting that it explicitly says they're not expecting me to code from memory first time, but I would like to familiarise myself with the language a bit before going to interview.Thanks!",,
534,https://www.reddit.com/r/datascience/comments/di9yoq/is_it_worth_keeping_putting_certificates_on_your/,di9yoq,is_it_worth_keeping_putting_certificates_on_your,Likewise231,0.67,1,2019-10-15 18:01:51,0,13,,"I am eco and business student, will do masters in BI/Data Science (Before anyone says better learn on your own - education is free here).I studied R and SQL on my free time. I used 2nd hand accounts studying some 90-hour worht of material that in the end results in a certificate that proves i did that. I am planning to another 100-hour worth of material (20 courses x4-5hours) to get a better understanding of Python. I have always been sceptical about people putting certificates on their linkedin profile, it seems like a fkin joke for me, but then i thought - well , thats a 100hour course, so i am at a situation where i am not sure whether they are completely useless in front of employer or they do have a little bit of value -for example my Masters degree cointains SQL+R+stats,ML ,research mathods etc but has no python in curriculum, but if i apply for a job with Python, maybe a 100h certificate would mean something?So i'd like people to tell me if it matters even a little bit? For example in my masters degree i wont have as much python and having something showing i did python might help? Or not really? How do employers look at certificates like that? Is it a joke and a big no no, or it can still act as some low-quality evidence you did something?",,"Education,"
535,https://www.reddit.com/r/datascience/comments/dhu7ab/analyzing_impact_of_feature_deployment_without_ab/,dhu7ab,analyzing_impact_of_feature_deployment_without_ab,The_Dakota_Kid,0.92,53,2019-10-14 19:49:36,0,37,,"Without consulting me, my company rolled out a new checkout process on our website and are now asking me for an impact analysis. This process is significantly different than the previous process and is much more demanding in terms of customer involvement(The customer is required to supply much more information). I would have gone the route of A/B testing to accurately measure impact, but since this after-the-fact, that approach is not in the cards. Our business is highly cyclical and we offer specific products in specific markets. Competition is also very high and competitor offers change frequently but significantly impact sales. I’m inclined to advise that they roll back the deployment and then conduct an A/B testing experiment in order to take a more scientific approach.Any thoughts on approaching this?",,
536,https://www.reddit.com/r/datascience/comments/difcq6/not_every_company_needs_data_science_or_machine/,difcq6,not_every_company_needs_data_science_or_machine,nouseforaname888,0.35,0,2019-10-16 00:07:41,0,10,,"We all hear the buzz about how data is the new oil or data is digital gold. Or we hear about how machine learning will change lives for the better.However, so many companies and teams don’t need data science. To use data science and machine learning effectively, you need a large amount of data. Not every company has nearly as much data generated as amazon or google or Facebook of Netflix does. Great examples of such companies that don’t need data science for now are early stage startups. You need to first build a product that customers use before you get a large amount of data. To gather that much data takes quite a while.So data science roles are likely to be more directed toward big companies with lots of data or certain startups that hit it big Eg uber before its ipo.My point of this post is data science is valuable but it isn’t the solution for every team or company.",,"Discussion,"
537,https://www.reddit.com/r/datascience/comments/die673/hello_guys_where_can_i_find_a_tutorial_on_how_to/,die673,hello_guys_where_can_i_find_a_tutorial_on_how_to,shizzyy67,0.14,0,2019-10-15 22:46:43,0,3,,,,
538,https://www.reddit.com/r/datascience/comments/dhh2qg/siraj_gets_caught_called_out_for_plagiarizing_a/,dhh2qg,siraj_gets_caught_called_out_for_plagiarizing_a,back50,0.97,511,2019-10-13 23:45:05,0,88,,,https://twitter.com/AndrewM_Webb/status/1183150368945049605,"Discussion,"
539,https://www.reddit.com/r/datascience/comments/dhqekt/overview_of_the_juliapythonr_universe_for_data/,dhqekt,overview_of_the_juliapythonr_universe_for_data,open_risk,0.78,20,2019-10-14 15:14:44,0,26,,"Jupyter and its moonsA project to add Julia as a third pillar in the frequent comparisons of Python and R (plus a linked proposal to develop Python (Data Science) Task Views)The motivation stems from the fact that open source data science ecosystems can benefit more from cross-fertilization of ideas / best practices and easy interoperability of all three systems, as each one brings rather unique features to the table.The overview page (this is a standalone entry in a public mediawiki that otherwise supports open source risk management)The data are structured in subdomain specific tables (statistics, econometrics, etc. etc.) with links to packages or documentationEach table incoporates (as its last row) relevant R CRAN Task Views. The idea is to have also a similar structure for Python, aka Python Task Views. Effectively Python Task Views would be a collarative repo + linked github Pages that offers a more structured alternative to existing awesome lists. Potentially each subdomain will be moderated by one or more domain experts (volunteer moderators welcome!)License is Creative Commons Attribution Share Alike 4.0 InternationalAll and any feedback is welcome",,"Projects,"
540,https://www.reddit.com/r/datascience/comments/dhoh6l/question_how_to_fit_a_discrete_distribution_over/,dhoh6l,question_how_to_fit_a_discrete_distribution_over,uakbar,1.0,5,2019-10-14 12:05:30,0,5,,"So, I have streaming data (access to only a mini-batch at a time and I DO NOT want to save data in memory), and I want to fit a discrete distribution over it. But I don't know a-priori how many components k there are, and what's worse is that the components can increase as well as decrease over time.If k were the same always, I could have just used a kalman filter, or an exponentially weighted averaging filter. But because k can (and will) change over time (but will converge in the limit to some unknown k' ), I am not exactly sure how to tackle this problem.Thanks!",,
541,https://www.reddit.com/r/datascience/comments/dho11l/as_a_data_science_major_should_i_participate_in/,dho11l,as_a_data_science_major_should_i_participate_in,Humble_muslim,0.62,2,2019-10-14 11:12:01,0,13,,"This is my first year as a data science major, and I currently have very little data science-knowledge.I was wondering if participating in programming contests (specifically ICPC) would be useful for that career path... or is it just a computer science/ software engineering thing?",,"Education,"
542,https://www.reddit.com/r/datascience/comments/dhav70/so_can_someone_have_a_career_in_data_science/,dhav70,so_can_someone_have_a_career_in_data_science,asylumsforthefeeling,0.81,35,2019-10-13 15:54:26,0,59,,"I mean, I always hear about how data science and machine learning go hand-in-hand. But, what if ML just doesn't interest me and I just like working with data for a company?",,"Career,"
543,https://www.reddit.com/r/datascience/comments/dhe1li/new_public_wiki_handwiki_for_data_science_and/,dhe1li,new_public_wiki_handwiki_for_data_science_and,jconcode,0.83,15,2019-10-13 20:03:36,0,0,,,https://handwiki.org/wiki/,"Projects,"
544,https://www.reddit.com/r/datascience/comments/dh3s7y/how_do_large_data_science_teams_work_together_and/,dh3s7y,how_do_large_data_science_teams_work_together_and,RareMeasurement2,0.97,127,2019-10-13 03:04:17,0,49,,"I've always found this perplexing since the entire Data Science profession appears to be so individualistic on the surface. Considering that the ideal Data Scientist is supposed to be an expert at software development, databases, statistics, mathematics, machine learning, deep learning, I often wonder how work actually gets done in teams in say a real job.If you look at other professions say Game development, which pretty much is focused on pushing out a software product (the game) to consumers, the job titles are often clearly defined, and normally broken down into distinct roles of Developer, Artist, Writer and Composer. This is just a gross exaggeration for a  typical indie team (AAA games would have legions of employees), but it is still quite rare if one person does everything.Now, back to data science - if you had people with PhDs in Maths, Statistics, Computer Science or Physics, how are the tasks even delegated if everyone on the team is at the same education or expertise level? Taking the typical Data Science workflow in mind, surely one of them would be extremely annoyed if all they were assigned to do was data cleaning?Would appreciate if anyone actually working in the industry be able to shed light on this topic.",,"Discussion,"
545,https://www.reddit.com/r/datascience/comments/dhkbbz/data_set_for_estimating_jobskill/,dhkbbz,data_set_for_estimating_jobskill,ant-wife,0.5,0,2019-10-14 04:30:48,0,1,,"Hey there,Is anyone aware of any algorithms/models that try to extrapolate number of people whose jobs will disappear based on AI/technological innovations and/or new job areas that will open up? Any data sets relating to this would be much appreciated!",,"Projects,"
546,https://www.reddit.com/r/datascience/comments/dh9osl/weekly_entering_transitioning_thread_13_oct_2019/,dh9osl,weekly_entering_transitioning_thread_13_oct_2019,datascience-bot,0.87,10,2019-10-13 14:00:28,0,147,,"Bleep Bloop. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki. You can also search for past weekly threads.I am a bot created by the r/datascience moderators. I'm open source! You can review my source code on GitHub.",,"Discussion,"
547,https://www.reddit.com/r/datascience/comments/dhg1p2/recommendations_for_articles_on_doing_data/,dhg1p2,recommendations_for_articles_on_doing_data,tmf1988,1.0,2,2019-10-13 22:27:08,0,1,,"I can't search Google for relevant articles because I keep getting 50,000 recommendations for Youtube data science channels.A friend is launching a screencast series on VUE.js, and wants me to do some data science with the analytics that will eventually be generated. I've never worked with Youtube data or their backend and would like some pointers from anyone who has.",,"Education,"
548,https://www.reddit.com/r/datascience/comments/dhchq2/extracting_movie_titles_from_text_source/,dhchq2,extracting_movie_titles_from_text_source,johnnMackk,0.5,0,2019-10-13 18:06:03,0,7,,"Hey guys,I would like to extract movie titles out of any block of text. I have a few ideas of how I could do this but I would love to get your recommendations.My main idea was to take note of the words and phrases used around the Movie names and write a regex to extract them.eg.  ""I really like Home Alone."" or ""Jurassic Park is awesome!"".The regex would look for the following patterns ""really like [a-zA-Z\ \d]"" and ""[a-zA-Z\ \d] is awesome"". I could also look for capitalized words but this is less accurate.I have never done any data mining before so not too sure how to get started with this.Thanks",,"Projects,"
549,https://www.reddit.com/r/datascience/comments/dgz01q/ml_model_to_predict_delay_in_accounts_receivable/,dgz01q,ml_model_to_predict_delay_in_accounts_receivable,Nero-4,0.86,46,2019-10-12 20:35:12,0,10,,"I have the accounts receivable data for the past few years and am working on a ML model to predict whether a future payment will be delayed or not (0 - No Delay, 1 - Minor Delay, 2 - Major Delay). Each invoice also has the amount associated with it, along with the timestamp when invoice was generated, timestamp it was paid, details of the customer etc.I am thinking of creating features such as week number of invoice, Year of invoice (to take care of the seasonality and trend), and the customer reliability score based on their payment history (for new customers, it will just be the mean).To evaluate the model, I will accuracy and F1 score. And maybe also consider the potential amount delayed (amount delayed * delay weight (0 - no delay, 1 - minor delay, 2 - major delay).Does the approach and evaluation metrics make sense? Anything I should keep in mind or do differently?",,"Discussion,"
550,https://www.reddit.com/r/datascience/comments/dh68e8/how_to_classify_if_we_are_the_lead_bank_for_a/,dh68e8,how_to_classify_if_we_are_the_lead_bank_for_a,StrictlyPlutonium,1.0,3,2019-10-13 06:59:44,0,7,,I am trying to identify if our clients use us as their main/primary bank or if they use a different bank.I can look at their transactions and try to see if they use their debit card a lot or do lots of ach transactions. If they have direct deposit/payroll coming in but just enough to pay their mortgage and no other transactions then this could mean they use someone else for their primary bank.There is no dependent variable that says a client is our main bank. So I would be having to guess essentially if the features I pick describes this behavior.I was thinking of creating a scoring model where each different type of transaction will have a value assigned to it and if the client reaches a certain score then I can estimate that we are the lead bank.How do you guys think I should tackle this?,,"Discussion,"
551,https://www.reddit.com/r/datascience/comments/dglmy6/microsoft_open_sources_sanddance_a_visual_data/,dglmy6,microsoft_open_sources_sanddance_a_visual_data,cdlm89,0.98,313,2019-10-11 23:32:15,0,16,,,https://cloudblogs.microsoft.com/opensource/2019/10/10/microsoft-open-sources-sanddance-visual-data-exploration-tool/,"Tooling,"
552,https://www.reddit.com/r/datascience/comments/dgr8bb/help_me_understand_what_ab_testing_looks_like_at/,dgr8bb,help_me_understand_what_ab_testing_looks_like_at,myfriendscode,0.87,48,2019-10-12 08:01:24,0,12,,"So I get that A/B testing is basically using statistical tests in industry. But what are the best practices/models to use? If I have control group data, user test data, and data from before the experiment even started, which sets would lead to the strongest conclusion? Idk if this question even makes sense, I'm just trying to get a firmer understanding of what I'm being taught and see how it can be applied beyond the classroom.",,"Education,"
553,https://www.reddit.com/r/datascience/comments/dh4p3w/how_do_i_map_a_large_set_of_unique_values_of_job/,dh4p3w,how_do_i_map_a_large_set_of_unique_values_of_job,ByMAster2,0.33,0,2019-10-13 04:27:37,0,4,,"I am working with a data problem that involves predicting the income of the person.One of the features of this dataset is 'Job Profession'. Now in this column of the profession, there are a set of distinct unique names. Here are some of the values --> https://pastebin.com/rrD3P1WrNow I want to map these jobs into industries which they are representing to reduce the dimensions in my model. So can someone suggest me on how should I go about mapping them?",,
554,https://www.reddit.com/r/datascience/comments/dgq8yy/enterprise_platforms_dataiku_databricks_knime/,dgq8yy,enterprise_platforms_dataiku_databricks_knime,question_23,0.83,8,2019-10-12 06:14:11,0,13,,"We're looking into these at work and it's surprisingly hard to find recent user experiences on them. Basically we want something that makes it easy to schedule and deploy our models (Python scripts or Jupyter Notebooks). We don't have the technical resources to be building Dockerfiles from scratch, and we really want something idiot-proof since some of these will be mission critical and central to our company's work. Something with integrated version control (based on Git) would be nice. We are not interested in drag-and-drop GUI machine learning pipelines, we're comfortable with our Python/Jupyter Notebook workflow. It has to work behind a firewall. It should have robust user management with permissions etc. We just need something to take our models to production in a smooth, organized way.We've looked mostly at Anaconda Enterprise, but it's hard to find user experiences with it. There isn't a free trial but it looks otherwise like a good fit for us. Just wondering what other people have used for this type of work in corporate environments.",,"Tooling,"
555,https://www.reddit.com/r/datascience/comments/dge7wh/whats_your_typical_data_pipeline_in_a_small/,dge7wh,whats_your_typical_data_pipeline_in_a_small,DiogenicOrder,0.98,126,2019-10-11 14:08:25,0,79,,"I'm curious about how, when working in smaller infrastructures, one creates a data pipeline ?For those of you who are one person or two person teams. What tools do you use from beginning to end to analyze data and build models ?Thanks",,
556,https://www.reddit.com/r/datascience/comments/dgdlxb/the_state_of_machine_learning_frameworks_in_2019/,dgdlxb,the_state_of_machine_learning_frameworks_in_2019,Sargaxon,0.8,44,2019-10-11 13:09:43,0,17,,,https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/,"Discussion,"
557,https://www.reddit.com/r/datascience/comments/dg1xtc/pytorch_released_v130/,dg1xtc,pytorch_released_v130,scopsy,0.98,179,2019-10-10 20:08:08,0,42,,,https://app.releasly.co/releases/pytorch/pytorch/1_3_0,
558,https://www.reddit.com/r/datascience/comments/dgjcw2/question_regarding_database_design_for_research/,dgjcw2,question_regarding_database_design_for_research,Fishparkay,0.4,0,2019-10-11 20:41:07,0,9,,"Hi Reddit world,A little background about myself...My background is in epidemiology and biostatistics. I have about 10 years of experience working within this sector at progressive levels. The institution is divided into a pre-clinical side and a clinical side. Much of my past experiences have been providing quantitative analysis to aid in improving the performance of care teams, improve quality of care, improve patient and staff experience, and of course reduce costs.Now, I recently (very recently) started a job as an analytics manager at a psych research institution. I'll try to break the organization fairly simple -- there is a clinical side and a pre-clinical side. On the clinical side, there are clinicians mainly doing paper-based assessments ( that I hope to transition to a digital collection tool at some point) which clinical coordinators (fresh college grads) are manually entering in the information into excel spreadsheets. For some studies, data is double entered ( 2 coordinators entering information, and appending the info into one spreadsheet). There are about 7 coordinators, each working on various projects that the others are not involved in. There are more issues, but this is just an idea.One clinician prefers to use RedCAP, so there is not common collaboration with respect to data collection across investigators.Clinicians will then either export from RedCAP or import the excel files to SPSS in order to conduct the analyses.I recently took a look at the data that has been collected, and it is in bad shape, to say the least. No data validation, no integrity. No uniform coding structure across the board (i.e. one study has a coding scheme, another completely different. There is an ID system in place for each study, however, it is not consistent because historically the ID was not used--and even now it isn't inputted consistently. Some worksheets in excel have about ten separate tables within that should be their on spreadsheets. Free text notes have been placed all over the spreadsheet in some places ( as im sure the coordinators/ clinicians have no idea about structured data.Not the pre-clinical side would like to access this data and/or easily view summaries of this data at any given time (however this should be de-identified on the clinical side for security reasons).There is also a wetlab, so we would like to track samples connected to the study participants as well.Now I would love to have a repository for structured, filtered data that has already been processed ready for Adhoc queries.I would love to have a data collection system in place that is easy to use for the coordinators, and that has data validation checks so they enter in the right information. Possibly some sort of form-based entry systemI would love for whatever database system is in place to allow for easy export to SPSS since the clinicians are comfy with that software and I dont want to reinvent the will. Most use SPSS on the clinical side for analysis, with R being the preferred package on the pre-clinical side.My initial thought was toclean all the data so it is structured in a correct manner ( just the thought seems tedious because not only is the current data protocol all over the place, we dont want to lose historical data for studies that have already been completed. We would have to migrate to the new format to include it newly designed database.Attempt to link all tables created on the clinical side, preclinical, and lab via a study ID/participant ID and possibly create a form for end-users to select the variables they would like to create a dataset from in order to complete the analysis they desire to perform.I would like the system implemented to allow me to create a live dashboard for a few metrics for the director to access at any time ( I was thinking possibly a Rshiny App?). Probably would need a login/authenticator along with it.I am also thinking about future scalability ( this is why using MS Access to solve the problem concerns me)My question to you--how should I best attack this problem and what is the optimal solution? I am able to use the coordinators to clean data, so that part won't be as tedious, but I also want a solution that is the simplest and less difficult for me to implement. I would appreciate any and all advice!Thanks in advance!",,"Discussion,"
559,https://www.reddit.com/r/datascience/comments/dg1vs8/150_successful_machine_learning_models_6_lessons/,dg1vs8,150_successful_machine_learning_models_6_lessons,maxmoo,0.94,12,2019-10-10 20:04:16,0,0,,,https://www.google.com.au/amp/s/blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/amp/,
560,https://www.reddit.com/r/datascience/comments/dfix5q/the_term_data_scientist_is_so_loosely_defined_by/,dfix5q,the_term_data_scientist_is_so_loosely_defined_by,nouseforaname888,0.93,297,2019-10-09 17:48:30,0,123,,"At some companies, data scientist is a person who creates monthly counts of customers and never works with machine learning. Even though the title is data scientist, this really should be a business or data analyst.At other companies, a data scientist is a person who builds data pipelines along with data analysis reports even though that should be a data engineer.And at other companies, a data scientist is someone who reads academic papers and writes software to translate those papers into software production code that is used by other teams. This should be a machine learning engineer but companies define it as data scientist.This along with the large number of data science graduates every year is creating a huge supply of people who call themselves data scientists. This makes it really difficult for hiring managers to wade through this supply of candidates to find the right person for the job.",,"Discussion,"
561,https://www.reddit.com/r/datascience/comments/dfr04a/data_science_business_strategy_intersection/,dfr04a,data_science_business_strategy_intersection,mikee_autee,0.81,20,2019-10-10 03:42:44,0,17,,"I'm a data scientist who enjoys applying data driven driven analysis to drive business strategy. In looking for opportunities I'm curious what industries foster these types of hybrid roles and even what job title I should be looking for.Day to day I like writing sql, doing analysis in python, building decks and gaining buy in for my business strategy projects.  Modeling and development work are in my tool kit but not what I want to build my career around. Any advice on how to grow and look for opportunities within this hybrid niche?",,"Job Search,"
562,https://www.reddit.com/r/datascience/comments/dfpphy/seguing_from_data_science_to_data_engineering_or/,dfpphy,seguing_from_data_science_to_data_engineering_or,Robin_Banx,0.86,27,2019-10-10 01:57:43,0,11,,"Anyone got any tips on transitioning to either Data Engineering or ML Engineering?  I need to work remotely due to disability, and it seems like there's just A LOT more engineering positions than Data Scientist positions (especially ones that are okay with being 100% remote from day 1).Have about a decade of experience in some-version-of-Data-Science (counting my first role which was using SPSS in a lab in undergrad).  Undergrad gave me a strong stats background, but I'm self-taught with coding.  I've been doing Python data science for about 6 years now, and I think I'm pretty good at Data Scientist Code Practices (packaging things into neat & tidy functions, descriptive names, even fallen in love with Type Annotations), and am very good with pandas & friends, and SQL (or at least the retrieval side).Buut I don't really have much Proper Software Engineering experience - I've written simple pipelines for clients (one's running to this day, and it emails me every day about it =D ) but it was always kind of ad-hoc.  I never really learned proper stuff about Testing, or even what else I don't know that maybe I'd need to.  I also find it kind of panic-inducing to touch live infrastructure, but hopefully I'd get used to that  =D  I do know my way conceptually around the different AWS & GCP services, though.I do like the Data Science part best, but honestly I legitimately enjoy designing data cleaning schemes too.  I wouldn't necessarily mind if that was my primary duty.  From what I've read about what ML Engineers do, sounds like I wouldn't necessarily mind that either (at least the parts that were familiar - setting up scripts to retrain models and serve up predictions and such).  Plus, again, seems like there's just a lot more work out there (especially remote) for these than for Data Science.Any tips or resources to recommend for either?  Most of the things I found seem to assume that you're a Software Engineer, haven't really found anything that's aimed at people who are starting from the Data Science side.Also, any advice as to which might be easier or more fun or just overall better move from Data Science?  Or just any stories to share from/about people who have made that move?Other assorted questions:What, if anything, should I know about Java?  I find those Spark stacktraces to be kind of terrifying - as a proper Data Engineer, would I imagine they'd come up a lot?Should I pick up Scala?  For one?  For either?  PySpark always seemed a little behind.  I do like Functional Programming a lot - I picked up Clojure on a whim a few years back, and I basically write Python as Functional as possible.Thanks!(Sorry if this belongs in the megathread, but it looked like that's more for getting into Data Science as opposed to starting with Data Science)",,"Career,"
563,https://www.reddit.com/r/datascience/comments/dfj62s/vs_code_has_a_jupyter_notebook_ui_now/,dfj62s,vs_code_has_a_jupyter_notebook_ui_now,evilcubed,0.98,100,2019-10-09 18:05:48,0,12,,"I just noticed that when I open a Jupyter notebook file now in VS Code, it opens in a Jupyter like UI. It looks similar to Jupyter Lab from what I can tell, but I guess I get the auto complete stuff in the cells which is pretty cool. Going to test it out more.",,"Tooling,"
564,https://www.reddit.com/r/datascience/comments/dg3xyj/have_you_ever_seen_simulation_techniques_and/,dg3xyj,have_you_ever_seen_simulation_techniques_and,ajaderade,0.25,0,2019-10-10 22:22:39,0,1,,"Pondering about the applications, and efficiency of using machine learning algorithms, improving predictive models versus simulations power of stochastic control. When could simulation be a better option?",,
565,https://www.reddit.com/r/datascience/comments/dfoaab/creating_database_and_web_server_to_run_python/,dfoaab,creating_database_and_web_server_to_run_python,pmarct,0.82,7,2019-10-10 00:07:52,0,9,,"I apologize if this is too basic of a question, but I am new to this.  Where I work, we have data stored on multiple sources (e.g. salesforce, podium, MS Dynamics, etc), I've set up code to aggregate and combine this data via python. However, I am now looking to set up a database to store this data and for a way to run my python scripts from the cloud.  Could anyone help direct me to resources that could help me accomplish this.",,"Projects,"
566,https://www.reddit.com/r/datascience/comments/df4lk5/tensorflow_20_is_now_available_in_r/,df4lk5,tensorflow_20_is_now_available_in_r,da_chosen1,0.96,237,2019-10-08 21:08:56,0,66,,,https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/,"Discussion,"
567,https://www.reddit.com/r/datascience/comments/dfk1bz/jupyter_data_analysis/,dfk1bz,jupyter_data_analysis,rrthirumulu,0.67,2,2019-10-09 19:07:05,0,5,,"Hey guys running into memory issues when working with big datasets in Python/Jupyter/pandas. I usually query AWS Redshift using psycopg2 and then process/analyze using pandas. I've also built derived tables in Redshift using a tool called dbt for some purposes, but I'd really like to use one environment to process/analyze/visualize since I usually want to edit some of the metrics if the analysis doesn't provide me with any actionable metrics. I already know about batching datasets but sometimes I'd really like to look at aggregated metrics within the past year or two. What workflow/tools do you guys suggest?",,"Tooling,"
568,https://www.reddit.com/r/datascience/comments/dfnk0h/why_do_do_people_export_a_dataset_from_a_database/,dfnk0h,why_do_do_people_export_a_dataset_from_a_database,rhonda455,0.38,0,2019-10-09 23:16:27,0,19,,"For example say you use a query to take out a data set, then you export it to excel to do statistical analysis such as hypothesis testing. Why can’t you just do a query that will give you the data set AND the hypothesis testing or whatever statistical calculations. Another example is adding tables or rearranging them. You can just use a query for that",,
569,https://www.reddit.com/r/datascience/comments/df8jp1/whats_the_best_way_to_choose_which_features_to/,df8jp1,whats_the_best_way_to_choose_which_features_to,do80,1.0,7,2019-10-09 01:44:26,0,8,,"I've playing around with this Kaggle data set, trying to improve my prediction accuracy. One of the ways I've been doing this is by choosing different features to feed into a model. What I would like to do is try every possible combination of features, but that takes too much time (there are over 30 features, so over 230 different combinations I could choose.I tried doing this anyway, but I can't test much more than 215 combinations on my machine. Regardless, I was able to get decent results. I tried using PCA to get better features to feed into my model, but the results were never as good as with some of the random combinations of raw features I tested. However, I did not spend nearly as much computer time with the PCA method. I just found the principle components choosing different numbers of components (1 - 30). This would take a few seconds to run at most. In the first case I would let my computer run for an hour or more, testing tens of thousands of different combinations of features.I'm hoping there's a better way to choose features for my model. Any suggestions??As a secondary, somewhat related, question... are there best practices for spending computer time when building/ training a model? Should I let my computer spend hours just on feature selection, or are there better ways to use that computer time?",,"Projects,"
570,https://www.reddit.com/r/datascience/comments/df5z5i/anyone_doing_data_sciencemachine_learning_jobs/,df5z5i,anyone_doing_data_sciencemachine_learning_jobs,mclovin215,0.67,8,2019-10-08 22:46:36,0,19,,"I am a few years away from obtaining a statistical modeling/programming-heavy PhD from a good US university. I have been getting away with going on smaller digital nomadic trips for up to 4 months a year, because my PhD adviser who I work under lets me work remotely for the summer/other school breaks. But now I am starting to plan ahead for the long run and am wondering if I can work remotely forever as a data scientist.My goal is to finish my PhD in 2-3 years, work a full-time Data Science job in the US for another year or two to boost my resume, and then stopping the full-time work and indefinitely going into working remotely as a data-scientist providing consultancy services, working on remote contracts etc.Problem is, I don't really know if it's common to do this. I am aware that a lot of programmers do this, and even know a few who are employed in US companies as programmers but just work remotely from Latin America. However, I haven't ever heard from any data scientists/machine learning experts working as digital nomads. It is possible that there are major obstacles to my tentative plan that I haven't even thought of. So it would be great to hear thoughts from someone who knows about this path. Are there any things I should do to prepare, or something else you wish you had known before you started this path? Any advice will be appreciated. Thank you in advance.",https://www.reddit.com/r/cscareerquestions/comments/df5ysw/anyone_doing_data_sciencemachine_learning_jobs/,"Career,"
571,https://www.reddit.com/r/cscareerquestions/comments/df5ysw/anyone_doing_data_sciencemachine_learning_jobs/,df5ysw,anyone_doing_data_sciencemachine_learning_jobs,mclovin215,0.88,12,2019-10-08 22:45:55,0,14,"Tech,","I am a few years away from obtaining a statistical modeling/programming-heavy PhD from a good US university. I have been getting away with going on smaller digital nomadic trips for up to 4 months a year, because my PhD adviser who I work under lets me work remotely for the summer/other school breaks. But now I am starting to plan ahead for the long run and am wondering if I can work remotely forever as a data scientist.My goal is to finish my PhD in 2-3 years, work a full-time Data Science job in the US for another year or two to boost my resume, and then stopping the full-time work and indefinitely going into working remotely as a data-scientist providing consultancy services, working on remote contracts etc.Problem is, I don't really know if it's common to do this. I am aware that a lot of programmers do this, and even know a few who are employed in US companies as programmers but just work remotely from Latin America. However, I haven't ever heard from any data scientists/machine learning experts working as digital nomads. It is possible that there are major obstacles to my tentative plan that I haven't even thought of. So it would be great to hear thoughts from someone who knows about this path. Are there any things I should do to prepare, or something else you wish you had known before you started this path? Any advice will be appreciated. Thank you in advance.",,
572,https://www.reddit.com/r/datascience/comments/deonyl/nate_silver_on_what_makes_a_good_data_scientist/,deonyl,nate_silver_on_what_makes_a_good_data_scientist,Ben___Garrison,0.92,297,2019-10-07 21:49:20,0,54,,,https://twitter.com/NateSilver538/status/1180900333003952128,
573,https://www.reddit.com/r/datascience/comments/df7cqq/text_mining_conversational_data/,df7cqq,text_mining_conversational_data,DS_throwitaway,0.33,0,2019-10-09 00:19:02,0,7,,"Just looking for some input and ideas. I have some data from a call center that is conversational. It's mainly prompts and responses.I've been tasked to analyze some of this call data to help improve the process. One of the biggest issues is that it is speech to text so the quality is already subpar.What I've done so far is aggregate all of the prompt responses into one conversation aggregate. Done some preprocessing, converted to tfisf and then done some topic modeling.Just trying to see if anyone has any other ideas if techniques I could apply. It's pretty open ended I know. Just thought I would hear other ideas.",,
574,https://www.reddit.com/r/datascience/comments/df2yna/how_would_you_interpret_an_increase_in_rocauc_but/,df2yna,how_would_you_interpret_an_increase_in_rocauc_but,rodrigonader,1.0,2,2019-10-08 19:09:54,0,5,,,,"Discussion,"
575,https://www.reddit.com/r/datascience/comments/deqpb6/americas_math_curriculum_doesnt_add_up_or_why/,deqpb6,americas_math_curriculum_doesnt_add_up_or_why,mindtonic,0.7,33,2019-10-08 00:12:38,0,45,,,http://freakonomics.com/podcast/math-curriculum/,
576,https://www.reddit.com/r/datascience/comments/dekbos/state_of_the_art_activation_functions_explained/,dekbos,state_of_the_art_activation_functions_explained,permalip,0.94,101,2019-10-07 16:39:00,0,1,,,https://mlfromscratch.com/activation-functions-explained/,"Discussion,"
577,https://www.reddit.com/r/datascience/comments/df1yqj/how_do_you_daisy_chain_multiple_datasets/,df1yqj,how_do_you_daisy_chain_multiple_datasets,saadmrb,0.25,0,2019-10-08 17:58:41,0,10,,"How do you daisy chain multiple datasets together in a way that aligns with some data you already have to get better results.For example you have one dataset of workout exercises , you have another for VO2, you have another for injuries,age,weight etc...How do you combine these datasets to get something valuable and insightful ?",,"Discussion,"
578,https://www.reddit.com/r/datascience/comments/deqv6n/purchase_data_pulled_from_walmart_receipt_or_app/,deqv6n,purchase_data_pulled_from_walmart_receipt_or_app,Niablis,0.84,4,2019-10-08 00:24:49,0,3,,"Hi, my apologies if this is the wrong place for this type of question.I am trying to quickly pull all the purchase data off of a Walmart receipt. Info such as the item, cost data, total cost of entire sale, etc. I currently try to track all that by manually entering the info by hand but it takes a while and is prone to error. My family is on an intensive debt payoff effort and every little bit helps.Walmart has an app that will scan your receipts but it seems to only export .png pictures of the receipts. Anyone know of a way to download previously mentioned data, and/or another app that pulls the info directly from the receipt?Thanks!",,"Projects,"
579,https://www.reddit.com/r/datascience/comments/dem2dc/new_open_source_database_designed_specifically_to/,dem2dc,new_open_source_database_designed_specifically_to,EverythingIsNail,0.88,12,2019-10-07 18:45:52,0,6,,,https://terminusdb.com/,"Tooling,"
580,https://www.reddit.com/r/datascience/comments/de9scr/ultimate_v10_release_of_yellowbrick_open_source/,de9scr,ultimate_v10_release_of_yellowbrick_open_source,W1zK1dd,0.97,184,2019-10-06 23:34:50,0,9,,,http://www.scikit-yb.org/en/latest/gallery.html,"Projects,"
581,https://www.reddit.com/r/datascience/comments/deiowd/are_there_any_python_libraries_that_help_with/,deiowd,are_there_any_python_libraries_that_help_with,Zenith_N,0.84,8,2019-10-07 14:22:56,0,23,,Are there any python libraries or examples on how to conduct a multivariate time series analysis ?,,"Discussion,"
582,https://www.reddit.com/r/datascience/comments/deumbm/what_metric_to_use_for_probability_prediction/,deumbm,what_metric_to_use_for_probability_prediction,rodrigonader,0.38,0,2019-10-08 05:40:05,0,14,,"The output/target is binary, but the model predicts probabilities. What metric to use for model comparison and why?!",,"Discussion,"
583,https://www.reddit.com/r/datascience/comments/dejsfh/question_about_limits_of_tableau_vs_pythonr/,dejsfh,question_about_limits_of_tableau_vs_pythonr,shlotchky,1.0,5,2019-10-07 15:57:23,0,15,,"Background about me: I recently started corporate job where a lot of people use Tableau for building dashboards and visualization of data. All of my previous data experience is entirely in R, and I am rapidly learning python. Things I am used to doing include basic dataframe manipulation, linear regression building, principal component analysis, mixed linear models and effect matrices, ggplot2 visualization, and some basic implementation of decision tree ML models.I have a meeting with some of my superiors and IT people today where we will be discussing software they want me to use. Having never used Tableau, I am not too sure what all of its capabilities are. Frankly, I would prefer to just R and Python for everything, but I think they will need some persuasion as to why they should let me stick with the tools I'm comfortable with and where exactly Tableau falls short of Python/R.Tasks that I will be doing in my job will be automating data reports, building dashboards, modeling, visualization, and exploratory data analytics.Any input to help me understand the world of tableau would be appreciated.",,
584,https://www.reddit.com/r/datascience/comments/de9fsa/career_growth_within_data_science/,de9fsa,career_growth_within_data_science,jbern5,0.89,60,2019-10-06 23:08:36,0,11,,"I am new to data science, coming from a software engineering perspective and I was wondering what some of the career growth/progressions within DS are? For example at a place like google, you can move from SWE II to SWE III to Senior Engineer etc. Additionally, are there any benefits/requirements for higher degrees that exist for progressing? Any input would greatly be appreciated since I don’t have much insight currently into the field, thank you",,
585,https://www.reddit.com/r/datascience/comments/de6f11/how_do_you_read_large_numbers_of_academic_papers/,de6f11,how_do_you_read_large_numbers_of_academic_papers,mystikaldanger,0.82,22,2019-10-06 19:35:40,0,13,,"When going on a Google Scholar binge, it's really easy for me to click the link to the citing articles of the paper I'm reading, then want to see the citing papers of those articles, and so on.What initially looked like a small field of knowledge that would take an afternoon to get caught up on is revealed to be an unfathomable ocean that requires a lifetime of study to make any dent in. I very quickly become overwhelmed,  and anxiety/panic starts to set in.Is there any way to cope with this feeling when doing research? I suspect a lot of it is due to my ADD and desire to Learn Everything.",https://www.reddit.com/r/MachineLearning/comments/de5wam/d_how_do_you_read_large_numbers_of_academic/,"Discussion,"
586,https://www.reddit.com/r/MachineLearning/comments/de5wam/d_how_do_you_read_large_numbers_of_academic/,de5wam,d_how_do_you_read_large_numbers_of_academic,mystikaldanger,0.97,494,2019-10-06 18:57:42,0,127,"Tech,","When going on a Google Scholar binge, it's really easy for me to click the link to the citing articles of the paper I'm reading, then want to see the citing papers of those articles, and so on.What initially looked like a small field of knowledge that would take an afternoon to get caught up on is revealed to be an unfathomable ocean that requires a lifetime of study to make any dent in. I very quickly become overwhelmed,  and anxiety/panic starts to set in.Is there any way to cope with this feeling when doing research? I suspect a lot of it is due to my ADD and desire to Learn Everything.",,"Discussion,"
587,https://www.reddit.com/r/datascience/comments/ddy9d2/how_business_intelligence_is_different_from_data/,ddy9d2,how_business_intelligence_is_different_from_data,weihong95,0.89,136,2019-10-06 05:56:14,0,57,,"""Is Business Intelligence really different from data science? Both are using data to solve the problem or create value. Isn't that the same?""This is one of the questions often asked by people around me and I would like to share my own perspective through the experience I have had.Most importantly, if you are still an undergraduate, or just graduated, or still considering to switch your job career to business intelligence, read this article before making your final decision.Comment below on how you think data science is different from business intelligence!Link: https://towardsdatascience.com/how-business-intelligence-is-different-from-data-science-f1673456b80c?source=friends_link&sk=e6d19d387c23649f2df8074ad97752f5",,"Career,"
588,https://www.reddit.com/r/datascience/comments/de53ao/weekly_entering_transitioning_thread_06_oct_2019/,de53ao,weekly_entering_transitioning_thread_06_oct_2019,datascience-bot,0.91,9,2019-10-06 17:59:01,0,121,,"Bleep Bloop. Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki. You can also search for past weekly threads.",,"Discussion,"
589,https://www.reddit.com/r/datascience/comments/ddu9gh/how_to_feature_engineer_a_categorical_nonordinal/,ddu9gh,how_to_feature_engineer_a_categorical_nonordinal,str8cokane,0.88,13,2019-10-06 00:20:04,0,23,,"I'm working on a data set that is decently large, >2 million rows. One of the features is a serial number for a product (so probably decently important). Usually, I would OneHotEncode them, but this isn't really possible because having 5000 columns would break my model. Any suggestions for how you would deal with this? Thanks.Edit: Some clarification. This is a pretty massive dataset, with over two million rows. I have two variables of concern. One is the ad campaign, of which there are 5704 unique values. The other is the product number of the game being played when the advertisement launches, which has >29k unique features. When predicting clicking on an ad in a mobile game, I think both are probably too important to drop. The other thing is, I'm aware that it isn't realistic or super intelligent to have these as features, but this is a take home technical interview, so it's part of the challenge to make due. Thanks again everyone for your thoughtful answers.",,"Projects,"
590,https://www.reddit.com/r/datascience/comments/ddwyxd/visual_data_layout_automatically_reposition_nodes/,ddwyxd,visual_data_layout_automatically_reposition_nodes,sentinel1x,1.0,4,2019-10-06 03:54:25,0,2,,"My question pertains to data visualization. Is there a name for the kind of layout where all the nodes are automatically repositioned every time a new connection is made, so that the overall presentation remains “uniform”, with relatively low variability in the distance between nodes and intuitive appearance of all the connections? The closest thing I’m finding is an “organic” layout but it doesn’t seem to be the same as what I’m referring to.",,
591,https://www.reddit.com/r/datascience/comments/ddygdu/any_nashville_tennessee_data_scientists/,ddygdu,any_nashville_tennessee_data_scientists,EOHFA,0.5,0,2019-10-06 06:14:46,0,4,,"My school is hosting a Data Science Lunch-n-learn to raise awareness to Data Science. It will be help on October 29. I am trying to find Data Scientists in Nashville who are interested If interested, more information about the program will be provided. Thanks!",,
592,https://www.reddit.com/r/datascience/comments/ddt7ez/do_i_need_to_improve_my_python_visualization/,ddt7ez,do_i_need_to_improve_my_python_visualization,19Summer,0.6,1,2019-10-05 22:56:57,0,11,,"Hi, everyone.Just a little background information.I am finishing my MSc Data Science program in May and I have started thinking about future.So the question is how much visualization is done in Python in real-world and how much in software like Tableu?I  am asking because I am pretty bad at Matplotlib and Seaborn (I mean I  can only create simple graphs, nothing complex and sophisticated) and  want to understand should I focus much on it? (I will focus on improving  it anyway, just need to udnerstand how intense I have to practice this  skill).Thanks for your answers!",,"Education,"
593,https://www.reddit.com/r/datascience/comments/ddaa3b/disillusioned_need_career_guidance/,ddaa3b,disillusioned_need_career_guidance,monkeyunited,0.9,71,2019-10-04 19:11:09,0,19,,"TL;DR: go back to old team and work on interesting things but remain a data analyst, or stay at new data science team, working on CNN, NLP but work is boring and CS-heavy in nature?Due to re-org, I (data analyst) was pulled into our data science team. This should be a dream come true, considering I'm doing a part-time master to break into the field, but I felt disillusioned?The team works on prediction problems from image or text using CNN and NLP. As cool as it sounds, it's almost too...cookie-cutter? We literally look at the problem, find a research paper that addresses the problem, and implement the code. Time was spent on writing the pre-processing code and dealing with processing speed issues (set up cloud, now code needs to work on cloud, ...etc). There's not a lot of thinking going on, if at all.That said, it's everything a data scientist-wannabe can dream of? My ear should get an orgasm hearing ""using Python to build pipeline and run spark and train a CNN and NLP to predict x on a cloud platform"". If I stick it through, CNN and NLP should also make me very in-demand for the next 5-10 years?In comparison, my previous position was a research consulting role, where my manager would ask questions and I'll have to answer it with or without the existence of data. Most time was spent thinking about the problem, making careful assumptions, and draw conclusions using limited amount of information. Lots of thinking and exchanging ideas was involved in a project.An example project was mapping consumers geographically and try to categorize them (apply median HH-income, median house value, proximity to high-end shopping mall...etc.). I'll never get it exactly right, but throughout the process we learn a lot about our consumers.It sort of dawn upon me that I went for a master so I can answer more complex questions. Although not necessarily using machine learning, my old team was answering questions that are way more interesting. That said, I'm not sure if it's just because I don't have the CS chop yet and when I do, work will become more interesting? Will it?Not sure what I need to make up my mind, just seeking general comment I guess.",,"Career,"
594,https://www.reddit.com/r/datascience/comments/ddiu3v/best_data_science_business_intelligence/,ddiu3v,best_data_science_business_intelligence,hankbennie,0.67,4,2019-10-05 07:01:32,0,7,,"In my work I analyze and apply algorithms to specific types of data sets for customers. Right now we just send our customers reports in bundles of files.I’m trying to figure out a way to build out a web-application without having to start from scratch.  Do you guys know a good framework to build and deploy a secure web app where you can show your visualizations (from graphs to tables), filters, and such? The web app would also need features that handle users, like timed-logouts, dual factor authentication, user specific data access rules, and the like.   It would also be great if it did things like handle URLs, set up custom pages, pop ups, etc.  Think wordpress but built to securely access and visualize databases in the cloud.I know I could start from scratch and build something on Flask or Django but I feel like the application I want to build must have been built many times over, just with different data, and there could be a product out there that solves thisHave any of y’all run into this problem? How have you solved it? Did you have to do a build out from scratch, did you take a combination approach (I.e. Django + Power BI)?",,"Discussion,"
595,https://www.reddit.com/r/datascience/comments/dd8jzs/how_do_you_choose_the_correct_approach_for_a/,dd8jzs,how_do_you_choose_the_correct_approach_for_a,Estiui,0.9,45,2019-10-04 17:02:54,0,32,,"Let's say I have a pretty simple problem. I have some input data (for instance, a-b-c-d possible answers to a 10 question test). I have some labels (for instance, if someone has passed the test or not).Provided that I don't know anything else about the problem (I don't know how much each question is worth, so I don't know the exact criteria to know if someone will pass the test), how would you try to predict the outcome of the test given a set of answers?The first thing that comes to mind is do a classifier. But the questions arise:How do I know which of them to choose?How would I know which of them would perform better?How would I find out which of the questions is more important to determine the outcome of the test?I have some experience with data science, but always find it hard to narrow the possibilities to try the solve the problem.EDIT: seems that my example sounds weird, so let's try with a similar one instead. Imagine that you have your customers filling that same test about their profile (age, gender, city, income, whatever...) and purchasing (or not) your products, so you'd want to relate their answers to the test to the likelihood of buying a product. Then, you'd want to know which are the most important questions/answers to determine whether the customer will buy your products, and you'd like to predict if your customers will buy or not your product depending on their set of answers.",,"Discussion,"
596,https://www.reddit.com/r/datascience/comments/ddagte/how_to_methodically_create_cohorts_for_an_ab_test/,ddagte,how_to_methodically_create_cohorts_for_an_ab_test,madzthakz,0.67,2,2019-10-04 19:24:40,0,9,,"I'm sorry if this is trivial but I'm very new to the A/B world so I'm not sure what to do and why.Question:- How should I design cohort sizes to establish statistically significant results from our A/B test?- NOTE: We will be sending out a survey so we'd want to make sure we are getting significant results for each question.Some things I'd be interested in:What methods are used to evaluate N size for each cohortsAm I right to assume that a 2 Sample T Test would be needed to evaluate statistical significance for each question?Any help would be much appreciated.[EDIT]: To provide more details, I am including a new recommendation system on our platform. Our A/B test will include two sets of recommendations and our survey will ask the following questions:Did these recommendations reflect your purchasing habits? (1-5)Would you buy any of the recommended items? (1-5)Were the ""Because you bought"" sliders useful? (1-5)",,"Discussion,"
597,https://www.reddit.com/r/datascience/comments/dcsp7r/make_openreview_awesome_chrome_extension/,dcsp7r,make_openreview_awesome_chrome_extension,misunderstoodpoetry,0.89,66,2019-10-03 17:46:34,0,2,,"I got frustrated with scrolling around on OpenReview papers to figure out the scores from each review, and how they influenced the overall decision. I wrote a Chrome Extension that adds a dashboard to OpenReview paper descriptions that makes it easier to see and overview of the reviews. Let me know what you think!Link to OpenReview Plus: https://chrome.google.com/webstore/detail/open-review-plus/lmenhbnkjklbeppieogagoajlmgnhdac",,"Tooling,"
598,https://www.reddit.com/r/datascience/comments/dcwzq0/geodata_and_filtering_need_tips/,dcwzq0,geodata_and_filtering_need_tips,xOrbitz,0.86,14,2019-10-03 22:50:54,0,7,,"Hey guys, I'm trying to to mess around with geodata for the first time and I'm trying to solve a filtering task.I have a dataset containing thousands of coordinates (latitude, longitude), and I need to filter the coordinates that are outside streets, for example coordinates that lands on parks, buildings, rivers, etc.After the filtering process, I need to stay only with the coordinates that are on the street.Any tips on how to do that? I'm using OSM data to extract what each coordinate represents, but I'm not sure whether this is the best approach.",,"Projects,"
599,https://www.reddit.com/r/datascience/comments/dcocw0/what_kpimetrics_are_being_used_to_evaluate_a_data/,dcocw0,what_kpimetrics_are_being_used_to_evaluate_a_data,AmbitiousPrompt,0.89,61,2019-10-03 11:13:17,0,28,,"IMO, a good amount of a data scientist work is basically exploration/research, which makes it hard to objectively measure success in one's work.",,"Career,"
600,https://www.reddit.com/r/datascience/comments/dcrqde/your_favourite_data_driven_stories/,dcrqde,your_favourite_data_driven_stories,amlwwalker,0.87,23,2019-10-03 16:34:13,0,11,,"I have recently found myself enthralled by the stories that data science unravels. My favourite so far is the story of Association Rules unravelling the association that was discovered between the purchase of beers and diapers. I'm on the hunt for more, similarly interesting and accessible stories for different data science (ML) techniques. Clustering/linear & logistic regression/naive Bayes/classification & decision trees/time series (not exhaustive list). I would love to hear or read any cool examples where methods such as these have unraveled truths, otherwise hidden. Nothing too complex, I like to tell these stories, so hardcore BioMedical findings probably won't cut it but I'm sure this community has some awesome ones. Sorry for waffling!! Thanks!!",,"Discussion,"
601,https://www.reddit.com/r/datascience/comments/dctdm2/whats_your_process_to_explore_new_business_data/,dctdm2,whats_your_process_to_explore_new_business_data,DiogenicOrder,0.88,6,2019-10-03 18:35:36,0,4,,"Hi all,So I'm starting a new project where I have to explore the data first ofc. After discussing with the people who created and dealt with the data, I'm left to analyse it.The thing is, there are many variables (around 200) which are boolean, continuous, discrete,... And I'm not sure where to start yet aside from asking the business people where they'd look first.So I guess my question is the following : what's your systematic and reproducible way to explore the data, classify the relevant and less relevant ones,..Thanks",,
602,https://www.reddit.com/r/datascience/comments/dcthqb/i_feel_like_many_bootcamps_career_coaches_are/,dcthqb,i_feel_like_many_bootcamps_career_coaches_are,[deleted],0.63,2,2019-10-03 18:44:12,0,37,,"Just wondering, realistically what is / was your time frame for you to get a job after your data science degree, bootcamp, etc? Just asking this because I have many friends in the same boat as me. Pretty good degree, past internship experience, yet still taking months and months with tons of rejections, to find one data science job, if at all (many of them took analyst positions).There's definitely less consolidated resources for getting data science positions, than there is for software engineering (almost all software candidates have to do whiteboarding, and therefore practice Leetcode). There's no 'Leetcode' for data science. The process is a definite struggle and if often times feels like you're going at it alone.",,
603,https://www.reddit.com/r/datascience/comments/dczkpg/what_the_heck_is_cloud_computing/,dczkpg,what_the_heck_is_cloud_computing,KanyeWest_AlterEgo,0.43,0,2019-10-04 02:07:22,0,16,,"Hey guys,I'm a junior data analyst that is a budding data scientist.  I'm completely self-taught and my 12-inch Macbook isn't really cutting it for me anymore. Both the screen size and the m5 processor are too slow. I was thinking about buying a good Chromebook and then installing Linux and learn by cloud computing. I believe I saw a wqay I can have notebooks in the cloud? How do I go about this, is it a viable plan, and how much would this cost, are there any free versions?",,"Tooling,"
604,https://www.reddit.com/r/datascience/comments/dcpjel/how_can_i_improve_my_vision_to_offer_ideas_for/,dcpjel,how_can_i_improve_my_vision_to_offer_ideas_for,ntlslayer95,1.0,4,2019-10-03 13:27:39,0,3,,I’m building out my companies first data science team but no one seems to know what they want or what to ask for. I want to be able to go to them with ideas for projects which could add more value to the company. How can identify these opportunities outside of just more experience and exposure to other projects?,,"Discussion,"
605,https://www.reddit.com/r/datascience/comments/dcavur/warning_data_analytics_bootcamp_with_trilogy_and/,dcavur,warning_data_analytics_bootcamp_with_trilogy_and,SmellsLikePneumonia,0.96,132,2019-10-02 16:22:52,0,37,,"My experience at The University of Denver has been that we have had 5 teachers in FOUR months of classes. Each one has quit or ‘moved classes.’ Trilogy has maintained that these ‘adjustments’ allow for us to get a broader teaching style...When you are learning and have a new teacher rotating basically every session, they have no idea what the instructor before them has delved into and what style they are teaching from.A few of the teachers would literally stand up with the physically printed solved code and just read from the code while typing it back into their computer. With one teacher, the code wouldn’t work and he basically said ‘You get the jist, but we have to move on for time’s sake...’Since we are so behind in the curriculum, they have added in Friday night sessions (on top of our 3 other days a week). I understand that I am making an investment in my future, but some balance is needed in life. We still have homework and group projects outside of class. I would say that 80% of us also have full-time jobs.When we spoke to the administrator about how difficult the situation was, they basically said ‘it has been really hard on us, too, with all of the changes.’ YOU AREN’T PAYING TO LEARN... you are BEING PAID to do your job. Sorry if you feel inconvenienced.ALL of the material is available online through users Github’s (readme’s and starter code included) and has not been changed in YEARS (2016).It is non-accredited program and uses the partner school’s name for accolades to their company.In my book, the one at DU has been a ripoff and a joke. If I can save one person $10k with the post, I’ll feel some justice.",,"Education,"
606,https://www.reddit.com/r/datascience/comments/dcptzq/sentiment_analysis_training_the_algo/,dcptzq,sentiment_analysis_training_the_algo,sotities,0.75,2,2019-10-03 13:56:32,0,6,,"To elaborate, I have used an API to get some twitter data (test data) but in order to train my model  I am using the Sentiment140 training data. This is a complete novice question, I know, but I am confused since on the one hand since both are twitter data it seems possible, on the other most blog posts etc use training and test of the same source (e.g. https://medium.com/@vasista/sentiment-analysis-using-svm-338d418e3ff1).Thanks in advance all! (Positive sentiment ^^)If this is not clear, I don't want to self-annotate my own dataset, thus I thought I could use an annotated training set from another twitter project.",,"Projects,"
607,https://www.reddit.com/r/datascience/comments/dco558/are_the_skills_used_in_data_science_turned_over/,dco558,are_the_skills_used_in_data_science_turned_over,LetsEndSuffering,0.6,2,2019-10-03 10:46:45,0,7,,,,"Career,"
608,https://www.reddit.com/r/datascience/comments/dcno6r/fuzzy_matching_multiple_data_points_to_find/,dcno6r,fuzzy_matching_multiple_data_points_to_find,AidAgency,0.86,5,2019-10-03 09:45:36,0,10,,"I work for large cash transfer programme in Somalia, funded by the European Union. Instead of giving people food, or paying school fees we give people electronic money to their mobile phones. They know far better what they need than we do.In Somalia, there's no ID system so when we register people for a year-long programme we take their names, phone numbers etc. But there's no way for us to definitively determine if someone has registered twice.Somali names are long (4 names) and spelt more on judgment than convention, so names aren't consistent. Plus, people often have more than one phone number.We've tried using fingerprint biometrics, but it was slow, expensive, inaccurate and we're not happy with the data protection risks (certainly the benefits don't outweigh them).We want to start using fuzzy matching over multiple data points to determine duplicates. Once we have a shortlist, we can use the photos to make a fairly accurate judgement. We have around 75,000 people's records.So, what are people's thoughts?How do we do this? Off the shelf package? Consultancy? Researcher?Any general hints on approach?Could machine learning be used?I'm happy to provide more details but obviously cannot share the data set!",,
609,https://www.reddit.com/r/datascience/comments/dcimd6/taking_pricing_tests_to_determine_a_continuous/,dcimd6,taking_pricing_tests_to_determine_a_continuous,Xamius,1.0,13,2019-10-03 01:36:33,0,4,,"Background: I run pricing tests as part of my job.  Ie for a particular product, a customer might see a price of 10, 15 or 20. I want to take the results of those tests to determine what price between 10 and 20 i should offer new customers.I should mention, we have several use cases to develop models that determine  which of those 3 prices we would offer a new customer, but i want to expand that to build a continuous pricing model instead of a model to predict 10, 15 or 20.Any ideas?",,
610,https://www.reddit.com/r/datascience/comments/dc4sh0/this_subreddit_has_lost_its_value/,dc4sh0,this_subreddit_has_lost_its_value,nouseforaname888,0.89,446,2019-10-02 05:33:22,0,135,,"Most the questions on here are how do I break into data science. The answers to most these questions are generic bullshit.Or it is questions like what are your future plans? Those also get lousy stupid answers.If you pose any questions on actual data science topics eg topic modeling or lasso/ridge regression or random forests, you don’t get much useful information most the time sadly.You get some snarky jerk who says we aren’t here to do your homework.Or even if it is a simple question you get answers like this post below https://www.reddit.com/r/datascience/comments/dc0idf/can_we_combine_multiple_datasets/?utm_source=share&utm_medium=ios_app&utm_name=iossmfIf you wanna learn data science, go to a different subreddit- Eg learndatascience or machinelearning",,"Can we impute it?,"
611,https://www.reddit.com/r/datascience/comments/dcq915/has_anyone_successfully_created_their_own/,dcq915,has_anyone_successfully_created_their_own,flyyoufools97,0.5,0,2019-10-03 14:33:59,0,9,,"I created a program in school that worked to instantly trade currencies, using the millisecond time periods for you to exchange your currency to another currency so that you'd end up with more in the end.   I think it was called financial arbitrage for currencies or something.My program wasn't using real time data and I only downloaded one instance of it just to see how it worked, but has anyone actually successfully created this?",,"Discussion,"
612,https://www.reddit.com/r/datascience/comments/dcefeq/as_a_data_scientist_how_do_you_deal_with_non/,dcefeq,as_a_data_scientist_how_do_you_deal_with_non,iKidA,0.75,4,2019-10-02 20:41:40,0,6,,How do you convince them about the value your model or analysis might bring? All they care about reporting metrics on a dashboard.,,
613,https://www.reddit.com/r/datascience/comments/dcil1c/help_getting_dataset_imported_via_into_tidy_data/,dcil1c,help_getting_dataset_imported_via_into_tidy_data,RareIncrease,0.5,0,2019-10-03 01:33:36,0,2,,"https://imgur.com/a/JAIgfkSHere's a pic of how the data table looks after importing into python/pandas from a PDF.   I'm basically trying to get all the variables on the row side (market, letter) to a column while keeping the data it describes intact since I'm importing from a pdf. I have no idea how with this structure.For example, I need a column labeled as ""Market"", a column as ""Letter"" so Market 1 will have a data point for each letter for each quarter.  Again, since it's PDF and all the data is there I need to keep it in tact if that makes sense.  I'm not sure how to do this using .melt or .pivot. somehow I need to swing the variables to columns and observations rows and I'm lost at how to do it with this format. Any python data science experts care to weigh in? :).Ignore the summary garbage, I'm deleting it.",,
614,https://www.reddit.com/r/datascience/comments/dc8bx4/wikis_for_publishing_scholarly_articles_on/,dc8bx4,wikis_for_publishing_scholarly_articles_on,openjscience,1.0,11,2019-10-02 12:28:40,0,0,,,https://jwork.org/home/node/68,"Projects,"
615,https://www.reddit.com/r/datascience/comments/dc4nas/youtuber_charged_loads_of_fans_199_for_shoddy/,dc4nas,youtuber_charged_loads_of_fans_199_for_shoddy,newplayer12345,0.87,38,2019-10-02 05:20:13,0,38,,,https://www.theregister.co.uk/2019/09/27/youtube_ai_star/,
616,https://www.reddit.com/r/datascience/comments/dbs1yk/fable_010_tidy_timeseries_forecasting_major/,dbs1yk,fable_010_tidy_timeseries_forecasting_major,GoodAboutHood,0.98,151,2019-10-01 13:34:20,0,10,,,http://fable.tidyverts.org,"Tooling,"
617,https://www.reddit.com/r/datascience/comments/dc10m6/unclear_about_the_advantages_and_whenwhy_to_use/,dc10m6,unclear_about_the_advantages_and_whenwhy_to_use,shankfiddle,0.62,6,2019-10-02 00:28:06,0,34,,"Went to an AWS Sagemaker intro training today.  I have heard of these notebooks many times in the past, and I'm struggling to understand what advantage they provide?Like the python interactive interpreter, you can go line-by-line... but why not just work in code where you can much more easily define classes, functions, etc?  I don't even IDE lol, I just text edit .py files usually and execute from a CMD prompt or bash if on UNIX server.Notebook hosting seems to me like a nice gui but the overhead doesn't seem to add any value.Is there something I'm missing?  Are there some strengths in certain scenarios that I'm not aware of?Note: I am learning data science (but say a 7/10 coder); by no means an expert in anything.  My mind is open and ready to absorb new learnings from this community!",,
618,https://www.reddit.com/r/datascience/comments/dbw270/people_in_the_industry_with_only_a_bachelors_what/,dbw270,people_in_the_industry_with_only_a_bachelors_what,hawyeet,0.85,20,2019-10-01 18:42:03,0,29,,"To be clear: I'm curious how people who already have a data scientist job title but only have a bachelor's envision their future career trajectory.Some questions -Are you planning on getting a masters?Why or why not?Are you still on your first DS role?Was getting interviews difficult without a masters?Do you want to stay in this field long term?I'd be interested to hear more about your experiences in general, though.I ask cus I'm in this situation and can't envision myself leaving work to get an MS unless it was to pivot away from data science. As someone that isn't hugely passionate about data science (I enjoy it -- I enjoy many other things as well), it doesn't fit my personal goals at the moment to walk away from $ to get an MS. I know that'll mean many researcher type roles (and lower level DS roles as well) will remain forever out of reach, but I know I can still make a nice salary without them. I get fewer interviews for roles I'm technically qualified for than a colleague that has a masters, though, and I do feel nervous when interacting with the many people that have PhDs in this industry.Kinda curious what other people's takes are.",,
619,https://www.reddit.com/r/datascience/comments/dbzbbn/advice_on_mentoring_high_school_students/,dbzbbn,advice_on_mentoring_high_school_students,pieIX,0.67,3,2019-10-01 22:29:48,0,5,,"My company partners with an underprivileged high school's work-study program. I volunteered to mentor one student, but I'm realizing that the gap between my daily work and a student with no programming experience is quite large.We have set up our student to label datasets for our models, but it's pretty monotonous work. Ideally, I'd like my student to have some work that might attract them to the field down the road.Any recommendations for working with high school students? Is it reasonable to set them up to learn Python? SQL? What kind of expectations should I have?",,"Discussion,"
620,https://www.reddit.com/r/datascience/comments/dc2eds/presenting_a_written_analysis_for_two_types_of/,dc2eds,presenting_a_written_analysis_for_two_types_of,ThisIsSimon,0.75,2,2019-10-02 02:12:05,0,4,,"For an interview I was ask to do a take home case study. I was asked to present my analysis in a format where it is suitable for a technical individual to verify my work and for a non-technical upper management individual to understand the answers to their questions.They prefer the analysis to be done in SQL and then have you use an external tool to display any graphs, but they're open to Python and R.I decided to present my analysis in a Jupyter notebook, because it allows an easy way for me to display graphs to answer some of their questions (explaining and showing a trend for example) and keep my work organized.Once I'm finished I'll hide the cells that have code blocks, that way if a technical individual wants to verify my work, they can open the cell to do so. While by default, my notebook will only show my explanation of my analysis and along with any visuals. Since they did have a preference for some SQL, I'll include likely include a query on how I would've aggregated the data using SQL somewhere.Does anyone have any opinions on presenting data to two different types of audiences? Just to be clear, I will be sending this purely over email for them to review and NOT be presenting it in person.",,
621,https://www.reddit.com/r/datascience/comments/dbjspn/announcing_tidyusda_a_package_for_working_with/,dbjspn,announcing_tidyusda_a_package_for_working_with,Beavertrapper07,0.97,104,2019-10-01 00:52:47,0,9,,"After a lot of hard work, tidyUSDA is now on CRAN. Excited to share this with the community.https://technistema.com/post/announcing-tidyusda-a-package-for-working-with-usda-data/",,"Tooling,"
622,https://www.reddit.com/r/datascience/comments/dbrtw0/data_science_manager_knowledge/,dbrtw0,data_science_manager_knowledge,Bardy_Bard,0.9,8,2019-10-01 13:12:28,0,11,,"Hi all,I am just curious to know what do you think are the essential topics a data science team's Manager should know. By knowing I am not saying they should be proficient in using them, just understanding what something is and potential applications.I recently switched jobs( a few months) and the current analytics manager used to be a business controller (That's ok). Apparently he used to be a data scientist/analyst,  but what I find puzzling is that he doesn't know anything about... well whatever is going on in data science.He doesn't know anything about python, sparks, MLflow, AWS .Barely knows anything about any kind of models, he knows neural nets exist and are useless, he might understand be able to compare a random forest with logistic regression...maybe.I am fine explaining things to non-technical people on non-technical terms, but I believe I need to be able to talk to my manager about my tech needs and what resources I need in order to do my job.Is such a person even qualified to lead a team of data scientists? Should I just look for another job at this point? Everyday it gets more frustrating.Needless to add he doesn't even seem interested in the subject at all, I feel like he is there to collect a paycheck.EDIT:I think as people have said I need to give more context, and probably it was just a venting post due to my accumulated frustration.A little bit of context: we are a medium sized company building up our data infrastructure and trying to move to predictive analytics from what has been historically mostly descriptive work on our customer behavior.Communication example goes like this (Note that I am a junior so I am expecting to develop my skill set) :I am having trouble with training a model (time wise) and I notice my code is running on a single core. I ask them if they ever encountered the same problem before and if so what solution was implemented. -> Never happened. Asks me what am I using and I say sklearn. Doesn't know what that is and I explain it's a ML library for Python.Or for example we talk on how we should do analysis. I propose we automate at least part of the data cleaning/diagnostics and build a library for special statistical tests that we have to do. Basically met with empty fish gaze. Um.. so that requires a lot of time you don't have, uh?Tbf I cannot think of many examples, maybe the problem is the lack of communication at all but I do not know where to start.",,"Career,"
623,https://www.reddit.com/r/datascience/comments/dbvphq/extract_data_from_apples_screen_time/,dbvphq,extract_data_from_apples_screen_time,19Summer,0.67,3,2019-10-01 18:17:17,0,3,,"Hi,everyone. I have a data visualisation class at my uni and a tutor asked us to gather some type of quantified self data (it can be randomly generated, the validity of data is not important) and to try to think what visualisations can be done. I want to use my real data from “screen time” as I believe I can fain some insights about myself while visualising it but the problem - I do not know how to extract it.May be some of you know how to get it done.Thanks in advance.",,"Tooling,"
624,https://www.reddit.com/r/datascience/comments/dbpsgw/automating_git_in_a_jupyter_notebook/,dbpsgw,automating_git_in_a_jupyter_notebook,one_game_will,0.88,6,2019-10-01 09:27:13,0,11,,"When I'm prototyping code in a notebook I tend to iterate quickly, and often make 'WIP' commits. I switch out to the console to use git, but it occurred to me I could automate WIP commits in a cell at the top of my notebook.Are there any obvious downsides to this I might be missing?",,"Discussion,"
625,https://www.reddit.com/r/datascience/comments/dbwuqu/jupyter_notebook_or_eda_examples_with_latlong_data/,dbwuqu,jupyter_notebook_or_eda_examples_with_latlong_data,SVintern97,1.0,1,2019-10-01 19:43:28,0,5,,"I'm stuck at doing my EDA at the moment, and I'm not sure how to pick at it. It's a huge data set (1mil+ rows, 100+ columns) and I am losing my mind staring at it. It would be extremely helpful to find something to give me inspiration on what questions to ask myself wit this data.My data mostly consists of lat / long points, dates, time, and device ID. The rest is a bit more granular.",,
626,https://www.reddit.com/r/datascience/comments/dbqy4u/ab_test_where_switch_groups_after_an_amount_of/,dbqy4u,ab_test_where_switch_groups_after_an_amount_of,balocha,0.64,3,2019-10-01 11:41:45,0,9,,"Is there a name for an AB rest where let’s say after a week of group A being exposed to experiment, we move them to Control group and viceversa? Setting for this is to measure impact of a tool in productivity with a small sample size.  We want to AB test but remove bias from having skewed groups.  Could theoretically do blocking but we don’t have too much data on the users.  Is this valid? Would appreciate any resources.  Thanks!!",,"Education,"
627,https://www.reddit.com/r/datascience/comments/dbdw7p/to_impute_or_not_to_impute/,dbdw7p,to_impute_or_not_to_impute,mordwand,0.95,72,2019-09-30 18:13:51,0,41,,"I've recently started as a data scientist after years in grad school. My mentor at my current company has a very strong view on missing data imputation, and advises avoiding it at all costs (he has a Wall Street background). But virtually every source, tutorial, etc includes some form of imputation as part of the workflow.I was wondering:what is  r/datascience's view on missing data imputation? I.e when it is acceptable, best practices, and what your personal experience has been.Thanks!",,"Discussion,"
628,https://www.reddit.com/r/datascience/comments/dbuqcn/womens_summit_in_nyc/,dbuqcn,womens_summit_in_nyc,dinardo,0.57,1,2019-10-01 17:08:35,0,0,,"https://news.efinancialcareers.com/uk-en/3002255/women-into-quant-finance-jobs/The current roster of summit sponsors includes Citadel, Point72, Marshall Wace and Ernst & Young. The intention is to steer women towards data science jobs in the sponsor companies. 75 places on the summit are available and despite the dearth of female quants, competition for places is already fierce: 750 women had applied by last Thursday and more are likely before the deadline of midnight EST on October 3rd.Applicants can be students or experienced female quants. They will need to take a 'foundational skills assessment' examining their ability to interpret charts and tables, to answer basic probability questions, and to respond to information processing and analysis questions. Places will go to female candidates who score highest on the assessment and who are looking for employment. Successful candidates will get to attend the summit and meet employers. They'll also get a mentor throughout the two week period and there's a 90% chance your mentor will be female. ",,"Education,"
629,https://www.reddit.com/r/datascience/comments/dbuenr/how_do_inhouse_data_teams_react_to_their_company/,dbuenr,how_do_inhouse_data_teams_react_to_their_company,SpecificTwo,0.5,0,2019-10-01 16:45:22,0,2,,"From what I gather, Kaggle challenges represent significantly dumbed down versions of what a given company’s data teams are working on.So how do these challenges play within the company itself? Is there a lot of eye-rolling about being pulled off real work to set this up coz some guy in marketing though it would be a great idea?Or is it a feeling that the company is basically saying “Yo, our data guys couldn’t solve this problem, maybe you guys can.”Or do most of the in-house team not even know there’s a Kaggle comp happening?I’d also be interested if any of the winning algorithms are ever implemented, and if so, what that process looks like.",,
630,https://www.reddit.com/r/datascience/comments/dbi4k0/gaining_marketable_skills_as_a_data_scientist_in/,dbi4k0,gaining_marketable_skills_as_a_data_scientist_in,RosmarysBabyBjorn,0.89,13,2019-09-30 22:54:47,0,6,,"I'm a data scientist in a large state government agency, and I really enjoy it. I like the pace, work life balance, freedom, and job security. I'm not working with state-of-the-art technologies, but that's okay with me: I was never going to become a world class data scientist working at the bleeding edge of the field. I have no plans to leave this job, but I also don't want to become trapped in it. I know that it's important to be able to tell a story about what I learned if I apply for a new job in 2, 5, 10 years. So for those of you who worked in government... what skills did you pick up that helped you become a better data professional? Are there technical or non-technical skill areas in which the public sector is superior to the private sector?",,"Career,"
631,https://www.reddit.com/r/datascience/comments/dbdnk7/my_semester_project_lidar_based_obstacle/,dbdnk7,my_semester_project_lidar_based_obstacle,uakbar,0.85,17,2019-09-30 17:58:10,0,0,,"The project: https://github.com/uzairakbar/rl-obstacle-avoidanceWhat definitely needs to be improved: details on problem statement and solution, docker file for ease of use?",,"Projects,"
632,https://www.reddit.com/r/datascience/comments/dbe1zh/data_science_in_the_insurance_industry/,dbe1zh,data_science_in_the_insurance_industry,Rify,0.88,12,2019-09-30 18:24:35,0,17,,"Hey!Anyone got some insight on what its like working with data at an insurance company? I'm going to start doing it soon. Its described as an actuarian position, but what they expect me to do is to analyze data related to insurance contracts in R.",,"Career,"
633,https://www.reddit.com/r/datascience/comments/dbjguf/software_for_data_analysis_club/,dbjguf,software_for_data_analysis_club,EschreurE,0.8,3,2019-10-01 00:28:18,0,5,,"I am starting a data analysis club at my college. Our first project is creating a database of all the stats collected by the baseball team. We want to let the database be easily accessible by all members of the club and baseball staff but only give certain club members permission to edit the database. I originally thought of using SQlite but am running into some problems with access permission and concurrency, so I'm turning to reddit for help. What (preferably free) software would y'all suggest we use? Another thing to keep in mind: most of our members are used to SQL and python. Any thoughts or suggestions would be very helpful!",,"Tooling,"
634,https://www.reddit.com/r/datascience/comments/dbkqqt/what_is_the_vast_gaping_hole_in_your_data_science/,dbkqqt,what_is_the_vast_gaping_hole_in_your_data_science,CWHzz,1.0,2,2019-10-01 02:02:42,0,20,,"We all have that one thing we should but don't know jackshit about. Curious to hear yours, no shame here.",,"Education,"
635,https://www.reddit.com/r/datascience/comments/dbanz4/is_there_an_easy_and_efficient_way_to_download/,dbanz4,is_there_an_easy_and_efficient_way_to_download,Altain2010,0.94,16,2019-09-30 14:15:44,0,10,,"I am currently researching about the evolution of popular topics in work and psychology journals. Because i am alone and have not that much expertise i realised, i need to focus myself on abstracts and not whole articles if i want to get this finished in a realistic time period. My problem is, it seems very inefficient to manually download or copy paste every article in a journal. So i wanted to know if journal pages have a function to download a lot of abstracts at once?",,"Projects,"
636,https://www.reddit.com/r/datascience/comments/db60sw/what_should_an_aspiring_data_scientist_know_when/,db60sw,what_should_an_aspiring_data_scientist_know_when,mrdlau,0.92,53,2019-09-30 05:51:49,0,21,,"I'm an aspiring data scientist that has the chance to work with data, python/R, and I'm trying to fill in any skills gap where I can to make myself more well rounded and marketable.  One part of the DS skillset that I  dont have a great concept of is cloud computing.  I get the concept of using something like AWS to purchase extra compute power to run code faster, but besides that, that's it.In terms of learning more about cloud computing,  what does it entail?  Is it specifically knowing how to runa specific tool like AWS, or is there more to it?  I'm guessing there may be more, so I'm just trying to get a sense of, what type of things should I aim to learn as it relates to 'cloud computing'?",,"Discussion,"
637,https://www.reddit.com/r/datascience/comments/dblb53/we_all_know_conventions_are_needed_but_how_have/,dblb53,we_all_know_conventions_are_needed_but_how_have,BroCirus,0.33,0,2019-10-01 02:45:44,0,1,,"The purpose of this thread is not to discuss what conventions should be or the methodology for arriving at those conventions, but rather the logistics of deciding what the conventions are. A lot of us have arrived at places that already had established style guides and standard practices. But do we know how those got there in the first place?How have you seen them decided on? Have you been involved? Was it the CTO/Management? Was it the individual team's tech lead? Was it all the developers in a room? Was it democratic or oligarchic? Was there a voting system involved?How long did it take to agree and finalize on? Were you around to see the conventions updated? Perhaps significantly overhauled?Please share your experiences, thoughts on how you would have preferred to see them established or sarcastic belittling comments!In full transparency I've been tasked with leading discussions on establishing conventions in our department and was curious how other places have done that.",,"Discussion,"
638,https://www.reddit.com/r/datascience/comments/dbdedv/what_types_of_data_tests_have_you_worked_on_for/,dbdedv,what_types_of_data_tests_have_you_worked_on_for,Unhelpful_Scientist,0.8,6,2019-09-30 17:40:30,0,7,,"I recent got one that required setting up a local SQL server, connect and then use 10 different tables to merge and aggregate data to answer some questions. This is for a start up in SF.Overall it probably took 6 hours plus getting the database setup. I am actually leaning toward turning the job down due to the level of ambiguity in the questions themselves. Imo if a question is unclear here that is a very poor sign.What kinds of projects and timeline have you had before?",,
639,https://www.reddit.com/r/datascience/comments/daxwf4/mid_career_advice_for_an_ml_generalist_update/,daxwf4,mid_career_advice_for_an_ml_generalist_update,maxmoo,0.96,235,2019-09-29 19:04:06,0,25,,"A few weeks ago I posted that I was having trouble with mid-senior level interviews. Since then I’ve changed a few things and had much better responses (3 onsite invitations and 2 offers). I've just signed an offer that I’m pretty happy with, and wanted to update you on some of the things that I think helped the most.Company sizeI was applying pretty randomly to a lot of different size companies, turns out my sweet spot seems to be startups with 10-20 employees who don’t have an ML manager yet. (I don't have enough management experience to go for manager roles at larger companies). I think this is because I’ve had too many experiences with bad managers that I don’t really trust them, so I probably put out a prickly vibe in interviews that puts people off.Age(ism)I do a lot better when interviewed by older people, like 40-50+, they seem to have more respect for my PhD and life experience rather than just trying to catch me out on something I don’t know off the top of my head. Luckily the tech bubble (e.g. 20-year old founders of juice startups) is settling down, I think I read somewhere that most successful startups are actually founded by 40+ year olds, so hopefully the industry will go more back to the way it was in the 80s and 90s.StatisticsI’ve never really got statistics on a deep level (my PhD is in pure math) so have always struggled with stats questions in interviews, e.g. “there are two groups of users each one does a certain number of clicks per day, how do you know if one is more than the other.” Stats just seemed like a random bag of z scores and t tests and I don’t even really believe in p-values; I’d remember enough to stumble my way thorough, and then say something about bootstrapping confidence intervals when I couldn’t, but it made me come across as pretty weak. What turned it around for me was reading “Statistical Rethinking” by Richard McElreath: writing out the equations for statistical models gives me confidence when I’m talking ( I come from a math background) and then I can just say that I would run MCMC to get the coefficients.I’ve also screwed up a few interviews with time series data from sensors (outlier detection etc) ... I still don’t really know how to approach these.ML modelsThis was one of the biggest things I was doing wrong in retrospect. When I was asked “tell me something you’ve done that you’re proud of” I’d tell stories about powerful business results I’d achieved using simple models like heuristics, logistic regression or random forests together with more organisational things like clarifying metrics and objective functions with stakeholders, product/design thinking, evolving data-labeling practices, and testing models in production as soon as possible.Lol turns out people don’t want to hear about any of this, maybe it made them think that I just plug data into a black box and don’t understand how it works? Anyway things turned around for me when I dropped all the business stuff and started just talking about (the one time) when I read a research paper, implemented the algorithm in PyTorch and got a meaningful gain in accuracy.EngineeringYou guys were right, I didn't need more engineering experience, I'm already pretty strong for a data scientist, I was just doubting myself due to my current company (which doesn't have a data science org) gaslighting me into taking a lower pay grade.Anyway hope this is useful to some of you, definitely going to approach my next job search differently although maybe things will be different by then anyway and I might be going for more management-level roles. Have any of you had similar experiences?",,"Job Search,"
640,https://www.reddit.com/r/datascience/comments/db50c2/useful_ways_data_scientistsanalysts_use_git_in_a/,db50c2,useful_ways_data_scientistsanalysts_use_git_in_a,mrdlau,0.81,6,2019-09-30 04:20:21,0,7,,"I spent this weekend learning git and I feel I have a good feel of  the basics.open up the terminal and point it to the working directoryinitialize a respositorymake changes to code, compare changes, and commit it.So my impression is that right now, I see it as a tool to keep track of all my changes, and/or also allow multiple people to work on a code and push it up to commit.Besides that,  is there any other key skill that I'm missing from git?  What else should I know about git that may be useful in a working environment?If my team doesn't really collaborate on a single code, so is it essentially just a version tracker for my personal use?",,"Discussion,"
641,https://www.reddit.com/r/datascience/comments/db0yxm/people_who_are_training_on_hundreds_of_millions/,db0yxm,people_who_are_training_on_hundreds_of_millions,Unreasonable_Energy,0.8,11,2019-09-29 22:46:31,0,15,,"As a ""data science "" newb, coming from a statistics background where smaller data is the norm and sampling is ubiquitous, when I see people here talking about the strategies for manipulating their massive datasets, I suppose they have good reasons to need to do that -- but in the same discussions, I see stuff about perfect being the enemy of good in a modeling context, get 90% of the way there today instead of 99% percent of the way there next month, etc.  I'm aware that in some extraordinary contexts you need everything you can get and more, but in most such cases, how much can you really be losing by sampling down a couple orders of magnitude?I'd like to hear about what kind of constraints you all are encountering in your work that require engaging deeply with the full don't-fit-on-your-RAM.  Is it massive dimensionality?  Hyper-rare outcomes?  Hundreds of millions already IS the sample from something even more unwieldy?  Need for extreme precision?  Commands from on high?  I assume most of this work in a business context is not heavy-duty training-vision-on-billions-of-frames-of-video type stuff, so what is it?  Trying to get a feel for this part of the practice that I'm not well acquainted with.",,"Discussion,"
642,https://www.reddit.com/r/datascience/comments/db1gax/weekly_entering_transitioning_thread_29_sep_2019/,db1gax,weekly_entering_transitioning_thread_29_sep_2019,datascience-bot,0.92,9,2019-09-29 23:22:25,0,110,,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki.You can also search for past weekly threads here.Posted at 2019-09-29 23:22:15 UTC",,"Discussion,"
643,https://www.reddit.com/r/datascience/comments/db4i6i/extracting_data_from_scanned_spreadsheets/,db4i6i,extracting_data_from_scanned_spreadsheets,hcir614,1.0,5,2019-09-30 03:37:02,0,14,,"I have a bunch of data on printed spreadsheets. Of course, the source of this data decided to take their raw data, input it into a computer, print out the data, and then not save any backups in a digital format. I have a pipeline going for re-scanning the pages and extracting the data, but the results have been less than stellar and I'm hoping somewhere here can provide a better way to go about it.All of the data is in the same format. I.E. Column 1 is date in DDMMYYYY, column 2 is an identifier, column 3 is a float to 1 decimal place, etc...Currently, this is my workflowScan imagesClean/sharpen/rotate/crop imagesConvert tif files to one multipage file Create config file >> tessedit_char_whitelist V-8BEIHOD5A04SQJ3GUNFL21RYT67P/9CMRun tesseract to create pdf and use configThen run tabula on outputI've also played around with using -psm6 segmentation mode and outputing to a TSV instead of running tabula, again, the results haven't been great; the biggest mistakes are misinterpreting characters (often to one that would never be in a particular column) and not properly differentiating columns.  I'm wondering if there is somewhat to explicitly state to tesseract, there are X columns to look for, the first column is in this format, the second in that format, etc etc etc. Is this possible?",,"Projects,"
644,https://www.reddit.com/r/datascience/comments/db2e36/approaching_small_businesses_for_free_consulting/,db2e36,approaching_small_businesses_for_free_consulting,Zanacorfe,0.64,3,2019-09-30 00:36:16,0,14,,"I need another personal project to put on my resume, and I'd like to work with some unique data to extract insights. Only issue is that I'm not sure where to look. My goal is to provide some value in the form of dashboards, predictions, business insights, etc. I think that since small businesses don't have the infrastructure for analytics, this can be a fun project where I go the full length of A to Z in a data science project.Only issue is that I a lot of small businesses don't know where to start when it comes to data. For example, if I walked into my local mom and pop gym, looked them in the eyes, and said ""I want to analyze your data"" they'd probably tell me to get out. But the truth is that chances are I can extract value from some fitness center data such as traffic in/out through check ins, effectiveness of sales promotions, etc.Has anyone been down this road before? Also, if you are a small business owner and would like to have me work with you I'm all ears. Currently I'm completing my master's in Applied Statistics and have the goal of becoming a Data Engineer/DS. ThanksEdit: Thanks everyone, this  has given me a lot of options to explore",,"Discussion,"
645,https://www.reddit.com/r/datascience/comments/da5mhe/found_this/,da5mhe,found_this,Sir-_-Butters22,0.98,1528,2019-09-27 21:55:41,0,47,,,,
646,https://www.reddit.com/r/datascience/comments/dahxre/yet_another_guide_to_deploy_plotly_dash_on_aws/,dahxre,yet_another_guide_to_deploy_plotly_dash_on_aws,MiracuIa,0.9,7,2019-09-28 18:07:33,0,2,,,http://www.zhengwenjie.net/beanstalk/,"Education,"
647,https://www.reddit.com/r/datascience/comments/d9y3bz/github_releases_dataset_of_six_million_methods/,d9y3bz,github_releases_dataset_of_six_million_methods,mystikaldanger,0.99,210,2019-09-27 11:50:18,0,1,,"Introducting The Github CodeSearchNet ChallengeSearching for code to reuse, call into, or to see how others handle a problem is one of the most common tasks in a software developer’s day. However, search engines for code are often frustrating and never fully understand what we want, unlike regular web search engines. We started using modern machine learning techniques to improve code search but quickly realized that we were unable to measure our progress. Unlike natural language processing with GLUE benchmarks, there is no standard dataset suitable for code search evaluation.We collected a large dataset of functions with associated documentation written in Go, Java, JavaScript, PHP, Python, and Ruby from open source projects on GitHub. We used our TreeSitter infrastructure for this effort, and we’re also releasing our data preprocessing pipeline for others to use as a starting point in applying machine learning to code. While this data is not directly related to code search, its pairing of code with related natural language description is suitable to train models for this task. Its substantial size also makes it possible to apply high-capacity models based on modern Transformer architectures.Our fully preprocessed CodeSearchNet Corpus is available for download on Amazon S3, including:Six million methods overallTwo million of which have associated documentation (docstrings, JavaDoc, and more)Metadata that indicates the original location (repository or line number, for example) where the data was found",,"Discussion,"
648,https://www.reddit.com/r/datascience/comments/da78zo/dealing_with_python_phobic_vp/,da78zo,dealing_with_python_phobic_vp,svpadd3,0.82,7,2019-09-28 00:00:32,0,9,,"So the V.P of engineering at my company seems to have an irrational dislike of Python and instead wants to force us (data engineering/data science) to use Java or when that isn't available (Google Cloud functions only support JS, Node, and Python)  to use JavaScript for all production applications. This is ridiculous as I have already attempted to explain to him (1) Java does not have the necessary machine learning libraries (nor the necessary transformations needed)  (2) orchestration tools like Airflow are exclusively Python (3) Python is easily deployable (tons of companies use it successfully in production) and (4) the majority of our team does not know Java but everyone is familiar with Python (this includes both data engineers and data scientists). No one I have talked to prefers Java on either the Data Engineering nor the Data Science side. This seems to be top lunacy of the greatest order. What is the best way to deal with this problem?",,"Career,"
649,https://www.reddit.com/r/datascience/comments/d9ou35/my_conversion_to_liking_r/,d9ou35,my_conversion_to_liking_r,LjungatheNord,0.95,255,2019-09-26 21:51:15,0,137,,"Whilst working in industry I had used python and so it was natural for me to use python for data science. I understand that it's used for ML models in production due to easy integration. ( ML team of previous workplace switched from R to Python). I love how easy it  is to Google stackoverflow and find dozens pages with solutions.Now that I'm studying masters in data analytics I see the benefits of R. It's used in academia, even had a professor tell me off for using python on a presentation lol. But it just feels as if it was designed for data analytics, everything from the built in functions for statistical tests to customisation of ggplot just screams quality and efficiency.Python is not R and that's ok, they were designed for different purposes. They each have their benefits and any data scientist should have them both in their toolkit.",,
650,https://www.reddit.com/r/datascience/comments/da0rk3/anyone_learn_a_new_language_by_forcing_themselves/,da0rk3,anyone_learn_a_new_language_by_forcing_themselves,meowmixalots,1.0,8,2019-09-27 15:56:12,0,12,,"I'm currently a data analyst. At my last job I used a GUI tool for analysis, and now I am using STATA. I'm glad to be writing actual code in STATA, instead of the nodes and dropdowns at my last job, but I've heard so many great things about R and I want to see what it can do. Not to mention to be competitive if/when I have to hit the job market again.My problem is that I've already become comfortable in STATA. But the upside is that my job is usually of a slower pace, so I *could* feasibly do my work in RStudio, and then re-do it in STATA to save code for others in my office. It's just hard to get over that hump of learning a new language, where I basically have to google pretty much anything before I do it.Has anyone learned a language successfully this way? Looking for a little motivation as I'm currently googling how to ""describe"" or ""summarize"" a dataset in RStudio (get a list of the variables and some basic stats) and I don't even know what command to use!",,"Discussion,"
651,https://www.reddit.com/r/datascience/comments/da60ve/share_data_dashboard_w_multiple_clients_via/,da60ve,share_data_dashboard_w_multiple_clients_via,zibdominus,0.5,0,2019-09-27 22:25:28,0,3,,"Anything like Chartio or Tableau that I can have my clients login to and see their own specific dashboards that I build for them?I have all their data in google sheets and I usually just download their data in excel, graphs, etc and email them the excel file.I would like to give them a live login where they could just see the data at their convenience.",,"Tooling,"
652,https://www.reddit.com/r/datascience/comments/da1uw0/using_results_of_analysis_as_predictors_in/,da1uw0,using_results_of_analysis_as_predictors_in,sotities,0.75,2,2019-09-27 17:16:18,0,11,,"Greetings all, I am trying to figure out if using results of other kinds of analyses(e.g. clustering, dim. reduction, sentiment analysis) is an option when creating a regression model. For example, let us say  I would like to measure the effect of twitter related sentiment on movie sales.",,"Projects,"
653,https://www.reddit.com/r/datascience/comments/da225b/how_do_you_talk_about_your_work_experince_in_your/,da225b,how_do_you_talk_about_your_work_experince_in_your,feldon0606,0.6,1,2019-09-27 17:31:09,0,5,,"I am the only ""data guy"" in our company and I've been responsible for all things related to data. I would love to read the sort of language you use when you talk about what you do. I always feel a little bit uncomfortable about bragging what I've achieved and what I know. I always feel like it is very bland, arrogant and boring to read. Can't think of a worse mix!Here's the sort of stuff I've done and How I would describe in my CV:Identifying useful datasets and purchasing  - I acquired relevant data sets from various providers which I have identified as useful to the business.Managing data generated by employees - I have organized and helped to set standards for handling data generated internally.Setting up a CRM - When I first joined company XYZ they had no formal CRM in place. I have played an important role in setting up CRM through identifying stakeholders' needs and implementing them in the CRM solution.Analyzing data to find safe investment opportunities - By combining data from various sources and collaborating with STFC, I have delivered a reliable method for de-risking investments. This method is currently used to plan an investment in telecoms infrastructure worth over £1.5mln.",,"Job Search,"
654,https://www.reddit.com/r/datascience/comments/d9ykip/how_to_identify_similar_datasets_based_on/,d9ykip,how_to_identify_similar_datasets_based_on,gajus0,1.0,2,2019-09-27 12:42:07,0,2,,"I have a dataset that describes movie releases, i.e. day by day number of seats allocated to the movie and number of seats sold at different geographic locations. This dataset looks something like this:Country IDCity IDMovie IDDateRelease DaySeat CountSeat Sold Count1112019-01-01-1450005001112019-01-02-1350003001112019-01-03-129000700This example dataset describes three days of a movie pre-release (thus the negative release day), and it says that on the first day when showtimes were published 5000 seats were allocated to the movie and 500 seats were sold on that day. Next day there were still 5000 seats allocated and another 300 were sold, etc.Release Day is normalised to represent the same period in the movie release window across all movies, i.e. release day 1 will always be Monday of the first isoWeek that contains the showtimes.My dataset describes couple of thousand movies across different cities. My task is given 1 movie release identify other movie releases that behaved similar at the same point in time in the past.Ideally, I am looking to do this in PostgreSQL, but it could be done outside of the database too.What is the best way to find the most similar datasets where multiple variables are shared (country ID, city ID, release day) and other variables have varying scales (seat count, seat sold count)?",,"Discussion,"
655,https://www.reddit.com/r/datascience/comments/da0b4x/a_question_for_more_experienced_data_scientist/,da0b4x,a_question_for_more_experienced_data_scientist,OneOverNever,0.67,1,2019-09-27 15:20:10,0,6,,"I'm arriving at an intersection between too many areas of expertise and frankly I'm a little overwhelmed.So, a few questions:When did you realize what you wanted to specialize in? Was this based on your previous knowledge of certain topics? (people who migrated to data science after having worked in other fields)Did you ever switch directions within data science?Am I completely delusional and I'm truly going to have to learn how to handle absolutely all fields of the profession?Have a good Friday :)",,"Discussion,"
656,https://www.reddit.com/r/datascience/comments/d9zopu/til_imagenet_has_labels_for_their_face_data/,d9zopu,til_imagenet_has_labels_for_their_face_data,ThatSpookySJW,0.62,2,2019-09-27 14:28:14,0,6,,,https://www.nytimes.com/2019/09/20/arts/design/imagenet-trevor-paglen-ai-facial-recognition.html,"Fun/Trivia,"
657,https://www.reddit.com/r/datascience/comments/d9w6w3/what_is_the_appropriate_title_for_this_job/,d9w6w3,what_is_the_appropriate_title_for_this_job,liuuuk311,1.0,3,2019-09-27 08:02:38,0,4,,"I applied for the following position in a data science company, and I'm doing a bit of research on similar jobs to have an idea of the potential salary because they are going to give me their offer next week.What is the appropriate title for this job?You are going to:Working with the management of MySQL and NoSQL databasesCreating a more fast and efficient way of storing and accessing dataLeading projects involving creating new databasesMaintaining and managing the data in our databasesGood knowledge related to collecting data from the webEfficient and compact programming skills with a good eye for error logging and debuggingAbility to write efficient and optimized queries in SQL and NoSQLStrong Ability to update and maintain SQL and NoSQL databases via PythonSupport both the Data and Development teams at the companyRequired Skills / KnowledgeSQLNoSQL(mongo)PythonDatabase design and modellingPerformance testingGitDesired Skills And InterestsPHPJavaETL ExperienceSQL Performance Tuning",,"Career,"
658,https://www.reddit.com/r/datascience/comments/d9yjb6/i_keep_seeing_the_meme_machine_learning_is_just/,d9yjb6,i_keep_seeing_the_meme_machine_learning_is_just,oseh112,0.33,0,2019-09-27 12:38:26,0,9,,From what little I know about the subject this doesn’t seem to be the case. I was wondering if it was true. There’s a real possibility I’m missing something. I’d like someone who knows their stuff to enlighten me please. Thank you.,,
659,https://www.reddit.com/r/datascience/comments/d9ut59/anyone_using_kedro_here/,d9ut59,anyone_using_kedro_here,WittyKap0,1.0,3,2019-09-27 05:39:11,0,7,,"I discovered kedro (here) recently and so far I have found it to be pretty awesome though there are some parts that I think can be improved.Just want to know if anyone here has been using it and if so, what are your thoughts. It doesn't seem to have gotten enough traction and the main discussion forum seems to be their github issues page (besides some naysayers commenting on the original press release)",,
660,https://www.reddit.com/r/datascience/comments/d9qom4/whats_pandas_missing_that_tidyverse_provides/,d9qom4,whats_pandas_missing_that_tidyverse_provides,thatusername8346,0.91,9,2019-09-26 23:59:08,0,23,,"I was just reading this post and there are people praising the tidyverse. I'm curious what the main features tidyverse has that pandas is lacking.This isn't intended to be any sort of argument starter , I'm just curious. I've used them both a bit and found them both nice, but I can't say that I've really missed anything from one that the other provides. Perhaps the mutate function in tidyverse is nice 🤔any examples would be of interest, thanks",,"Discussion,"
661,https://www.reddit.com/r/datascience/comments/d9r4c3/neural_networks_explained_feedforward_and/,d9r4c3,neural_networks_explained_feedforward_and,permalip,0.82,7,2019-09-27 00:30:18,0,3,,"> Link; Neural networks: Feedforward and BackpropagationHey r/datascience,I wrote this long article explaining the basics of neural networks, and I just got it published on Towards Data Science. I hope that you could learn something from it and have a discussion with me. I'm always open for feedback, questions or any other type of comments.",,"Discussion,"
662,https://www.reddit.com/r/datascience/comments/d9a3o1/the_secret_sauce_to_landing_a_data_science_role/,d9a3o1,the_secret_sauce_to_landing_a_data_science_role,mathmagician9,0.96,530,2019-09-25 23:47:47,0,61,,"I see tons of posts on here claiming specific technical skills needed to become a data scientist. As someone who conducts interviews, mentors new data scientists, and up-skills analysts and engineers, I wanted to offer my perspective. While I believe it is true that there are certain base technical skills required, I do not believe technical knowledge is what your interviewer is looking for, especially if you've made it to a conversational interview.The skills listed are merely talking points. Your interviewer most likely understands that you aren't currently an expert at every skill they question. They are likely interviewing you until they get to skills you are unfamiliar with. How do you respond when you don't know something? Do you admit it, or do you try and cover your competency? Are you defensive or are you curious? This is a continuous learning and feedback role. How have you identified, learned, and implemented a new skill? Are you even passionate about learning or are you obviously chasing titles, prestige, or salary?They are looking for you to be confident in what you do and do not know. Do you boast algorithms and techniques you can't explain or worse, are you arrogant or elitist? Quickly in this role you will be presented with extremely ambiguous requirements. How comfortable are you with this ambiguity and how can you adapt or learn what is necessary to overcome and move forward with development? Will the team risk failure because you didn't speak up about your ability? Do you seek perfection and risk analysis paralysis, or do you iterate and experiment quickly? Are you someone who is a joy to mentor, support, and watch grow? Grit, growth oriented, self-aware, and an open-mind are qualities I consider essential.With the right mindset and support, the technical skills are not difficult to learn, especially with the pace of evolving tools. It's an investment the company should be knowingly willing too make. This mindset is what is hard to train for.Hope my advice helps. Good luck!",,
663,https://www.reddit.com/r/datascience/comments/d9soum/my_top_10_r_packages_for_data_analytics_jacky/,d9soum,my_top_10_r_packages_for_data_analytics_jacky,xiaodaireddit,0.67,2,2019-09-27 02:31:17,0,2,,,https://www.actuaries.digital/2019/09/26/my-top-10-r-packages-for-data-analytics/,"Tooling,"
664,https://www.reddit.com/r/rstats/comments/d9son5/my_top_10_r_packages_for_data_analytics_jacky/,d9son5,my_top_10_r_packages_for_data_analytics_jacky,xiaodaireddit,0.92,70,2019-09-27 02:30:46,0,11,,,https://www.actuaries.digital/2019/09/26/my-top-10-r-packages-for-data-analytics/,
665,https://www.reddit.com/r/datascience/comments/d9mz6b/fantasy_football_prediction_project_feedback/,d9mz6b,fantasy_football_prediction_project_feedback,KingBuckIII,0.76,4,2019-09-26 19:37:03,0,9,,"** Mods - I looked through the sub's rules and didn't see anything that precluded asking for a code review, but let me know if this isn't allowed.Hi all - As the title mentioned, I am working on building a model that can predict fantasy points scored in the National Football League (NFL) for a given player in a given week. To start off, I am working on gathering historical data that I can use to backtest my model. This consists of:NFL players and the number of points they scored in a given weekThe game spread and game total predicted by sportsbooksStats used to evaluate the matchups each player is inAs of now, I have only worked with one set of data (2018 season, week 17) for one position (quarterback). Before I scale the program for other weeks/positions, I was hoping to get some feedback. I will appreciate any and all feedback. Some of the things I have in mind are:How are my function comments? Are they too specific or are they ok?How is my code design? Can anything be done to make it more elegant/efficient? Would an OOP approach help and what might that look like?Are my use of the pandas methods merge, concat, etc. efficient? I am thinking maybe those could be more efficient, in light of all of the renaming and dropping I did.Anything and everything else!A little bit about me - I am mostly self-taught, but have taken an intro to computer science class at a university. We got through OOP, but most of the OOP concepts are a bit of a head-scratcher for me haha.You can find what I have so far here: https://github.com/michaeldlynch3/nfl_backtest, including the raw files I started with.",,"Projects,"
666,https://www.reddit.com/r/datascience/comments/d9ulcq/bad_interview_experience/,d9ulcq,bad_interview_experience,sang89,0.67,1,2019-09-27 05:18:43,0,3,,"First of all, sorry if this is the wrong place for this post. I wanted to share my experience with yall, but totally fine if this needs to be deleted.I had a technical phone interview a couple of days back with a big tech company for machine learning swe position. Interviews are hard to come by and I was really excited about this one.When it began, from the get go, I was struggling to understand what the interviewer was saying. It wasn't his English. It was bad audio quality (probably caused by echo in an empty room he was in) and his fast talking style, which made it difficult. I was literally leaning towards my phone which was on speaker,each time he spoke. I tried my best to repeat things which I didn't fully grasp (very frequently).I didn't do well on the interview. It was my first, and felt I was rushing into answers coz he was talking so fast, and at times I zoned out thinking about how poorly it was going. I did answer the programming question.I emailed the recruiter after letting her know. Now I feel I should have brought up the audio issue right at the start of the interview. This was something I didn't anticipate even one bit and caught me completely off guard.It stings coz it was an easy interview and i could have done wayyy better than I did..",,
667,https://www.reddit.com/r/datascience/comments/d9u7lu/if_were_coining_the_term_mad_to_refer_to_machine/,d9u7lu,if_were_coining_the_term_mad_to_refer_to_machine,rowdyllama,0.5,0,2019-09-27 04:43:34,0,5,,,,"Discussion,"
668,https://www.reddit.com/r/datascience/comments/d9g0vu/using_pandas_profiling_to_get_an_overview_of_any/,d9g0vu,using_pandas_profiling_to_get_an_overview_of_any,DrChrispeee,0.87,30,2019-09-26 08:54:09,0,7,,"I'm an aspiring ""Data Scientist"" and through the last 6 months I've been working with data in Python almost exclusively and using primarily pandas to do so.Normally when I first get a new set of data I use the .info(), .describe() and .sample() methods on my dataframe to get a quick overview, however I just discovered the ""Pandas Profiling"" package,  which makes creating this kind of overview even easier and more powerful than the vanilla approach!I've made a quick animation to show off a lot of the features of the package in a really short article: https://towardsdatascience.com/exploring-your-data-with-just-1-line-of-python-4b35ce21a82dObviously there's some limitations to this, but it's really powerful for understand the distributions of your variables and find any highly correlated or highly skewed variables as well.I hope you find it useful!",,
669,https://www.reddit.com/r/datascience/comments/d9nb6y/source_to_follow_ds_news/,d9nb6y,source_to_follow_ds_news,kenenec,1.0,5,2019-09-26 20:00:59,0,4,,Where do you guys follow Data Science industry related news?,,"Discussion,"
670,https://www.reddit.com/r/datascience/comments/d9mo9j/how_to_create_a_ratings_index_to_compare/,d9mo9j,how_to_create_a_ratings_index_to_compare,sarvesh2,1.0,3,2019-09-26 19:15:41,0,6,,"I have  real state data and i want to compare some of the houses with each other and assign them a rating [0-10].My factors are foot traffic, days on market and some other factors related to house like no of bed/ bath, area etc. I don’t have any output variable so i can’t build any kind of classification or regression model and use it for ranking.For example if i take out 3 houses from data set A , B and C. i want to assign them ratings based on the available factors like A=3 , B=8 and C=6. There can more than 3 houses for comparison. How can i approach this problem? Any help will be much appreciated.",,"Discussion,"
671,https://www.reddit.com/r/datascience/comments/d9r1wg/all_onehot_features_any_goto_first_models/,d9r1wg,all_onehot_features_any_goto_first_models,one_game_will,1.0,1,2019-09-27 00:25:26,0,6,,"I am looking at a dataset where essentially each observation has a set of tags, and an associated outcome (a real number). I have one-hot encoded every tag as a feature and can just throw everything and the kitchen sink at it to get the best prediction, but it feels like there might be a staple ML (or classical stats) approach that is always a good place to start for this type of dataset.Essentially I am imagining my observations lying on vertices of a hypercube in feature space and feel like there should be an elegant way to make predictions on it; any suggestions?",,"Discussion,"
672,https://www.reddit.com/r/datascience/comments/d9pym1/is_there_a_website_where_i_can_use_sql_and_upload/,d9pym1,is_there_a_website_where_i_can_use_sql_and_upload,dashiesweetie,0.5,0,2019-09-26 23:07:26,0,6,,A website where I can upload excel tables to it as well? I have an assignment and I tried downloading SQL server on my computer but it just won’t work. There is always some error that I can’t figure out no matter how much I follow the YouTube tutorials. I just want a simple website where I can do queries and upload excel files so I can retrieve data from the excel data set,,
673,https://www.reddit.com/r/datascience/comments/d9pqme/find_all_different_combinations_of_string/,d9pqme,find_all_different_combinations_of_string,Jbor941197,1.0,1,2019-09-26 22:51:52,0,2,,"Hello,My goal is to determine if a transactions comes from a group of companies. I have a separate data set with example transactions from each company. How would I find every possible combination (maybe something regex related), so that I can determine if a transaction is from one of the desired companies. Don't need step by step help just pointing me in the right direction would suffice. R or python pleaseExampleUDNKDKIUS%&* AMZN XXXXJDNDJDKIUUYYERBNM AMAZO XXXXXNNN",,"Projects,"
674,https://www.reddit.com/r/datascience/comments/d9i7tm/data_science_events_and_organisations_australia/,d9i7tm,data_science_events_and_organisations_australia,new-user-123,0.79,5,2019-09-26 13:18:22,0,4,,"(Will crosspost to r/australia once I figure out how to do that)Hi everyone!As someone who is a year or so into their analytics journey (somewhat), I've been meaning to go to some events and perhaps professional societies. I have accountant friends who are in that Charted Accountant club and lawyer friends who are in their Law Societies, but what about for data science? Any in Australia?Best I can find is Statistical Society of Australia?There is also the 'Data Science and AI Association of Australia' which has 116 people on Facebook and looks like its for uni students (their forum is basically 'How do I do this week 2 homework question'). There is also the 'Institute of Analytics Professionals of Australia' but I'm not sure if they're active because the only event they mention on their website is something that happened almost two months ago.There is also the 'Data Science Institute of Australia' which is even worse - the only event they mention is something back in April...Any ideas? Or is this the sort of space where I say, 'Alright, I'm making my own'?",,"Networking,"
675,https://www.reddit.com/r/datascience/comments/d9lnw0/parquet_file_viewer_for_windows/,d9lnw0,parquet_file_viewer_for_windows,bluethundr0,0.67,1,2019-09-26 18:03:32,0,2,,Is there a Parquet file viewer available for windows that  you don't have to download from the windows store? My company disables the windows app store on the laptops we use.,,"Discussion,"
676,https://www.reddit.com/r/datascience/comments/d9h0io/word_cloud_using_comments_from_this_subreddit/,d9h0io,word_cloud_using_comments_from_this_subreddit,chancedare,0.63,2,2019-09-26 11:01:35,0,3,,,,"Fun/Trivia,"
677,https://www.reddit.com/r/datascience/comments/d8vbxd/i_just_want_to_say_that_i_love_this_community_for/,d8vbxd,i_just_want_to_say_that_i_love_this_community_for,Shouldacouldawoulda7,0.94,275,2019-09-25 01:33:09,0,21,,"It seems that, regardless of the knowledge gaps between different users, the people in this sub are always truly interested in sharing their knowledge about the field and industry. Thank you for taking the time and for being so damn nice about it.",,
678,https://www.reddit.com/r/datascience/comments/d96vbf/ide_for_ds/,d96vbf,ide_for_ds,kenenec,0.8,8,2019-09-25 19:51:31,0,32,,What is your favor IDE and editor as DS,,"Discussion,"
679,https://www.reddit.com/r/datascience/comments/d9cob5/how_do_all_these_sites_get_their_data/,d9cob5,how_do_all_these_sites_get_their_data,The_John_Galt,0.33,0,2019-09-26 03:23:06,0,5,,"Sites with real estate data like zillow or bestplaces, personal data (cell phones, email etc) like rocketreach.co where are they getting it? I'm assuming it's all open source and they are just compiling and repacking it for sale but is there a good way to find the underlying open data source?",,
680,https://www.reddit.com/r/datascience/comments/d976ew/what_public_data_set_have_you_found_the_most/,d976ew,what_public_data_set_have_you_found_the_most,dfcHeadChair,1.0,3,2019-09-25 20:13:33,0,5,,"Sort of a generic conversational question, but which data set is either the coolest or most useful by however you define them.It could be work or project related, or maybe something you just found one day and thought was a neat data set.",,
681,https://www.reddit.com/r/datascience/comments/d96c6o/can_i_call_myself_a_data_scientist_on_linkedin/,d96c6o,can_i_call_myself_a_data_scientist_on_linkedin,nicolas-gervais,0.8,3,2019-09-25 19:13:34,0,8,,"Just got hired by Canada's largest bank as a ""forecasting and modeling analyst"". I don't think it sounds as good as data scientist so I'd rather put that on my LinkedIn and resume. The job description and desired competencies are basically identical to the usual data scientist job: image recognition, using deep learning, machine learning, ensemble methods to perform a range of calculations. The forecasting part doesn't seem true based on the job description, not once were time series mentioned.",,
682,https://www.reddit.com/r/datascience/comments/d9kese/is_there_a_minimum_iq_needed_for_data_science/,d9kese,is_there_a_minimum_iq_needed_for_data_science,CryptPrep,0.18,0,2019-09-26 16:29:55,0,31,,"Hi,I'm currently a freshman majoring in CS + Stat who is really interested in the field of data science.DS absolutely amazes me and I wish to work hard and make it into this field and contributing to the society.Back in 2013, I took an official IQ test at UIUC.The result turned out to be 117, and back then I really did not have a care about my result.It was more like ""oh well cool I guess?""Even the researchers there told me that I do have an IQ that is 1 std above the average. However, the measuring of intelligence is very vague, so it may not be all that accurate.About a year and a half ago, my friend introduced me to a prominent psychologist named Jordan Peterson.I consumed all of his contents, and sometimes I would find myself watching his videos for 6 hours straight. Since college has started, I no longer really watch his contents that much but there is one thing that bothers me.There is one of his lecture which you can find on youtube called ""Occupation and IQ"" or something along with that nature.It turns out as for most engineering field, IQ of 130 is minimum. As for data science, it turns out you need to have an IQ of 150 (3 std up above the average population).The truth is that IQ is purely genetic (meaning you cannot improve your IQ and at best you can up about 2 points basis), and it is in fact a good way to measure your intelligence and success besides consciousness. That is why, as Peterson claimed that White and Asian Male in America tends to be more successful, and minorities have it a hard time to make a living.This somewhat made me think if I should even try to become a data scientist.Even software engineering needs an IQ of 130.Jordan Peterson said that there would be a slight variation and outliers but it is going to be much harder for IQ 117 to compete with IQ 150, especially in the field like data science.However, the reason I'm posting here is that I feel like an IQ of 150 is a bit too high. I would understand if it is around IQ of 140 which is the average IQ for a physics professor. So that means data scientist are more intelligent than physics professor?Please enlight me on this topic reddit!",,"Discussion,"
683,https://www.reddit.com/r/datascience/comments/d8x23w/jupyter_notebook_support_coming_to_vs_code/,d8x23w,jupyter_notebook_support_coming_to_vs_code,Life_Note,0.96,43,2019-09-25 04:23:04,0,2,,,https://twitter.com/davorabbit/status/1176314998806630400,"Discussion,"
684,https://www.reddit.com/r/datascience/comments/d9apdk/how_can_i_increase_the_accuracy_of_my_occupancy/,d9apdk,how_can_i_increase_the_accuracy_of_my_occupancy,NEGROPHELIAC,0.5,0,2019-09-26 00:40:51,0,5,,"Hi there,I have a project that's aimed to predict the amount of occupants at my local gym given the date and weather.Here's my Kaggle kernelI have two datasets, occupants on a given hour and weather on a given hour.My process is that I combine these two datasets, and using Occupants as the target.However, when I implement a regression algorithm I can only reach a prediction score of 57%.I'd love any advice on how to modify my solution to achieve better predictions?Thank you.",,"Projects,"
685,https://www.reddit.com/r/datascience/comments/d92pt8/is_anyone_here_from_nepal_would_like_to/,d92pt8,is_anyone_here_from_nepal_would_like_to,ashim1412,0.78,5,2019-09-25 14:41:05,0,0,,"First of all thank you to everyone here for creating quality post, suggestions, links and helping others to learn.But as title suggest, is there any professional from Nepal in here? I am finding it very hard to find a traineeship or an intern to further my career. So it would be of great help, if I could get in touch with data science professionals from Nepal.",,"Networking,"
686,https://www.reddit.com/r/datascience/comments/d93er5/those_of_you_who_use_personal_laptops_at_work_are/,d93er5,those_of_you_who_use_personal_laptops_at_work_are,Lostwhispers05,0.83,4,2019-09-25 15:38:04,0,4,,What the title says.,,
687,https://www.reddit.com/r/datascience/comments/d91ea7/anyone_tried_gaussian_process_for_time_series/,d91ea7,anyone_tried_gaussian_process_for_time_series,phildunphy2018,1.0,4,2019-09-25 12:32:39,0,0,,"Using GP for extraction and prediction of seasonality, trend and noise from actuals?",,
688,https://www.reddit.com/r/datascience/comments/d8r4w2/how_do_you_manage_overthinking/,d8r4w2,how_do_you_manage_overthinking,DataBar,0.94,57,2019-09-24 20:20:10,0,42,,Few months into my first analyst job and I'm realizing that my work pace is down to a crawl many times simply because I'm overthinking a problem.Anyone else get over something like that? What helped?,,
689,https://www.reddit.com/r/datascience/comments/d947xt/data_science_in_a_noncorporate_setting/,d947xt,data_science_in_a_noncorporate_setting,ibetDELWYN,0.6,1,2019-09-25 16:41:07,0,2,,"How hard would it be to transition to doing data science or analytics outside the world of business?A little context - I've been working as an associate data scientist, finding ways to retain more users and deliver a better customer experience through our app. I've been feeling frustration that the work I do is mostly in the service of product managers that don't understand the data and misuse the insights we provide to game their KPIs. And at this point, I don't think it'll get any better even if I leave - All the companies feel the same.Is there hope for someone who wants to try working in a non-business setting, but doesn't want to fully devote himself to the statistical rigors of ML? I see myself as more of an analyst and less of an engineer - How can I apply those skills outside of a business context?Fields that come top of mind are environmental sciences, transportation and energy engineering. Is there a place in those (+ similar) fields that don't require a Master's or PhD level of understanding, for a humble data analyst such as myself?You guys' thoughts would be much appreciated. Thanks!",,"Career,"
690,https://www.reddit.com/r/datascience/comments/d8la5g/how_much_linear_algebra_do_you_use_on_a_day_to/,d8la5g,how_much_linear_algebra_do_you_use_on_a_day_to,MagneticSpark,0.95,95,2019-09-24 12:31:01,0,37,,"I recently started watching MIT's opencourseware course on linear algebra, and I'm having a bit of trouble grasping concepts like the Spectral Theorem and the Singular Value Decomposition. I get their application in stuff like PCA, but I only have a rough understanding of the underlying principles.For something like the Gradient Descent, I understand that it works by minimizing the error by looking at the gradient and finding the local (global if lucky) minima, but if I had to code implementations to the SVD or Gradient Descent from scratch, I'm not sure I could do it, so I thought I would pose the question in the title to the seasoned veterans.",,
691,https://www.reddit.com/r/datascience/comments/d8r00s/explanation_of_how/,d8r00s,explanation_of_how,SVintern97,0.93,13,2019-09-24 20:10:22,0,5,,I'm currently an intern who's never really did formal data science projects. I am currently using these tools but not sure how they're all connected to one another.dbeavermssql and sqlserverjupyterdockeranconda,,
692,https://www.reddit.com/r/datascience/comments/d8pkg0/best_way_to_model_sports_outcomes_using_regression/,d8pkg0,best_way_to_model_sports_outcomes_using_regression,Low_end_the0ry,0.88,12,2019-09-24 18:27:05,0,15,,"I'm trying to get started with predictive modeling on basketball outcomes and am confused on what's the best way to model the outcomes. One thing I'm having issues conceptualizing is how to model head-to-head matchups.For example, if the Lakers are playing the Celtics, could I just use a linear model to predict some a rating for each team, e.g.,lakers_rating ~ shooting + turnovers + rebounding + free_throw_rate,   celtics_rating ~ shooting + turnovers + rebounding + free_throw_rate,  and then comparing the two ratings? Or maybe I could use a logistic regression and get a predicted probability of winning for each team? e.g.,lakers_prob_win ~ lakers_shooting + lakers_turnovers + lakers_rebounding + lakers_free_throw_rate  + celtics_shooting_def + celtics_turnovers_forced + celtics_def_rebounding_ + celtics_ft_rate_allowed?Extra: Another thing I'm trying to figure out is how to take into account previous matchups between the teams, as well as previous matchups between the individual players on the teams.I know this might be overly simplistic, but I'm just trying to figure out different ways to conceptualize the problem. Much thanks!Note: This is for a specific personal project, I'm not interested in beating Vegas.",,"Tooling,"
693,https://www.reddit.com/r/datascience/comments/d8wts9/question_logistic_regression_to_predict/,d8wts9,question_logistic_regression_to_predict,Ceedeekee,1.0,2,2019-09-25 04:00:23,0,5,,"I've been doing kaggle for about two months with my first entry being Logistic Regression to solve the titanic with ""OK"" accuracy.This time I am trying to predict the probability that the ferry is late based on: time-series (by the minute) of traffic, the Trip endpoints, the vessel name, the day of the week, time of departure and our target: Delayed (0 or 1).I am using a logistic regression and am worried about a few things, namely overfitting and having too many categorical dummies as my predictors.For example my X consists of :All the dummies for [Trip Endpoints, Vessel Name, Day]. This results in a dataframe with 39 additional binary value columns.A moving average of traffic for the departure time.Now as the post title implies, the competition requires me to predict the probability of a delay. I did a bit of general research last night that led me to the roc_aux_score and an ROC graph as a good benchmark for my model.My score began at .58 with solely my traffic SMA and I worked it up to .69 using all the above predictors. Now my question is can I use ROC score as a relevant metric? I am trying to predict probabilities here, not a binary outcome, which leaves me wondering how I can know what is a False Positive or False Negative? My second question is: if so few categorical fields return so many dummy columns, is using all of them unwise even if my roc score increases?",,
694,https://www.reddit.com/r/datascience/comments/d910em/what_is_the_question_that_data_science_tries_to/,d910em,what_is_the_question_that_data_science_tries_to,boatwatcher,0.17,0,2019-09-25 11:47:54,0,5,,"Hi all,Been following the sub on and off for about a year now after having caught the general DS-bug that has been spreading in the academia and the industry.  I consider myself as an enthusiastic observer of data science rather than even a hobbyist, as my main academic focus is in economics.Therefore, naturally, my critique comes from a social science viewpoint. What is the problem that you, as a data scientist, are trying to solve?The bandwagon effect does't seem to disappear anywhere from the schoolyard, it just masks itself better in the workplace. And this shouldn't come as news to you that these days everyone wants to do machine learning and neural networks. So just like in the schoolyard, suddenly everyone's in in the latest fad, but half of those only because everyone else is too and the new Air Maxes bought them a second in the spotlight during recess. The equivalent of this in the field of data science shouldn't need elaboration, but I dare to say that the ones in the back of the wagon are the most dangerous ones; as they themselves don't have a strong view of the bigger picture, they lend their skills to the agendas of those who do.There's a paradigm in political economy, that the more things are (attempted to be) quantified to guide decision making, the more fascist the system becomes. Quantified Self is already a thing. Quantified Others is also a thing, as the Cambridge Analytica/Facebook/Trump campaign mess showed (facebook has on average 5000 data points on every american citizen - need I even mention this in this sub?). I worked in economics research for a while and my supervising professor had a paper where they applied machine learning (talk about the bandwagon effect) to figure out whether heart rate can predict economic decision making.So if you're concerned with predicting human behaviour in your daily DS tasks (as many of you are), what's the consequence? Knowing what people are likely to do is certainly valuable in a profit-maximising economy, but what about on a societal level? Should the government predict who benefits most from monetary incentives to attend university, based on family factors and other columns of data they have? It'd certainly make the invested money yield the most, so why not?To go back to the paradigm I presented earlier, the more we rely on this kind of quantified advice, the less the individual has room for movement and the more has been already decided for them. What if we found a gene that would be a strong predictor of impulsiveness and had that gene information of every citizen? We'd be fools for not taking this into account in health care policy and web shop algorithms, right? That companies probably already know the citizens better than the governments is troublesome because the companies are driven by profit, not by moral considerations (be it equality, wellbeing or individual freedom).I don't want to get into discussion about what if the models have bias and the siloing-up of worldviews following recommender algorithms. They are obvious problems that the field faces, but are secondary to moral considerations I present here.I may appear as a warmongerer to some and seem to having omitted all the real opportunities the new science provides. I'm NOT saying there is no place for data science - I'd just like to hear from within the field what that place is perceived to be.",,
695,https://www.reddit.com/r/datascience/comments/d8muxc/data_science_and_politics/,d8muxc,data_science_and_politics,TastyxJujube,0.88,12,2019-09-24 15:00:32,0,20,,"Good Morning r/datascienceI wanted to get your various opinions on career options within the political world as a data scientist. I’m currently a comp sci grad working in the consulting world and am continuously drawn toward working in the political realm, perhaps working on campaigns or behind the scenes doing poll analysis leveraging data science.My question for you is, does this make sense as a career option? Would this be something you would recommend going to school for, or do you think there would be openings that can be acquired via bootcamp?I appreciate any insight from any angle people have on this.",,
696,https://www.reddit.com/r/datascience/comments/d8suk4/interactive_staffingcapacity_model/,d8suk4,interactive_staffingcapacity_model,engineeringgirl123,1.0,3,2019-09-24 22:22:50,0,5,,"Hello!I am trying to figure out the best platform or tool to use to build a highly interactive capacity model for a service organization. I would need to know all locations we have, what they service, the volumes, associated costs. And be able to run different scenarios based on moving volumes around, changing locations, etc.Has anyone done something similar? What tool did you use?",,
697,https://www.reddit.com/r/datascience/comments/d8tch3/shared_work_metric_reuse_lineage/,d8tch3,shared_work_metric_reuse_lineage,clapper_never_lied,0.75,2,2019-09-24 22:58:59,0,6,,"Hi all - what are you using/recommend to use to encourage teams to:1 - reuse logic; git is a candidate but i am looking for something more like an online search and navigation mechanism that when analyst has a working logic set, the result is published and can easily pulled in for reuse2 - along with 1, I would like complete lineage/transformation for every data element. if transform of a transform of a transform, i want to be able to see whole path, graphically3 - easily ""productionalized"" logic - to take an analytic metric or dataset, and without creating something not unlike spreadmart or access database spaghetti, to be able to hand a canned easily self documenting process to someone else to schedule it to be produced on a regular basis with industrial repeat-ability and ease of maintenance.I was thinking mulesoft or something similar, but curious to know what you are doing in a massive corporate environment to achieve described.Or am i just dreaming?",,"Discussion,"
698,https://www.reddit.com/r/datascience/comments/d8dmds/just_finished_a_tough_data_prep_job/,d8dmds,just_finished_a_tough_data_prep_job,blinkOneEightyBewb,0.93,90,2019-09-23 23:59:21,0,44,,"The set had 80 total predictor variables and around 10,000 observations. I’ve been working on cleaning and engineering this for a few weeks during my free time in school. I haven’t prepared a data set with this many variables before.In the industry would this have been broken up across multiple people on a team?Realistically if I was working 8 hrs a day I probably could’ve finished in a week or so. Do I need to just keep practicing and getting faster or am I rushing?",,"Discussion,"
699,https://www.reddit.com/r/datascience/comments/d8okt6/question_references_for_cluster_analysis_on/,d8okt6,question_references_for_cluster_analysis_on,godmorpheus,1.0,2,2019-09-24 17:14:10,0,3,,"Can someone recommend me a book or something about cluster analysis for longitudinal data? I only found some articles about it while using R packages, which is good! But I wan't to know the theory behind it.Thanks",,"Education,"
700,https://www.reddit.com/r/datascience/comments/d8ioa7/is_there_a_curated_list_of_ai_project_i_can_test/,d8ioa7,is_there_a_curated_list_of_ai_project_i_can_test,bodytexture,0.83,8,2019-09-24 07:18:26,0,4,,,,
701,https://www.reddit.com/r/datascience/comments/d8jh21/5g_tower_locations_with_jsoncsv_datasets/,d8jh21,5g_tower_locations_with_jsoncsv_datasets,ihazshuvel,1.0,7,2019-09-24 08:50:28,0,3,,"My group is working with 5G tower/node locations to find predictive analysis. Anyone know any where/any body with access to that data? Lats/Longs and quantities per city would be great.I don't want to brute force it by scraping numerous sites to make my own csv file just to gather limited data, so my team is reaching out for any additional advice or to be guidance. Thanks!",,
702,https://www.reddit.com/r/datascience/comments/d8975r/as_a_data_scientist_do_you_use_type_hinting/,d8975r,as_a_data_scientist_do_you_use_type_hinting,alphaharris1,0.83,45,2019-09-23 18:51:08,0,21,,"For data science–and for the data scientist– type hinting is invaluable for a couple of reasons:It makes it much easier to understand the code, just by looking at the signature, i.e. the first line(s) of the function definition;It creates a documentation layer that can be checked with a type checker, i.e. if you change the implementation, but forget to change the types, the type checker will (hopefully) yell at you.Of course, as is always the case with documentation and testing, it’s an investment: it costs you more time at the beginning, but saves you (and your co-worker) a lot in the long run.Note: Type hinting has also been ported to Python 2.7 (a.k.a Legacy Python). The functionality, however, requires comments to work. Furthermore, no one should be using Legacy Python in 2019: it’s less beautiful and only has a couple more months of updates before it stops receiving support of any kind.The hello world of type hinting is# hello_world.py 
def hello_world(name: str = 'Joe') -> str:
     return f'Hello {name}'
We have added two type hint elements here. The first one is : strafter name and the second one is -> strtowards the end of the signature.The syntax works as you would expect: we’re marking name to be of type strand we’re specifying that the hello_worldfunction should output a str. If we use our function, it does what it says:> hello_world(name='Mark')
'Hello Mark'
Since Python remains a dynamically unchecked language, we can still shoot ourselves in the foot:> hello_world(name=2) 
'Hello 2'
What’s happening? Well, as I wrote in the introduction, no type checking happens at runtime. So as long as the code doesn’t raise an exception, things will continue to work fine.What should you do with these type definitions then? Well, you need a type checker, or an IDE that reads and checks the types in your code (PyCharm, for example).Type checking your programThere are at least four major type checker implementations: Mypy, Pyright, pyre, and pytype:Mypy is actively developed by, among others, Guido van Rossum, Python’s creator. Pyright has been developed by Microsoft and integrates very well with their excellent Visual Studio Code;Pyre has been developed by Facebook with the goal to be fast (even though mypy recently got much faster);Pytype has been developed by Google and, besides checking the types as the others do, it can run type checks (and add annotations) on unannotated code.Giovanni Lanzani is the director of learning and development at GoDataDriven. Check out the code --  Type Hinting for Data Science.",,"Tooling,"
703,https://www.reddit.com/r/datascience/comments/d89frd/my_cofounder_garry_tan_interviewed_the_creator_of/,d89frd,my_cofounder_garry_tan_interviewed_the_creator_of,kn0thing,0.85,36,2019-09-23 19:07:11,0,2,,"https://www.youtube.com/watch?v=33FeV87Q9Z4Jake Klamka created Insight Fellows program, a free fellowship that has brought together the world's best scientists and then helps them get to the top of their fields at the best tech firms in the world.The program started with just 8 fellows 8 years ago and has now grown to a program that graduates 1,000 alumni per year in 6 cities and 8 different disciplines— not just data science but data engineering, AI, DevOps, Health Data, Data Product Management, Crypto and Security fields too.Figured you all would be interested to learn more about it. Let me know if you have any questions and Garry (u/foilfoil) will be in the comments!",,
704,https://www.reddit.com/r/datascience/comments/d8j5wr/map_geographic_center_a_seemingly_easy_request/,d8j5wr,map_geographic_center_a_seemingly_easy_request,saltinthedesert,1.0,3,2019-09-24 08:13:50,0,9,,"I’m interested in hiring someone who can design/program a tool/API that finds the geographic midpoint for a large list of addresses. Similar to what all the midpoint websites do for 2 locations, but for much higher quantities. We’re a non-profit looking for the best place to put our future building space based on member addresses.The only websites I can find that had this functionality previously have been shut down.Happy to answer questions. Thanks!",,"Projects,"
705,https://www.reddit.com/r/datascience/comments/d85bir/problems_faced_by_linear_regression_with_day_to/,d85bir,problems_faced_by_linear_regression_with_day_to,dash_365,0.79,63,2019-09-23 13:39:14,0,49,,"Hey guys,I have written a small blog post on problems linear regression models are vulnerable to with trivial real world analogies. Kindly read it and provide feedback if you have the time.https://medium.com/@aspiring_data_scientist/why-is-knowing-scikit-learn-not-enough-for-a-data-scientist-82e7fb05bc74",,"Education,"
706,https://www.reddit.com/r/datascience/comments/d8dyez/downloading_plotly_graphs_as_static_images/,d8dyez,downloading_plotly_graphs_as_static_images,rooty94,0.83,7,2019-09-24 00:23:03,0,3,,I'm trying to download some plots that I made in Plotly for a publications. If I export as a PNG using the option in the interactive plot it exports in a low resolution.I have heard that [Orca] (https://github.com/plotly/orca#installation) can be used to download plots. However I really don't understand the installation instructions on the link. Can anyone help me out please?,,
707,https://www.reddit.com/r/datascience/comments/d8bzgk/questions_about_my_first_kinda_data_science/,d8bzgk,questions_about_my_first_kinda_data_science,parth2480,0.92,10,2019-09-23 21:59:10,0,23,,"Hey everyone,My supervisor/manager has asked me to use the data we have to predict how an area  or a sector in an area will perform. We have a lot of 'shallow' financial and location data on a lot of businesses across most sectors (store sales, online sales, transaction values, transaction frequency and demographics being the main ones).My concern is that since this is my first project relating even a bit to data science, I don't want to underperform as I plan to get a graduate job in data science. I have some knowledge of logistic regression KNN, DBSCAN etc but I want to apply it.I know about the general methodology, have a clear goal, clean the data, build a model if necessary, evaluate and improve. Are there any things I should be particularly careful about considering the type of data I'm working with?Should I be concerned about integrating with other datasets (eg. Unemployment)?Edit: thanks for all the great answers. It helped me better understand how I should approach this. Also if anyone has comments that were missed, let me know but I'm going to sleep but I'll definitely get back to you in about 8 hours.",,"Discussion,"
708,https://www.reddit.com/r/datascience/comments/d880lv/tlstm_new_advancements_in_deep_learning/,d880lv,tlstm_new_advancements_in_deep_learning,t3l3tubie,0.85,19,2019-09-23 17:24:48,0,0,,,https://github.com/mkrupczak3/T-LSTM,
709,https://www.reddit.com/r/datascience/comments/d8bqn7/is_it_reasonable_to_perform_feature_selection_of/,d8bqn7,is_it_reasonable_to_perform_feature_selection_of,cdlm89,0.92,10,2019-09-23 21:41:30,0,17,,"I am unsure of whether performing feature selection on categorical and continuous features independently (in the case of hundreds of features) would lead to a suboptimal model, compared to if feature selection was done jointly with both types of features.The purpose of performing model selection independently would be to reduce the analytical and experimental complexity for the first iteration of model development. Follow-up iterations could take the reduced set of features and perform feature selection jointly over both types of features that remain after independent feature selectionThis of course could be tested empirically which I don't have the time to do at the moment. The only literature I found that discussed selecting categorical and continuous features independently was here, but it is discussed the context of hybrid feature selection.Any thoughts or pointers to literature would be most appreciated!",,"Discussion,"
710,https://www.reddit.com/r/datascience/comments/d8ipv6/is_there_a_way_to_search_the_internet_for/,d8ipv6,is_there_a_way_to_search_the_internet_for,TurboEntabulator,0.38,0,2019-09-24 07:23:19,0,6,,"For example:""An increase of xxx%""Where x is a digit. I'm looking for 3 digit numbers followed by a percentage, with ""an increase of"" right before the numbers.",,
711,https://www.reddit.com/r/datascience/comments/d86ytr/tasked_with_cleaning_data_of_over_4_million_car/,d86ytr,tasked_with_cleaning_data_of_over_4_million_car,i160069,0.83,16,2019-09-23 16:04:09,0,33,,"My dataset contains ads of cars from 4 different websites and the most problematic feature to clean is the car badge. The car badge is a.k.a the car variant. For example: Toyota Corolla Levin SX, Toyota Corolla Levin ZR are two different badges of the same car.The problem is that the badge field is almost always a text input box that users fill manually and that gives rise to some very mind-bogling entries too. There are a lot of entries where people have actually entered yes/no in the field and have left it blank too.My data contains at least 1615 different car models and each model can have >= 0 different badges. What I'm currently doing is to run the SQL query 'select DISTINCT badge from table where model_id = xxxx' in a loop and save the output in separate text files by model number. This gives me 1615 files that I will need to inspect individually as car models usually have no similarity between them.After going through most of the files, I've realized that common errors are yes/no, blank fields, upper/lowercase mixtures, unnecessary hyphens (SRT-V has the same meaning as SRTV), 4WD and 4X4 being interchanged.All of these errors can be fixed by Regex but, there are entries which may not look wrong but actually do not exist (like G6LPG).To properly eliminate anomalies, I fear that I will have to go through every file and crosscheck every badge by doing a search on it to confirm how the manufacturer actually writes it. Is my fear correct or am I missing something stupidly simple that can make my task much shorter?",,"Discussion,"
712,https://www.reddit.com/r/datascience/comments/d89htq/why_do_we_need_to_convert_geo_coordinates_into/,d89htq,why_do_we_need_to_convert_geo_coordinates_into,sarvesh2,0.5,0,2019-09-23 19:11:00,0,6,,,,"Discussion,"
713,https://www.reddit.com/r/datascience/comments/d7qx0r/do_data_science_organisationsteams_recruit_people/,d7qx0r,do_data_science_organisationsteams_recruit_people,MrLongJeans,0.94,138,2019-09-22 16:10:55,0,48,,Basically you are your company's king of the Excel users. You self-train to SQL server and run your own mini data stack from the company's data-marts to front-ends in Power BI. Like ultra mini stacks on a high powered desktop machine. You learn basic bitch 'conversational' Python and SQL language.Is that enough to enter data science teams at a post-Excel company?  Or do data scientists laugh off applicants who come from Excel-centric businesses?  You know what I mean by that--we've all seen organizations that are stubbornly clinging to doing 95% of their work in Excel in 2019.Edit: I imagine numerous data analysts are asking themselves this question.  Bosses don't seem to realize that they're increasingly asking analysts to do data science tasks like wrangle data too big for MS business software.Edit: Have a social science/research statistics Master's degree.,,
714,https://www.reddit.com/r/datascience/comments/d892dz/can_you_recommend_any_good_books_on_arima/,d892dz,can_you_recommend_any_good_books_on_arima,vigbig,0.5,0,2019-09-23 18:41:35,0,2,,,,"Discussion,"
715,https://www.reddit.com/r/datascience/comments/d7zf9p/simplifying_kaggle_competition_for_hs_science_fair/,d7zf9p,simplifying_kaggle_competition_for_hs_science_fair,squirorb,0.92,10,2019-09-23 03:06:33,0,15,,"I'm doing a high school science fair as a sophomore this year, and I was interested in doing something public health related, and since I knew of the field of data science I checked out Kaggle for inspiration, coming across this and this regarding detecting diabetic retinopathy, which seems like a perfect project, and relevant to me given my family's history of eye disease.So, I know how to code but I wouldn't consider myself very good yet. In addition, I don't know the required math(calculus, linear algebra, statistics), which I know are huge. I think it is possible for me to get into stats, but definitely not at a super high level where calculus will be needed. I'm new to the field, as can be seen.Since my only thing is some programming knowledge, could it be possible for me to do a science fair project with a modified version of this as my project? I'm curious whether this can be simplified down into something more basic, but can still somewhat do its job since I don't have enough knowledge to really take on the competition as a contender. I think that it's very possible that I'm being naive/dreaming, so I'd apologize for that, and if so I shall work with something else.I look forward to your responses; thank you in advance.",,"Projects,"
716,https://www.reddit.com/r/datascience/comments/d7zd2z/want_to_leave_first_job_in_industry/,d7zd2z,want_to_leave_first_job_in_industry,bayesfordayz,0.83,7,2019-09-23 03:01:40,0,10,,"I worked in IT for a couple years before pursuing a master's in stats. I worked as a graduate research assistant my first year, then interned at a company over the summer. The internship was a bit disappointing; I felt like I wasn't a great fit, and the domain was pretty boring, but I still made the most of it. After the internship finished, they interviewed me for a full time role and converted me to a full time data scientist/statistical modeler. I don't feel like I deserve this role. I feel my manager embellished my internship ""accomplishments"" to the team I interviewed for because he knew the internship was disorganized/lackluster (interns from prior years also thought it wasn't great, so maybe he might look better if I converted to full time?) The interviews weren't even that technical/theoretical, focused mostly on behavioral questions. I accepted it because I knew it was an amazing opportunity.I would much prefer to work part-time or remote. I commute 45 minutes+ each way, my days start at 6AM and I don't get home until 11 because of class (have one more year left in the master's program). I feel like I'm going to burn out and either work (possibly get PIPed) or grad school would suffer.  I'm very grateful for this opportunity and am surrounded by brilliant well-experienced modelers/data scientists, but I'm just not happy. I've networked with other companies that would allow part-time/remote work, but for one company their tech stack  isn't as great (they use SAS, gross) and for the other, the work wouldn't be consistent (more project based), but I'd get more experience with the software engineering side. Those companies are much smaller but I feel like I'd have more opportunities to work on a variety of projects and make an impact rather than support older projects/models like I currently do. If I left my current company, I'd almost certainly be burning a bridge, and that's not a great start to my career.I'd appreciate an objective perspective. I think the right thing to do is to stay with my current company and just suck it up until I finish my master's, but I'm very tempted to leave. If it means anything, I want to get more into the MLE/engineering side.",,"Career,"
717,https://www.reddit.com/r/datascience/comments/d7zzib/how_to_determine_a_binary_variables_threshold/,d7zzib,how_to_determine_a_binary_variables_threshold,Hejeeke12,0.71,4,2019-09-23 03:55:41,0,9,,"I’m trying to create a binary variable in the data set - approved and disapproved are the output of the variableI have approved and disapproved datapoints that each come from one datapoint for a product. If I am trying to determine if the product is approved by customers (considering that a perfect 100% is nearly impossible), how would I go about setting the threshold of what’s considered approved?",,
718,https://www.reddit.com/r/datascience/comments/d7ypuo/my_application_was_good_enough_to_get_into_screen/,d7ypuo,my_application_was_good_enough_to_get_into_screen,rhonda455,0.86,5,2019-09-23 02:06:06,0,8,,They want someone who knows SQL and having advance knowledge of python is a plus. I never mentioned python on my resume but still chosen since I guess it’s just a bonus. My fear is that at the final interview I won’t get chosen cause someone will know both sql and python. I’m teaching myself python as much as possible to learn some basics. What are some tips to overcompensate what I don’t know (python skills),,
719,https://www.reddit.com/r/datascience/comments/d7szeg/im_a_full_time_data_science_recruitment/,d7szeg,im_a_full_time_data_science_recruitment,Iwobisapplejuice,0.71,13,2019-09-22 18:44:33,0,39,,"So I commented on a post on here a few days ago and some people seemed to be interested that I’m a recruiter and had a few questions, so thought I would make a post. I recruit Data Scientists and Machine Learning Engineers for a living and would love to chat to some Data enthusiasts away from the professional bubble. Feel free to ask any questions at all about the market, what recruiters actually do, or what companies really look for in a Data Scientist!",,
720,https://www.reddit.com/r/datascience/comments/d7ybev/making_use_of_indexes_why_dont_they_get_used_more/,d7ybev,making_use_of_indexes_why_dont_they_get_used_more,Astreanna,0.38,0,2019-09-23 01:30:50,0,3,,I've realized that not many people on my team know what an index is and/or how to use them effectively. I find this shocking as they are incredibly useful to quickly understand large amounts of data and find outliers.I'm curious if anyone here makes use of indexes and in what context you use them in? My most recent case is building them into a Bot Traffic Identification Script - to help build weightings for the different traffic verticals.,,
721,https://www.reddit.com/r/datascience/comments/d7pamv/weekly_entering_transitioning_thread_22_sep_2019/,d7pamv,weekly_entering_transitioning_thread_22_sep_2019,datascience-bot,0.91,9,2019-09-22 13:39:54,0,101,,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki.You can also search for past weekly threads here.Posted at 2019-09-22 11:39:54.728752 UTC",,"Discussion,"
722,https://www.reddit.com/r/datascience/comments/d7j5bh/feeling_depressed_about_current_job/,d7j5bh,feeling_depressed_about_current_job,ABZ-Aaron,0.81,39,2019-09-22 02:29:13,0,26,,"So I'm 28, and I have a neuroscience master's degree.I am currently working in a basic Engineering/IT type job.I've started a ""Data Science BSc Apprenticeship"" at a local university. This is 4 years.However... My job isn't a data science job. It's not even a data analyst job. Although there is room in my job for data analysis and maybe ML, I have no real mentor. I decided to do the Apprenticeship as it was essentially free training.I'm working really hard to work my job AND keep up with the apprenticeship. But I just feel like what I'm doing is not going to be worth all the hard work.Any advice? Can I still develop the skills to become a data scientist within the next 4 years, or am I setting myself up for a crisis in my 30s?I'll be honest - my constant worrying about this is really impacting my mental health. I don't sleep properly anymore. I find it hard to enjoy the things I used to (e.g. watching movies).I spend Friday and Saturday nights learning Maths, practicing Python, and reading up on Computer Science fundamentals - yet I still feel a million miles away from where I'd need to be to be considered a data scientist.",,
723,https://www.reddit.com/r/datascience/comments/d7vxk6/d_siraj_apologizes_and_promises_refunds_within_30/,d7vxk6,d_siraj_apologizes_and_promises_refunds_within_30,permalip,0.5,0,2019-09-22 22:20:13,0,0,,Here is the twitter thread,https://www.reddit.com/r/MachineLearning/comments/d7vv1l/d_siraj_apologizes_and_promises_refunds_within_30/,"Discussion,"
724,https://www.reddit.com/r/MachineLearning/comments/d7vv1l/d_siraj_apologizes_and_promises_refunds_within_30/,d7vv1l,d_siraj_apologizes_and_promises_refunds_within_30,permalip,0.89,323,2019-09-22 22:14:57,0,127,"Tech,",Here is the twitter thread,,"Discussion,"
725,https://www.reddit.com/r/datascience/comments/d7v6ir/does_anyone_know_what_a_fullstack_bi/,d7v6ir,does_anyone_know_what_a_fullstack_bi,wild_bill34,0.33,0,2019-09-22 21:25:20,0,9,,I heard someone mention this title for the first time yesterday and I was curious to see if anyone knew what this role was and what day-to-day responsibilities would entail?,,
726,https://www.reddit.com/r/datascience/comments/d7pgic/counting_algorithm_help/,d7pgic,counting_algorithm_help,soundtracking,0.72,3,2019-09-22 13:57:32,0,6,,"Hi all,I am trying to figure out the best method to approach a problem and have been unable to find something by googling!I have a dataset of 140000 records, and up to 58 of these at a time are grouped by a common ID. The 140k records can be any one of a few hundred results. I want to count how many times each result appears in the same group as any other result. Ideally displaying the final counts in a cross-table.To me it sounds simple, but when I sat down to start coding, I realised I had no clue what the most efficient way to approach the task would be!Thanks",,
727,https://www.reddit.com/r/datascience/comments/d74usq/the_requirements_for_these_data_jobs_are_getting/,d74usq,the_requirements_for_these_data_jobs_are_getting,OneSaucyWaffle,0.99,1408,2019-09-21 04:30:26,0,66,,,,"Fun/Trivia,"
728,https://www.reddit.com/r/datascience/comments/d7ixj8/real_data_science/,d7ixj8,real_data_science,BeggarInSpain,0.85,17,2019-09-22 02:13:22,0,21,,"I started with Kaggle, have thrown plenty of algorithms to data and stacked then without much thinking, have chased every point to get as deep into top 10% as possible and I thought this is data science. Until I came into realization that most of the job is spent on data cleaning / preparation and then simple and easily explainable algorithm is what you what to use most of the time.What is your experience?",,"Discussion,"
729,https://www.reddit.com/r/datascience/comments/d7rm93/going_straight_into_data_science_with_an/,d7rm93,going_straight_into_data_science_with_an,UnleashTheWolf,0.5,0,2019-09-22 17:05:48,0,7,,"I live in the UK. If I have a good level of maths and a bachelors degree in engineering, is it possible to land a role as a data scientist straight away?My friend who has been working as a data scientist for a few years now told me that the best route would be to get a job as a data engineer first for 6-12 months while I learn about data and skills like python, as well as continue to improve my maths, then aim to get promoted. This sounds like a solid plan, but if it is possible to go straight into the higher up job then that would be nice.Any thoughts on this?",,"Career,"
730,https://www.reddit.com/r/datascience/comments/d7k6pc/pursue_masters_degree_or_jobinternship_after/,d7k6pc,pursue_masters_degree_or_jobinternship_after,sarjou,0.85,9,2019-09-22 03:58:32,0,24,,"I'm an undergraduate Economics major and I'm debating whether to pursue a master's degree or work after graduating.Current career goal: Data analyst; informing public policy.Background (all beginner level): Python, R, SQL, ArcGIS, STATA, Statistics/Econometrics, Linear Algebra/Calculus. I also plan to learn Tableau and/or Power BI before I graduate.Experience: I've had a couple internships where I mainly prepared reports/summaries about legislation and policies, based on previously published literature/data. I'd say they developed my critical thinking, written communication skills, and gave me experience in the environment I'm interested in (public policy) - but no hands on experience with programming or data. I hope to land an internship with more programming, in the Spring semester. Other than that, I've done a few basic class projects with Python, R, SQL, ArcGIS, STATA, econometrics.My thoughts: I would like to take 1-2 years off after graduation to gain real world experience, but if its unrealistic to be employed in my field with my skill-level, I might as well go straight into a Master's program where I'd study Applied Statistics with a concentration in Data Analysis. However, I was hoping to take time off to work and make sure this is a career path that I truly want.For the seasoned data analysts out there:With current my background, how likely is it that I'll get an entry level job, or at least a paid internship, in data analytics after graduation? Or are most data analyst jobs geared towards individuals with more experience/technical background than me?Are there similar but more realistic positions I could apply for?Do you have any suggestions of alternative paths I could take, or tips on how to make myself more marketable?Thank you so much!",,"Career,"
731,https://www.reddit.com/r/datascience/comments/d7lyn4/roomdemand_for_webscraping_skills_in_data/,d7lyn4,roomdemand_for_webscraping_skills_in_data,PuppyPriest,0.83,4,2019-09-22 06:54:11,0,8,,"I'm wondering how much I should ""invest"" into picking this up as a skill. The benefits of web-scraping for personal use have been abundant, which is why I've spent a decent amount of time getting good at it, but I'm not sure how much I should think about it as a skill for a jobs.I'm wondering whether employers actually look for web-scraping/mining as a useful skill for data-oriented roles and 2) given web-scraping can be a legal gray area (and in some cases prohibited by sites, e.g. Glassdoor and LinkedIn, in their terms of service), especially as seen from a commercial use standpoint, I'm wondering whether it's even a skill you can apply effectively in a job.Insights would be appreciated. Thanks!",,"Discussion,"
732,https://www.reddit.com/r/datascience/comments/d7sm05/make_google_fill_in_the_blanks/,d7sm05,make_google_fill_in_the_blanks,TurboEntabulator,0.29,0,2019-09-22 18:17:51,0,2,,"I'm trying to use the search terms:""***% yoy""""an increase of *** percent""But I still get results showing double digit growth. How can I get search results that show only triple digit growth?",,
733,https://www.reddit.com/r/datascience/comments/d7okd3/how_do_predictive_models_such_as_ann_differ/,d7okd3,how_do_predictive_models_such_as_ann_differ,runnersgo,0.4,0,2019-09-22 12:13:41,0,2,,"Graph models as in models based on graph theory (e.g. nodes and edges).I'm trying to make sense on how models such as neural networks differ from a graph model, especially in a predictive sense.In ANN:'features' are basically represented as some numbers, say 0-1 (e.g. width of height of some flower), or just some labelsthese input values are fed through one or more hidden layers where these hidden layers have some activation functions (i.e. making linear values to non-linear) and send the output to an output layer.depending on the applications, ANN can be either a classification or regression problem solving approach.the more data you have, the better the accuracy.but overtraining the data can cause overfitting making the model inaccurate in a non-linear world.but ANN doesn't necessary need a ""relationship"" between the features.In graph models/ graph theory:'features' are basically represented as nodes and edges.e.g. Stock value (a node) is impacted (an edge) by the negative sentiments coming from China (another node).as the network grows (i.e. more countries are added to the network), the distance between the nodes grows.assume: the further away a foreign country (i.e. a node) is to the US, the lesser impact it has to the US's economy.using some calculations, we can now make some reasonable forecasting i.e. to what degree a foreign country would impact the US economy based on the graph distance.in a sense, large data are not needed as no training is required.What I got from here:ANN:Needs large data.Overfitting may occur.Doesn't need a relationship between the features.Graph:Doesn't need large data.May not have overfitting scenarios (not too sure about this one)Needs a relationship between the features (in a sense ...)I'm not too sure really. Any views, input or others are so welcome!",,"Discussion,"
734,https://www.reddit.com/r/datascience/comments/d7hzxi/version_control_for_data_science/,d7hzxi,version_control_for_data_science,cds_483,0.77,7,2019-09-22 01:06:22,0,9,,Anyone knows any good version control systems for data science applications (Python or R)? I need a tool that can help me do data versioning. I've been using Git until now which is not ideal for the data science use case. Looking forward to your answers!,,"Tooling,"
735,https://www.reddit.com/r/datascience/comments/d7ns1d/unsupervised_learning_on_hybrid_data/,d7ns1d,unsupervised_learning_on_hybrid_data,gauravc2796,0.5,0,2019-09-22 10:34:36,0,4,,"I have a hybrid data that contains 15 categorical data and 4 continuous data.I need to implement a prediction on the data. So as I don't have any labeled data, I need to implement the unsupervised algorithm.Now Using PCA my dimensions reduced to 5 but still it has 3 categorical and 2 continuous data. Now to create a prediction algorithm, I can use KMeans for continuous data or KModes for categorical data, But I couldn't find any algorithm that works on both types of data.Can anyone know any algorithm that works on both the data types for unsupervised prediction?",,"Discussion,"
736,https://www.reddit.com/r/datascience/comments/d7hfa2/data_analysts_and_scientists_did_you_have_to_show/,d7hfa2,data_analysts_and_scientists_did_you_have_to_show,Lilyteal4,0.77,7,2019-09-22 00:25:54,0,18,,Such as the data work you done or any data visualizations? Or is making sure the hiring manager knows what you are talking about is good enough. Do I have to show that I know how to use SQL or tableau,,
737,https://www.reddit.com/r/datascience/comments/d7g3ue/interested_in_coding_a_revenue_management_ai_to/,d7g3ue,interested_in_coding_a_revenue_management_ai_to,bodytexture,0.86,5,2019-09-21 22:49:19,0,3,,,,
738,https://www.reddit.com/r/datascience/comments/d7iscm/can_this_visualization_be_done_in_python/,d7iscm,can_this_visualization_be_done_in_python,the_chosen_one96,0.67,2,2019-09-22 02:03:09,0,6,,,https://www.reddit.com/r/dataisbeautiful/comments/d44kvs/coloring_san_franciscos_streets_by_suffix_oc/?utm_source=share&utm_medium=web2x,"Education,"
739,https://www.reddit.com/r/datascience/comments/d7kwti/is_a_data_manipulation_gallery_that_shows_how/,d7kwti,is_a_data_manipulation_gallery_that_shows_how,xiaodaireddit,0.57,1,2019-09-22 05:07:30,0,4,,"E.g. is there a rosetta code type website that's just focused on data manipulation? E.g. showing how to ""get the first row of each group"" in Python, R, Julia?",,"Discussion,"
740,https://www.reddit.com/r/datascience/comments/d7jzld/getting_a_data_analyst_job_with_low_gpa/,d7jzld,getting_a_data_analyst_job_with_low_gpa,theoneandonlynathan9,0.43,0,2019-09-22 03:39:41,0,8,,"I'm in my 3rd year as a BSc in Math and Stats at a top 2 university in Canada. My GPA is really low, I'm doing my best to get it up in my last 2 years of school so that I could hopefully go to graduate school, but if that doesn't happen I was gonna become a data analyst. Do you think companies will care a lot about my low GPA (2.3). Also, will I have an easier time finding work in the US vs Canada? What can I do to boost my chances of getting an internship in the summer (or is it a lost cause)? Thanks!",,
741,https://www.reddit.com/r/datascience/comments/d7itb3/2nd_year_college_student_go_to_aws_initiate/,d7itb3,2nd_year_college_student_go_to_aws_initiate,NotAnNFLGM,0.33,0,2019-09-22 02:05:23,0,2,,I am a 2nd year in Uni and plan to go into DS or something involving predictive modeling as a career. I only know a little bit about cloud services (never used them (besides Google Colab) but know how they work).Is AWS initiate worth attending given my background?,,"Networking,"
742,https://www.reddit.com/r/datascience/comments/d7fdat/data_science_path_course_codecademy_vs_data_quest/,d7fdat,data_science_path_course_codecademy_vs_data_quest,Dota2player111,0.6,1,2019-09-21 21:54:47,0,13,,"Hello everyone,I am an aspiring data scientist and seriously considering purchasing premium membership to complete data scientist path in Codecademy or Dataquest. The question is which one has a better curriculum? Codecademy premium membership seems quite a bit cheaper than Dataquest but it looks like they do not go over R which kind makes me concerned. On the other hand, they have been in business for 7 years and perhaps are more credible.Any advice would be really appreciated. Thanks!",,"Education,"
743,https://www.reddit.com/r/datascience/comments/d6wgmp/i_attended_a_bootcamp_career_day_through_work_and/,d6wgmp,i_attended_a_bootcamp_career_day_through_work_and,jambery,0.96,185,2019-09-20 17:23:05,0,69,,"I come from a traditional background (B.S. in Math/Econ, M.S. in Statistics) before starting my first DS job and like many of my other peers, have looked down upon the structure of boot camps. Recently through work I was invited to attend a career day where 20 new bootcamp grads presented their capstone project. I went with the goal of possibly opening up my viewpoint on bootcamps, and here are ultimately my thoughts.There are some bootcamp people who have very advanced degrees, and are using it to bridge the gap between academia and industry.Out of 20 people, 3 had a M.S. and 2 had a PhD. I definitely noticed a more thorough approach in their capstone projects (i.e. carefully deciding on which models to use, understanding their data, understanding model outputs, and effortlessly conveying to the audience what their results produced.) These were definitely the strongest projects, and with their knowledge in academia plus skills like Python, AWS, etc. taught in the bootcamp will most likely land jobs.There seems to be a large disconnect between what Data Science is in a bootcamp and Data Science in real life.15/20 projects involved Computer Vision, Audio/Image Processing, or NLP. Nearly everyone used pre-trained deep neural nets, word2vec, etc. and just applied their own datasets (often Kaggle sets) and nonsensically add/removed layers to fine tune their model results. Most of the presentations revolved around if their results were cool or not, and this is a very dangerous approach to DS, as:You will most likely not be doing deep learning after your bootcamp. This sets an unrealistic goal.Some fed their neural nets completely biased datasets, and it was clear that the results were biased as well and they did not realize thisIt was clear that some people did not understand how they work at all, and were just interested in the results and applications. This leads me to:The fundamentals of Machine Learning and Statistics seemed to be ignoredNearly all of the bachelors level presentations used extremely clean datasets from Kaggle and were essentially cookie cutter projects based off of each other. There was almost no discussion on understanding feature relationships, feature engineering, feature importance, missing value imputation, bias, etc. (the few that did do it stood out to me very well.) Everyone jumped to the strongest models first (deep neural nets, XGBoost) without trying simpler ones to see if it would solve their question.All in all, I can see why bootcamps have their appeal (why do a 2 year MS or a 4-6 year PhD when I can land a job in 12 weeks?) and I do believe that they could land jobs in certain places (such as roles that are glorified analysts, basic data engineering, or the modeling is cookie cutter.) However in an environment where businesses are trying to solve unique and tough problems that highly impacts the business, a bootcamper may fail as they don't have the sound fundamentals as someone who has spent years studying the field of ML.EDIT: I also asked around, and the rate for people landing ML jobs after bootcamps are about 25%.",,
744,https://www.reddit.com/r/datascience/comments/d7emm3/what_would_you_consider_realistic_expectations_of/,d7emm3,what_would_you_consider_realistic_expectations_of,fread9999,0.5,0,2019-09-21 20:59:35,0,8,,"My manager hired two entry level data analyst and put them under me.  They both have 0 work experience , but MS in computer science.  I manage 8 people, but I feel the expectation my manager has on these two employees are unrealistic and they are being treated as full fledged data scientist, rather than the entry level data analyst positions they were hired for.My Expectation of Entry level AnalystMy expectation of two kids with 0 years experience but MS in CS would be that they would do some basic reporting, queries, and some basic atleryx workflows.  They would also be able to at times be able to do ad hoc trend analysis and communicate their findings.Managers ExpectationsMy manager is asking them to do what I consider ""moderately difficult modeling"" .  For example, ""look a like models"" and predictive analytics such as looking at the steps the customer has taken on a web page and predicting which of those customers that did not buy a product, are mostly likely to return and buy a product.IssueThe reason I care about this is because I manage 8 people and the time I have to spend on these two employees assignments is almost the entirety of my week.  They have never pulled data in a work environment and are having to deal with a huge array of datasources and aggregating them, extremely dirty data, API Calls to just get to the data to even do their work.  Then these two kids with 0 experience with digital advertising or modeling in a work environment have to build out these predictive models.QuestionsAm I being too lenient in my expectations? Should I be expecting more?  Is my manager being unreasonable in his?If my manager is being unreasonable , how would you best communicate this?  I feel like the gap between his and my expectations is extremely large",,"Career,"
745,https://www.reddit.com/r/datascience/comments/d7e2o6/interview_with_welds_main_contributor/,d7e2o6,interview_with_welds_main_contributor,unbalancedparen,0.5,0,2019-09-21 20:17:29,0,0,,,https://notamonadtutorial.com/weld-accelerating-numpy-scikit-and-pandas-as-much-as-100x-with-rust-and-llvm-12ec1c630a1,"Tooling,"
746,https://www.reddit.com/r/datascience/comments/d7akki/projects_torchdata_implement_map_cache_filter_etc/,d7akki,projects_torchdata_implement_map_cache_filter_etc,szymonmaszke,1.0,2,2019-09-21 15:36:07,0,0,,"**Hi r/datascience **,(and sorry for failing flare, not used to this :( )What is torchdataI would like to present you a new open source PyTorch based project (torchdata) which extends capabilities of torch.utils.data.Dataset by bringing map, cache and other operations known from tensorflow.data.Dataset (and actually a little more than that).All that with a single line of code: super().__init__()For more, check documentation or github repository.Functionalities OverviewUse map, apply, reduce or filtercache data in RAM or on disk (even partial caching, say first 20% RAM and the rest on disk)Full PyTorch's Dataset and IterableDataset support (including torchvision)General torchdata.maps like Flatten or SelectConcrete torchdata.datasets designed for file reading and other general tasksExampleCreate image reading dataset  import torchdata
  import torchvision


  class Images(torchdata.Dataset): # Different inheritance
       def __init__(self, path: str):
          super().__init__() # This is the only change
      self.files = [file for file in pathlib.Path(path).glob(""*"")]

  def __getitem__(self, index):
      return Image.open(self.files[index])

  def __len__(self):
      return len(self.files)
map each element to torch.Tensor and cache() everything in memory:  images = Images(""./data"").map(torchvision.transforms.ToTensor()).cache()
concatenate with labels (another torchdata.Dataset instance) and iterate over:  for data, label in images | labels:
      # Do whatever you want with your data
Installationpip is the easiest of course:    pip install torchdata
You can also use nightly releases (torchdata-nightly) or GPU/CPU Docker based images (check documentation). Hopefully conda will be released soon as well, stay tunedBTW. You can also checkout torchfunc, I plan to make a separate post about that in a week or so.Thanks for reading and checking out :D",,"Projects,"
747,https://www.reddit.com/r/datascience/comments/d78r8o/as_a_research_master_of_economics_student_what_do/,d78r8o,as_a_research_master_of_economics_student_what_do,Miriel18,0.71,3,2019-09-21 12:20:35,0,1,,"Hello everyone,I  am research master of economics student in one of the leading universities in Europe, during my bachelor I took two  courses about R and I have two short internship experience(each of them  was 2 months) and my responsibilities can be considered as 'data  analyst' who uses R. During the first year of the master I took three  econometrics courses in which we focused on linear regression, logistic  regression, time series and panel data. Hence, I believe that my  econometrics knowledge and background are good.In the second year, I will take two data science courses in which we go through  Elements of Statistical Learning and Introduction to Statistical  Learning books, plus I will also take two micro-econometrics courses, one is theoretical and the other is applied.So,  do you think that this background is enough for being data scientist? I  believe that I should experience more in the application aspect,  especially for coding. What should I do more in order to survive in the  industry? Do I need learn Python, my opinion is that improving my R skills will be more efficient than learning Python from knowing nothing, is this true?Your comments and suggestions are more than welcomed and very  valuable for me..Thank you.",,"Education,"
748,https://www.reddit.com/r/datascience/comments/d766tt/what_programming_tools_created_this/,d766tt,what_programming_tools_created_this,Hubbardia,0.84,4,2019-09-21 06:47:48,0,8,,http://157.249.177.25:3838/dse4KSS/,,
749,https://www.reddit.com/r/datascience/comments/d79oa7/what_is_data_science_and_what_do_data_scientists/,d79oa7,what_is_data_science_and_what_do_data_scientists,mahtabalam93,1.0,1,2019-09-21 14:07:27,0,0,,,https://www.scientificworldinfo.com/2019/09/data-science-and-data-scientist-challenges-and-opportunities.html#.XYYSNUhPDiw.reddit,"Education,"
750,https://www.reddit.com/r/datascience/comments/d75ap9/data_science_data_engineering_higher_compensation/,d75ap9,data_science_data_engineering_higher_compensation,bigchungusmode96,0.87,6,2019-09-21 05:14:02,0,5,,"I know that there are a decent amount of data scientists with CS backgrounds, but if an individual has the experience & skills to do both data science and data engineering does that usually lead to higher compensation?Data science and data engineering are usually two separate positions, but do you also think some employers would fill both positions with the same said individual?",,"Career,"
751,https://www.reddit.com/r/datascience/comments/d79inl/how_do_you_improve_your_analytics_and/,d79inl,how_do_you_improve_your_analytics_and,runnersgo,0.67,1,2019-09-21 13:50:46,0,1,,"Long story short:Boss wanted to see the initial interpretation of the data gathered after 1 weekHe only had 5 mins to see them - must make sense to him - thankfully, stored all the data properlyAggregated all the data - data were basically some timeseries data - some categorical data also existed which were plotted on a piechart or a histogram.Did all the aggregation and visuals within 15-20 mins. Pasted on power pointPresented to the boss - he's okay with it - he did ask, ""but, on one of your slides, I've no idea what 50% there means"", insinuating or hinting that he didn't know how I came up with the figure - but 5 mins passed, he said thanks and went off his wayI was somewhat disappointed with myself, but in any way, in retrospect, what ""I think"" I did wrong were:Not explaining those percentages on a footnote - those sort of questions can be handled by some mini footnotes I believeNot planning for a reactive strategy - I knew this was coming, I should have made some effort to make a ""data story"" out of the gathered data from the first week of data gatheringWhat do you guys think? Any inputs of my scenario are highly appreciated!Also, how do you manage/ improve your analytics and visualisations when you're in a time crunch?",,"Discussion,"
752,https://www.reddit.com/r/datascience/comments/d7b7n5/diskframe_can_be_more_epic/,d7b7n5,diskframe_can_be_more_epic,xiaodaireddit,0.25,0,2019-09-21 16:31:45,0,0,,,http://diskframe.com/articles/more-epic.html,"Tooling,"
753,https://www.reddit.com/r/rstats/comments/d7b77x/diskframe_can_be_more_epic/,d7b77x,diskframe_can_be_more_epic,xiaodaireddit,0.8,12,2019-09-21 16:30:46,0,6,,,http://diskframe.com/articles/more-epic.html,
754,https://www.reddit.com/r/datascience/comments/d7756u/open_ai_gym_personal_setup/,d7756u,open_ai_gym_personal_setup,vineetverma_it,0.5,0,2019-09-21 08:40:36,0,0,,"Hey guys...I am new in this forum so don't know if this goes here but...I saw the openAi documentation recently, and was wondering if I could set it up in my local laptop or some cloud vm to try my own experiments...Is it even possible..??If yes, the. Is there any guide on its installation...??The documentation was quite short and it was not clear to me how i could achieve the above",,"Projects,"
755,https://www.reddit.com/r/datascience/comments/d734dd/socialbehavioral_science_jobs/,d734dd,socialbehavioral_science_jobs,Siba911,0.72,3,2019-09-21 01:48:34,0,3,,"I haven’t integrated into the data science realm just yet, but I am looking to transition to essentially the same thing in the military and am working my MS in the field. I really enjoy what data science and analysis is all about, but I’d like to IDEALLY transition to a DS job within a behavioral/social science organization when I transition out in about 5 or so years.Pay is very important to me. Not because I personally care for money, but i have a wife and four kids and the military compensates very well for Officers and there are very many benefits when it comes to insurance.My questions about DS jobs for social/behavioral sciences are:Do they pay about as well as others?Are they far and few between jobs in this field?Is there any preference to those who have experience within psychology/sociology etc. over your regular data scientist?",,"Career,"
756,https://www.reddit.com/r/datascience/comments/d77lu3/can_i_write_a_paper_when_i_undergraduate_student/,d77lu3,can_i_write_a_paper_when_i_undergraduate_student,ikibinyirmiyedi,0.25,0,2019-09-21 09:41:15,0,2,,This is my final year at university. My major is computer engineering and i have graduation project. I have a lot of interest in academy. I want to write a paper for my happiness and it will give me the opportunity to do my masters in good schools. Also i've part-time job at a start-up company as a data science intern. İ've passionate about data science. Actually i've passionate computer science areas where mathematic exist. So; I know this is a general  question but can i write a paper? What are steps I need to take for this? How can I find a good idea? I guess I need some motivation. Any help and suggestion will be appreciated.,,"Education,"
757,https://www.reddit.com/r/datascience/comments/d6rrk7/went_to_interview_for_a_data_scientist_position/,d6rrk7,went_to_interview_for_a_data_scientist_position,lycan2005,0.78,31,2019-09-20 10:12:06,0,27,,"The manager's interpretation of the job is basically,Data manipulation (from various sources)Take data output from 1 and display it, make some required prediction.Well, technically he is not wrong, but i think he kinda over simplify the whole thing.I asked some questions to the manager, just to understand more about his organization and the environment,Any team members under him handle data transaction between their suppliers and his organization? (Answer: None)Did they use any standardized test platform, proprietary or open source? (Answer: No, non-standard test platform)How many team members, all product engineers? (Answer: close to 20, yes)What tools they are using to do product analysis? (At this point, he didn't want to answer my questions, he then proceed to tell me his vision of automated production floor, importance of data visualization, etc)I didn't follow up with this position in the end. I think he got a bigger problem to solve first, which is establishing a proper data layer between his suppliers and his organization, before thinking about how to use all these data for analysis. You can't build a house and expect water can magically flow into the house without all the pipes right?Anyone currently worked as a data scientist? I'm looking for some insight, what is the actual work that data scientist take care of, to what extend?I'm currently a software dev trying to get into data science field. This is not the first data science job i applied to. The employers expectation of the job are kinda different from what i thought.Appreciate if someone can share with me their insight. Thank you.Edit: Thanks for all the feedback. To add a bit more context, i've been working on backend development of data layer for my current job. I know well the importance of it and have no problem working on that in new job. The huge flag i saw was, the manager's focus was mostly on the benefits of data science, but neglect the fact that he need to spend lots resources (time, money, people) to develop + maintain the system before he can get those benefits. During the interview, i get the vibe that, he got strong opinion on how's things should be done and doesn't like to be tell otherwise. Clearly there was a big gap between our understanding of the job, i just don't think it will work out well for both of us. Therefore i decided not to follow up with them on that job.",,"Discussion,"
758,https://www.reddit.com/r/datascience/comments/d72euv/survey_software_hopefully_free_that_will_present/,d72euv,survey_software_hopefully_free_that_will_present,fschwiet,1.0,2,2019-09-21 00:49:13,0,2,,"I want to do an online survey I post from different sites (reddit, twitter, facebook, etc).  I put some questions together with https://www.strawpoll.me/, but I think the order of the questions and answers is introducing a bias in the responses.  Is there any software I can use, hopefully free, to present the questions and their answers in random order?Survyegizmo.com looks like it will let you put in custom script to reorder questions.. ugh, I'm wondering if something better can be done.I really don't know where to ask this.  My first thought was to ask my friend who is a data scientist... and so I thought I'd try this forum.",,"Tooling,"
759,https://www.reddit.com/r/datascience/comments/d6buto/kmeans_be_like_mine_mine_mine/,d6buto,kmeans_be_like_mine_mine_mine,postal__dude,0.97,1419,2019-09-19 12:02:02,0,27,,,,"Fun/Trivia,"
760,https://www.reddit.com/r/datascience/comments/d73yt6/deep_learning_for_nlp_or_computer_vision/,d73yt6,deep_learning_for_nlp_or_computer_vision,snip3r77,0.4,0,2019-09-21 03:04:43,0,0,,Can you guys recommend which field should one focus on if I'm already in the DS field and would want to go into either one of the in the very near future ( 3 to 6 months ) ?I have already completed Coursera's Deep Learning specialization.Thanks.,,"Job Search,"
761,https://www.reddit.com/r/datascience/comments/d6suz0/is_it_a_good_idea_to_retraing_a_ml_model_every_2/,d6suz0,is_it_a_good_idea_to_retraing_a_ml_model_every_2,L3GOLAS234,0.78,10,2019-09-20 12:21:06,0,11,,"Hello. In my company we have a model for anti fraud detection which has data until june. I am coding a script to automate the retraining of the model with new data every two or three weeks. The hyperparameters would be always the same ones, so as the variables. The algorithm is XGBoost. We tried different sampling models for avoiding problems due to our imbalancement in classes, but it turned out that the best option was to take every data we have, keeping a relation of 99/1 for no_fraud/fraud.Is it a good idea? Is there any chance that the model gets worse with this kind of updates?",,"Discussion,"
762,https://www.reddit.com/r/datascience/comments/d6pmvk/has_anyone_read_this_book_is_it_worth_it_to_buy/,d6pmvk,has_anyone_read_this_book_is_it_worth_it_to_buy,Skyartemis,0.9,26,2019-09-20 06:20:31,0,11,,,,"Education,"
763,https://www.reddit.com/r/datascience/comments/d6r55z/resources_for_spark_and_kafka/,d6r55z,resources_for_spark_and_kafka,mdrilwan,0.83,12,2019-09-20 08:59:58,0,0,,This site contains very good resources for spark and Kafka https://legacy.gitbook.com/@jaceklaskowski,,"Tooling,"
764,https://www.reddit.com/r/datascience/comments/d7021q/best_practices_for_picking_a_machine_learning/,d7021q,best_practices_for_picking_a_machine_learning,0_marauders_0,0.62,2,2019-09-20 21:43:18,0,1,,,https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model,"Discussion,"
765,https://www.reddit.com/r/datascience/comments/d6vp1l/online_training_platformscourses/,d6vp1l,online_training_platformscourses,[deleted],0.63,2,2019-09-20 16:27:49,0,2,,"My company has a VERY large training budget, and they’re basically forcing me to use my fair share of it before the year ends, so here I am.If money wasn’t an issue, what classes/softwares/trainings would you seek? It’s worth mentioning that worldwide travel is a possibility, but right now I’m looking more for interactive trainings.I’m mainly looking for training on Tableau, SQL, and R.Example - I know that for investment banking, Wallstreetprep is a great website that offers in-depth training on all areas of the business - Excel, modeling, fin statement review, etc. Does anything like this exist for Data Science?Thanks!",,"Discussion,"
766,https://www.reddit.com/r/datascience/comments/d6ztej/is_data_science_ideal_for_me_given_my_background/,d6ztej,is_data_science_ideal_for_me_given_my_background,emaxwell13131313,0.33,0,2019-09-20 21:25:24,0,7,,"I am looking at Data Science positions and have a PhD in nuclear and computational physics from a program ranked in the top 45 in my field, which included Artificial Neural Networks and Phenomenology, a Postdoc in Chemistry and molecular dynamics and 5 month contract position as a researcher at a signal processing startup.  My linkedin in page has more details: https://www.linkedin.com/in/evan-askanazi-404133a3/I was wondering if I am looking in the right career path given my current background. I was looking at Data Science but it seems that right now there are way more applicants in America and elsewhere looking for Data Science work than there are openings available. I've heard it brought up but it seems that the supply of Data Scientists is much, much higher than the demand, which is why so many researchers are struggling and failing to get desired work in this field.And so while my background does include work that can be classified as Data Science, it's not solely about Data Science and so I was wondering if maybe there are options I haven't been made aware of. I also don't think a pure coding based job, such as a Front End or Back End Developing job, would work since I would be competing with hundreds of coders who've spent 2 years or more in boot camps, industry positions, tech firms and other places doing coding projects that can be added to portfolios. As of now I don't have a portfolio of the kind of projects one would do in a bootcamp since my previous work was in research that was a mix of chemistry, physics, data modeling (artificial neural networks being an important example), algorithm applications and machine learning.",,"Job Search,"
767,https://www.reddit.com/r/datascience/comments/d6ndjd/just_turned_down_a_new_job_at_25_pay_raise/,d6ndjd,just_turned_down_a_new_job_at_25_pay_raise,tmotytmoty,0.74,11,2019-09-20 03:03:38,0,27,,"I feel so dumb, but it did not feel right. Plus, I really like my current boss and co-workers, and a good crew is hard to find. I helped hire most of them. The new gig did not have a stack, and did not allow data scientists to have local admin rights on the standard issue, non-dev PC, that I would have to make use of...to install r...so every new package would require an it ticket. 24 hours later I can use ggplot2... At the current gig, I built the stack. I am the admin.  I choose the machine specs! It’s awesome. But still... 25%... hard to back away from. I’m pretty sure I made the right choice in staying, but I wanted to hear if you all have stories about walking away from an somewhat overwhelming offer because of:a) your current job was just too good (and what was so good about your current job? Money? People? What?) b) the new gig looked incredibly uncomfortable (what made it uncomfortable?) c) a little bit of a and b.",,
768,https://www.reddit.com/r/datascience/comments/d6tgsv/srgan_adapt_the_model_to_the_input_image/,d6tgsv,srgan_adapt_the_model_to_the_input_image,JarsOfJam-Scheduler,1.0,1,2019-09-20 13:22:37,0,0,,"I wrote and trained my own SRGAN: so I obtained a generator's model that takes 32x32 images as input and gives their improved 128x128 version as output...However, the end users of my Android app will send images of any size, 3800x2800, 53x12, etc.How can I run my SRGAN on such images: Should I change the generator's training to take images inputs with any dimensions into account (differing from the original SRGAN research paper)? Or can I change the shape dimensions of the input layer of the model on the fly?Note: https://deepai.org/machine-learning-model/torch-srgan - they actually did it! I don't know how...",,"Projects,"
769,https://www.reddit.com/r/datascience/comments/d6ssp4/my_company_is_looking_at_dataiku_to_build_data/,d6ssp4,my_company_is_looking_at_dataiku_to_build_data,pranjal_22,0.5,0,2019-09-20 12:14:02,0,2,,,,"Tooling,"
770,https://www.reddit.com/r/datascience/comments/d6ri3l/what_tools_are_used_to_make_connected_3d/,d6ri3l,what_tools_are_used_to_make_connected_3d,lynob,0.25,0,2019-09-20 09:39:55,0,5,,"This chart:What is it called?  Connected 3d interactive cluster?What tools are used to make it? viewing the page source didn't help, all I know is that vuejs might have been usedCan it be done in Tableau? if not what can it be done with?Is there any example or tutorials on how to do that?",,"Discussion,"
771,https://www.reddit.com/r/datascience/comments/d64w8p/nice_try_google_yes_i_misspelled_tpr/,d64w8p,nice_try_google_yes_i_misspelled_tpr,forthesakeofspatial,0.87,213,2019-09-19 00:44:05,0,19,,,,"Fun/Trivia,"
772,https://www.reddit.com/r/datascience/comments/d6o4in/little_data_problem/,d6o4in,little_data_problem,xyz_TrashMan_zyx,0.67,1,2019-09-20 04:05:46,0,4,,"On my day job, in my career, training data size has never been a problem. But on a side project, analyzing city budgets and expenditures, I have time series data with only a few observations - 2016,2017,2018,2019, and sometimes 2020. As a data scientist I want to do modeling but what kind of modeling can you do when you have only 5 observations?Cutting edge data visualizations of increases, the timeline of budget stuff in a bar chart with 4 bars, I'm not sure. Any recommendations on how to add value to data with such a format?",,"Discussion,"
773,https://www.reddit.com/r/datascience/comments/d6jsle/online_anomaly_detection/,d6jsle,online_anomaly_detection,Relatiro,1.0,1,2019-09-19 22:26:57,0,6,,"Since I'll be working on anomaly detection in time series data soon'ish, I was wondering if any of you have specific recommendations in terms of literature, algorithms, python libraries etc. All opinions and suggestions are very welcome!The specific applications will be along the lines of electric and hydraulic systems, if that matters.Thank you guys in advance 💪",,
774,https://www.reddit.com/r/datascience/comments/d6fsiu/learning_material_for_network_theory/,d6fsiu,learning_material_for_network_theory,VisuelleData,1.0,1,2019-09-19 17:38:19,0,4,,"I'm looking for some learning material on network theory. I'm particularly interested in centrality measures and applications of network analysis combined with other metrics. For example, using sentiment scores of Twitter posters and the posters' centrality value to identify positive / negative influential Twitter users.",,
775,https://www.reddit.com/r/datascience/comments/d66vu2/what_are_your_90_50_10_predictons_for_the/,d66vu2,what_are_your_90_50_10_predictons_for_the,sepa299,0.94,12,2019-09-19 03:22:33,0,9,,"Saw this post in r/cscareerquestions, thought it would be interesting to hear from data scientists on the matter.",,"Discussion,"
776,https://www.reddit.com/r/datascience/comments/d6f073/learn_more_advanced_data_science/,d6f073,learn_more_advanced_data_science,HeartSurgeonInJapan,1.0,1,2019-09-19 16:41:39,0,5,,I‘m fresh out of my cs master’s program and I already got a job as a junior data scientist starting next month. I’ve only passed an introduction to machine learning course in my masters and I’m familiar with the basics but I have no knowledge of deep learning and more advanced techniques for NLP and machine learning. What would you recommend me to study? Online courses or books I can study before starting my job. I really want to learn more and be more prepared.,,"Career,"
777,https://www.reddit.com/r/datascience/comments/d6kq58/you_are_running_an_ab_test_on_a_new_proposed/,d6kq58,you_are_running_an_ab_test_on_a_new_proposed,nouseforaname888,0.13,0,2019-09-19 23:36:08,0,4,,,,
778,https://www.reddit.com/r/datascience/comments/d6gci0/how_do_you_create_a_passion_for_data_science/,d6gci0,how_do_you_create_a_passion_for_data_science,aporetical,0.2,0,2019-09-19 18:18:27,0,4,,"I'm very passionate about programming languages.I was just looking over random pycon lectures and I've watched many on advanced techniques.I also noticed I havent watched many on data science topics. Yet, part of my job is knowing this content.My question is: what advice would you give to start that autodidactical fire (ie., passion) in me?I already know quite a lot (from linear algebra, optimization, statistics to spark) -- but I'm just not feeling that drive to ""relax"" to data science lectures in the way I might relax to multi-hour functional programming ones.",,"Discussion,"
779,https://www.reddit.com/r/datascience/comments/d5nfjc/mistakes_data_scientists_make/,d5nfjc,mistakes_data_scientists_make,ADGEfficiency,0.96,431,2019-09-17 23:20:53,0,42,,In my job educating data scientists I see lot's of mistakes (and I've made most of these!) - I wrote them down here - https://adgefficiency.com/mistakes-data-scientist/.  Hope it helps some of you on your data science journey.,,"Education,"
780,https://www.reddit.com/r/datascience/comments/d664tv/mortgage_bonds_from_2008/,d664tv,mortgage_bonds_from_2008,RicardoMoyer,1.0,3,2019-09-19 02:20:35,0,2,,"does anyone have or know where can I find the data for the mortgage-backed securities/Mortgage bonds or CDOs/CMOs from 2004-2008? in 2006 there were 27k MBS's, is there a dump from one of the rating agencies or banks?",,"Projects,"
781,https://www.reddit.com/r/datascience/comments/d60kge/data_science_masters_uk_rankings/,d60kge,data_science_masters_uk_rankings,JackWills94,0.82,10,2019-09-18 18:49:47,0,5,,"Last month I commented on a post about how I kept track of all the best Data Science Master programs whilst I was applying. After that I received a handful of messages asking for a copy of it so I updated for 2020 applications and will post here (and link those who messaged me directly).https://1drv.ms/x/s!As-tjB7ho2tOihoL85njBe1Mi4gNFew caveats:As there are no Data Science ranking specifically I used a weighting of the University aggregate, their mathematics and their CS rankings (2:1:1).For some rankings it uses the average of a range (i.e. 150-200 = 175)Some Universities were above the ranking system (i.e. 500+) so I gave them 550.I use the QS Top University Rankings:  https://www.topuniversities.com/university-rankingsCost is reflective of mostly 2020 prices, however if not available I used the 2019 cost.Hope it helps!",,"Education,"
782,https://www.reddit.com/r/datascience/comments/d5xsbj/ab_testing_10_common_mistakes_we_all_make/,d5xsbj,ab_testing_10_common_mistakes_we_all_make,jacquespeeters,0.81,18,2019-09-18 15:27:36,0,3,,,https://medium.com/manomano-tech/a-b-testing-10-common-mistakes-we-all-make-97a5030f1d44,
783,https://www.reddit.com/r/datascience/comments/d696iw/why_does_sas_have_such_a_bad_rep/,d696iw,why_does_sas_have_such_a_bad_rep,Bruh-ism,0.6,1,2019-09-19 06:49:50,0,25,,"I work in an organization where I initially proposed a business case for the adoption of Python/Pandas as our toolkit for quantitative data analytics instead of SAS for our Finance market risk team, and the feedback I got was that due to the fact that it is open source there is no central organization that is really held accountable for problems or potential bugs. As a result, SAS makes the most business sense for larger enterprises. I personally totally understand why this was the direction that leadership decided to take because of the level of customer support and even though I obviously would never use it on my own projects, it has its place in a corporate environment where regulations require vendors to provide some level of support for their tools , in this case SAS institute is the accountable party, and you pay for that support as opposed to the free open source.I just want to hear your thoughts because I think as a community we should still appreciate that SAS does play a role in the industry and corporate-scale data science is still a growing area of data science that we should support and foster, and turning students away from ever picking up SAS is a negative approach to take because it really depends on the person's own career interests and also the use cases and data environment they would work in. In an ideal world obviously open source makes the most sense but in a real corporate environment, I can resonate with why SAS would be the weapon of choice.",,"Discussion,"
784,https://www.reddit.com/r/datascience/comments/d68i2y/ai_for_scent_security/,d68i2y,ai_for_scent_security,lilahaan,1.0,1,2019-09-19 05:42:33,0,3,,"Odd title, I know. Shower thought: Can we leverage ML for accurately predicting smells? Who needs drug dogs at airports when we have computers!",,"Discussion,"
785,https://www.reddit.com/r/datascience/comments/d64y2n/job_market_dynamics/,d64y2n,job_market_dynamics,Texugo_do_mel,1.0,2,2019-09-19 00:47:59,0,4,,"As a programmer, I see that a lot of companies value experience over education. It is not so important to have formal education if you have the skills –  even that it is not so clear in the job description. On the other hand, companies seen to be looking for at least a MSc when it comes to data science. Is this impression wrong? If it is accurate, how is this academic level of education important in a data scientist job? Is a job of a data scientist somehow related to an academic job? I am trying to understand this dynamics.",,"Career,"
786,https://www.reddit.com/r/datascience/comments/d662yo/whats_the_outlook_for_data_analyst_roles_in_the_uk/,d662yo,whats_the_outlook_for_data_analyst_roles_in_the_uk,BruhDontFuckWithMe,0.67,1,2019-09-19 02:16:17,0,1,,"I have a degree in economics, there is a government apprenticeship im interviewing for. Its 18 months paid, with 20% of the work week dedicated to studying for the Bsc. I really would hate to invest all that time into something thats not a stable future career. Im also struggling to understand why my degree isnt enough for the role, ive done many advanced stats courses, research projects and a stats dissertation. Degree is level 6, an apprenticeship is level 4, which is the level my first year modules at uni were...",,
787,https://www.reddit.com/r/datascience/comments/d5xvpx/are_there_any_packages_for_multivariate_time/,d5xvpx,are_there_any_packages_for_multivariate_time,kadify,1.0,8,2019-09-18 15:35:00,0,13,,"What I am doing is trying to detect when a battery may be starting to exhibit non-normal operations, possibly preceding a major event, or a component failure. I have about 100 different sensors all measuring different parts of the battery equipment and I have 30 second real time data for each of those sensors. I've already matched them all together creating a dataframe that is about 100 columns by 1000 rows, I'll probably need to import the data into a matrix rather than a dataframe for processing as I start getting more rows.What I want to do is find anomalies within the different sensor data and then match those together to find out if there are consistent anomalies among multiple sensors (ie something is breaking and 10 sensors all show anomalies at the exact same time).Is there anyway to do this/would it be better to do PCA/dimensionality reduction first? There are quite a few sensors that are highly correlated, mostly due to coming off the exact same piece of equipment but measuring slightly different things.One example I've found is datastream.io, but I believe I'd have to save the anomalies for each column and then find matches among different columns and I don't know how the anomalies are saved and whether it would be difficult to try to find consistent anomalies. It also doesn't help me figure out which columns/sensors are the most indicative of an anomaly, which I would like to have if possible.Any help would be greatly appreciated!",,"Projects,"
788,https://www.reddit.com/r/datascience/comments/d64b7w/how_will_data_science_be_in_5_years/,d64b7w,how_will_data_science_be_in_5_years,aerdna69,0.25,0,2019-09-18 23:41:27,0,6,,,,"Discussion,"
789,https://www.reddit.com/r/datascience/comments/d6019g/is_it_just_me_or_does_this_prediction_scare_you/,d6019g,is_it_just_me_or_does_this_prediction_scare_you,chayblay,0.5,0,2019-09-18 18:12:21,0,32,,,,
790,https://www.reddit.com/r/datascience/comments/d5zrtw/h2o_automl/,d5zrtw,h2o_automl,da_chosen1,0.5,0,2019-09-18 17:53:54,0,13,,"I saw a demonstration of what h20.ai can do with its automl capabilities, and it was crazy. The tool was able to create a model that scored in the top 10 of a Kaggle competition, and its a drag and drop field. I wanted to ask y’all, what does that mean for the future of data scienctist?",,"Discussion,"
791,https://www.reddit.com/r/datascience/comments/d5dvju/finance_employer_not_keen_on_phds_changes_job/,d5dvju,finance_employer_not_keen_on_phds_changes_job,MonthyPythonista,0.93,261,2019-09-17 10:08:03,0,188,,"https://news.efinancialcareers.com/uk-en/3002110/do-you-need-a-phd-to-be-a-quantSome of the most frustrating colleagues I've worked with have been people who've come out of a PhD [...] No one choses to do a PhD unless they love doing something in great detail and often on their own.""These can all be ""total contraindications"" for working in a team and getting things done quickly, said Ainsworth.Ainsworth manages a team of 40 data scientists and engineers at Schroders, but he prefers not to use the term 'data scientist' due to its allure for people who've simply jumped upon the data science and machine learning bandwagon. ""We had a data science role, but when changed the title to 'data consultant' immediately all the people who just thought they wanted to work in data science and machine learning disappeared,"" said Ainsworth. ""Really good people see through to the role, past the title."" Just some food for thought.A debate on PhD yes vs PhD no would be one of those sterile how-long-is-a-piece-of-string type of questions, because you cannot generalise. But one thing I have noticed is that people with a very theoretical background tend to struggle to adapt to a business world in which it is often best to spend 1 hour to get 90% of the answer, as they'd rather spend 3 days to get the full answer. Which isn't to say that a PhD is useless, of course not - I just mean that PhD graduates must realise that the business world is very different from academia.The comment about the job title is very interesting because it speaks volume about the guff surrounding certain trendy buzzwords!",,"Discussion,"
792,https://www.reddit.com/r/datascience/comments/d5unco/predict_time_series_behavior_without_strong/,d5unco,predict_time_series_behavior_without_strong,agalan_bd4bs,0.8,3,2019-09-18 10:15:40,0,8,,"I have been looking for some algorithms. I want to predict the behavior of a time series but it have no seasonality component (not very important) and the algorithms always look for time patterns. I tell you the problem:Imagine there is a football stadium in some city, some days there is a football match. Supose it is in a random day, it could be on monday, tuesday... or saturday, no day have so much height than other. I have a time series with some variables: availability of hotel rooms near the stadium, number of people in X square, Y square... etc, near the stadium, number of people on restaurants near the stadium... etc.I dont know if some day there is a football match but, of course, these variables have different behavaiour before a football match. I want to predict, one day at 2 p.m. if that night will be a football match, using for example the values of that variables the day before and the morning of that day.Which is the best algorithm you can recommend me to do this?",,"Tooling,"
793,https://www.reddit.com/r/datascience/comments/d5xulv/responsible_web_scraping_gathering_data_ethically/,d5xulv,responsible_web_scraping_gathering_data_ethically,devishnya,0.67,1,2019-09-18 15:32:37,0,5,,,https://blog.soshace.com/en/python/responsible-web-scraping-gathering-data-ethically-and-legally/,
794,https://www.reddit.com/r/datascience/comments/d5xnke/are_categorical_variables_getting_lost_in_your/,d5xnke,are_categorical_variables_getting_lost_in_your,at_least_,0.67,1,2019-09-18 15:17:21,0,12,,"Not my article but this helped me on a problem where I was trying to apply a random forest algorithm with sklearn:https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/TL;DR Decision tree models can handle categorical variables without one-hot encoding them. However, popular implementations of decision trees (and random forests) differ as to whether they honor this fact. We show that one-hot encoding can seriously degrade tree-model performance. Our primary comparison is between H2O (which honors categorical variables) and scikit-learn (which requires them to be one-hot encoded).",,"Education,"
795,https://www.reddit.com/r/datascience/comments/d5z0pt/testing_in_data_science/,d5z0pt,testing_in_data_science,sweetlou357,0.25,0,2019-09-18 17:00:46,0,2,,We currently have a package of data processing functions and we want to integrate testing throughout our codebase.What is the best way to approach this? Most functions take in a dataframe and return a single value or even another dataframe 😱 so it seems much trickier than testing for example part of a user story in a web application.Curious to see any suggestions or what has been successful in your experienceThanks!,,
796,https://www.reddit.com/r/datascience/comments/d5ri8a/r_or_python_for_machine_learning_ai/,d5ri8a,r_or_python_for_machine_learning_ai,philippatt,0.75,2,2019-09-18 04:46:05,0,3,,"I would love some input or your view about R vs.Python in ML/AI field! I am big Python lover when come into ML/AI. I know R, but primarily used it for Time Series analysis and other statistic analysis. Recently, there are people saying that R can do the same job as Python in terms of ML/AI (NLP specifically), which I kind of have a different view. What would you think about the two? Thank",,"Discussion,"
797,https://www.reddit.com/r/datascience/comments/d5sh6w/how_to_go_about_predicting_if_a_customer_will_buy/,d5sh6w,how_to_go_about_predicting_if_a_customer_will_buy,MultipurposeEraser,1.0,1,2019-09-18 06:15:34,0,3,,"Some background, My current role is Data Engineering but I have a opportunity to test my knowledge of our data. I know how to move around the data better than anyone, now I just need to understand how to use it for business purposes. I have ""features"" in my data and I have if an item was bought in a category. Now I just need a model that works with Pyspark and data frames.I have read some stuff onhttps://www.datacamp.com/community/tutorials/survival-analysis-Randhttps://spark.apache.org/docs/2.1.0/ml-classification-regression.html#survival-regressionare these interchangeable? do they do the same thing?What is a good resource to solve my problem in Pyspark?",,"Discussion,"
798,https://www.reddit.com/r/datascience/comments/d5pump/anyone_interview_at_amazon_for_a_tech_engineer/,d5pump,anyone_interview_at_amazon_for_a_tech_engineer,pharaphoks,0.4,0,2019-09-18 02:28:37,0,9,,"Hello,I am interviewing for the support engineer role and I am stressing about the interview and the live coding exercise. Did anyone interview for a similar role? Tips would be greatly appreciated. Thank you!!!",,"Career,"
799,https://www.reddit.com/r/datascience/comments/d5oxsf/hoeffding_inequality_for_a_certain_trial_what/,d5oxsf,hoeffding_inequality_for_a_certain_trial_what,boydbuilding,0.67,1,2019-09-18 01:15:18,0,6,,"HiP[|μemp − μ| > ε] ≤ 2e^(−2*N*ε^2)suppose try for this   X ∼ Bernoulli(p = 0.8) N=300 , so the μ=0.8. for N=300, got μemp=0.83, ε=0.1, then|μemp − μ| > ε already holds. What does P do here?  what is P's role? helps pleaseThanks a ton!",,"Discussion,"
800,https://www.reddit.com/r/datascience/comments/d5nmt9/what_goes_in_a_github_repo_all_work_across_the/,d5nmt9,what_goes_in_a_github_repo_all_work_across_the,iluvbinary1011,0.67,1,2019-09-17 23:35:57,0,4,,"As the title says, I'm working on an independent DS project where I'm writing code across the entire lifecycle: data collection/sourcing, ETL/transformation, loading to Postgres, feature engineering, model implementation, training, testing, and developing some TBD production interface.On one hand, I'd like to host all the code in a GitHub repo to showcase my ability to work across a project from end to end, but on the other, it'd look pretty messy (with modules in the data engineering phase that no one else would ever use) and it seems to make sense to only open source the production app code.What's a typical procedure for hosting projects like this?",,"Projects,"
801,https://www.reddit.com/r/datascience/comments/d5gkaf/what_are_your_reference_management_solutions_for/,d5gkaf,what_are_your_reference_management_solutions_for,Xayo,0.75,4,2019-09-17 14:54:13,0,5,,"I'm about to embark on my journey as a Ph.D. student. During my research project, I will heavily work with deep learning. A significant part is also implementing new solutions.During my Master Thesis my solution to reference management was to check in all papers i read into github, and hoping to remember which part of knowledge comes from which paper. You might as well call my existing solution for tracking references non-existant.Going into my Ph.D., I would obviously like to change this. What solutions have you found work for you to track references?",,
802,https://www.reddit.com/r/datascience/comments/d5mei2/data_scientist_interview_at_playstation/,d5mei2,data_scientist_interview_at_playstation,samanou,0.5,0,2019-09-17 22:05:11,0,0,,I have a data science interview at PlayStation in the next two weeks. What should I expect?,,"Job Search,"
803,https://www.reddit.com/r/datascience/comments/d5f4fb/suggestions_on_good_practice_when_merging_kmeans/,d5f4fb,suggestions_on_good_practice_when_merging_kmeans,The_Foetus,0.86,5,2019-09-17 12:39:36,0,1,,"Hi, I was wondering if I could get some feedback into whether my methodology is problematic or not.I'm working with a pre-established set of 12 cluster centroids in a classification problem, based on the output of a 42-element 2D joint histogram. When classifying points, these histograms are collapsed so that the classification is only done on a 3-element vector representing the mean quantities of the data point.The purpose of this is to identify cloud types, to feed into some of my cluster-specific analysis. Now, three adjacent cluster centroids all refer to the same cloud type, however they have different 'thicknesses'. In my final work, I'd like there to be just a single cluster to represent this type. I worry though, by just merging by, for instance, taking the mean of these centroids, the classification step will miss many points that would've ordinarily been assigned to these clusters, because they might then be closer to another centroid which doesn't represent the data point accurately.My idea is to classify my datapoints with a codebook containing the three centroids (say, clusters 1, 2, and 3). After allocating all my points, I'd then merge the clusters together into a single classification. This would then result in a cluster which has been manually extended to capture points that wouldn't ordinarily be in it.Is this a problematic way of merging clusters, as opposed to say, taking the mean of the three cluster centroids? Or are there better ways of doing this?I've drawn out a basic diagram attempting to illustrate what I mean - https://i.imgur.com/aGIW3f5.jpgThanks a lot in advance",,
804,https://www.reddit.com/r/datascience/comments/d53wxb/continuing_education/,d53wxb,continuing_education,negroamigo012,0.95,110,2019-09-16 19:28:39,0,3,,Anyone have suggestions for good blogs and websites that keep up with data science and how it’s changing as an industry. I like to stay abreast to the happenings in whatever field I work in.,,"Education,"
805,https://www.reddit.com/r/datascience/comments/d5l88y/how_would_you_explain_to_a_group_of_senior/,d5l88y,how_would_you_explain_to_a_group_of_senior,Thyphan69,0.5,0,2019-09-17 20:41:07,0,9,,,,
806,https://www.reddit.com/r/datascience/comments/d5nit8/entry_level_data_science_interview_inquiry/,d5nit8,entry_level_data_science_interview_inquiry,Zvezda75,0.25,0,2019-09-17 23:27:44,0,3,,"Hi all.This is my first post on Reddit so forgive any errors.Background:I am an undergraduate student currently finishing up on my bachelor's degree in computer science with a minor in mathematics. I have been involved in the Natural Language Processing (NLP) lab at my university performing some tasks to assist PhD students with their research. I have really fell in love with NLP, as well as data science in general. I joined the lab in Fall 2018 and have since acquired co-authorship on an arXiv paper, have had a chance to be part of a bioinformatics research program over this past summer, and try to aim most in-class projects towards NLP/data science. My current cumulative GPA is a 3.47 (pursuing chemical engineering lowered my GPA by some), and my major GPA is a 3.77. Although I did not perform well as a chemical engineering students, after I transferred to the computer science department I feel that I have really excelled in my class work and genuinely enjoy computer/data science.Entry Level Data Science Interview Inquiry:I have decided to apply for some entry level data science jobs that only require a bachelor's degree. I have taken some entry level software development/engineering and have seen there are a ton of resources out their in regard to preparing one for the inevitable coding interview. My gut feeling tells me data science 'coding' challenges/questions are going to be different than the what most resources for coding interviews provide. From what I can tell, there is little information on entry level data science type of interviews and was wondering if there are any specific topics/challenges I should go over or what to really expect from an entry level position interview. I really want to do well on these potential interviews as my interests align more with data science/NLP rather than software development/engineering positions.Any advice would be very much appreciated! (:",,"Job Search,"
807,https://www.reddit.com/r/datascience/comments/d5k8on/beginner_question/,d5k8on,beginner_question,nickmehul,0.5,0,2019-09-17 19:30:25,0,3,,"Hi,I am just starting out my education in Data Science and analytics. I am looking at a list of relevant skills and had  a question. I am interested in deriving insights from datasets like finding trends from sports scorecharts from past decades. I want to see what skills I need to pick up to get started? I know R and Python are popular ones. Which languages are needed to refine the data and which one to actually derive patterns?Thanks",,"Education,"
808,https://www.reddit.com/r/datascience/comments/d57bck/looking_to_land_a_data_scientist_position_by/,d57bck,looking_to_land_a_data_scientist_position_by,StringCheeseInc,0.85,36,2019-09-16 23:53:29,0,43,,"Hi Everyone!I’m considering leaving my current job and looking for a job in the data science field starting in April 2020 and would appreciate guidance / feedback.Background: I work for a Fortune 500 company in NYC and have been with the company for 11.5 years.  I started in their leadership development program and spent first 2/3’s on business side before moving to IT in pursuit of my passion for data and analytics. On the business side I made a great reputation and built strong relationships by building tools to automate tasks, manage field groups, improve productivity and accounting of work among many other things.  I deviated from the traditional career path and chose to join IT ~ 3 years ago and led multiple reporting development teams before joining our internal tech “startup” as the analytics lead, where we deliver products using agile methodology and design thinking.The group I’m currently in is growing rapidly but the IT organization as a whole is looking to reduce size and they’re offering a voluntary package to all IT employees with the terms that you’d have to stay until end of March, 2020.  I love my current job and people I work with but would like to explore other industries, work on cutting edge technologies and solve new problems.Other Factors to Consider: I am the primary source of income and am married and have three children.  As for the package, I would have to accept it in November and once/if accepted it’s locked in.My questions are:When should I begin applying for jobs?What is the expected salary range for a data scientist in NJ / NYC area?What other credentials may be needed to land interviews / job?Do most data scientist positions allow for working remotely at least one day per week?What are some other factors I should consider / any guidance from anyone who has gone through something similar?Hope others can benefit from this discussion as well.Mods if this is not the right place for something like this please delete.Thanks in advance for feedback and guidance!",,
809,https://www.reddit.com/r/datascience/comments/d5jime/examples_of_teaching_data_sciencemachine_learning/,d5jime,examples_of_teaching_data_sciencemachine_learning,Chrominum_,0.5,0,2019-09-17 18:37:06,0,1,,"I have researched on any great examples that have teaching experience/curriculum for K-12 education on data science or machine learning. If you know any related cases, let me know.Thanks in advance.",,"Education,"
810,https://www.reddit.com/r/datascience/comments/d5ihmo/october_8_talk_with_hci_pioneer_joseph_konstan/,d5ihmo,october_8_talk_with_hci_pioneer_joseph_konstan,ACMLearning,1.0,1,2019-09-17 17:20:57,0,1,,"On October 8 at 4 pm ET,  Joseph Konstan Distinguished McKnight University Professor and Distinguished University Teaching Professor in the Department of Computer Science and Engineering at the University of Minnesota, presents  ""Recommender Systems: Beyond Machine Learning.""This talk will take a look at successes and failures in moving beyond basic machine learning approaches to recommender systems to emphasize factors tied to user behavior and experience. Along the way, we will explore approaches to combining human-centered evaluation with data mining and machine learning techniques.Register free to attend live or view the on-demand recording later.",,"Education,"
811,https://www.reddit.com/r/datascience/comments/d5i7b2/ab_testing_and_statistical_significance/,d5i7b2,ab_testing_and_statistical_significance,Low_end_the0ry,1.0,1,2019-09-17 17:00:26,0,18,,"I come from a social science background where I design experiments and and compare the differences between the groups.Now I'm trying to wrap my head around A/B testing and when it makes sense to test for statistical significance in a business setting.For example, if we make some change to a website where the Text is Red on one page and Blue on the other,Text colorSignup rateBlue72.5%Red75%This difference probably wont' be statistically significant, but if the company makes $200 for every customer who signs up, over time this will result in a large increase in revenue (assuming the product/site gets a lot of visitors).And because this change doesn't cost the company anything, shouldn't it be implemented regardless of whether the difference is statistically significant or not?",,
812,https://www.reddit.com/r/datascience/comments/d59d9y/tripped_up_by_data_engineering/,d59d9y,tripped_up_by_data_engineering,mjgierc,0.73,5,2019-09-17 02:34:22,0,16,,"Quick question - how many people here are regularly tripped up by data engineering issues, like data cleaning, infrastructure, data warehouse work, ETL, etc?Does it keep you from properly doing your job? I've read lots about the 80/20 rule related to time spent cleaning data vs. actually analyzing it, but is this just marketing BS?",,"Discussion,"
813,https://www.reddit.com/r/datascience/comments/d5d0gq/any_strong_opinions_on_preffered_nice/,d5d0gq,any_strong_opinions_on_preffered_nice,trapspeed3000,1.0,1,2019-09-17 08:23:31,0,2,,"I know this is a strange question, but most people don't go through keyboards every three months. I figured there are probably some other data scientists who pound on their peripherals.My company just replaced my machine and I'm thinking using this as an excuse to upgrade/tweak a variety of things. I can't stand magic mouse. My main thing is something that's somewhat ergonomic and feels nice to the touch.Anyone have a mouse they particularly like or suggestions on what to try?",,
814,https://www.reddit.com/r/datascience/comments/d5an47/questions_to_ask_a_data_scientist/,d5an47,questions_to_ask_a_data_scientist,SuperchargedJesus,0.75,2,2019-09-17 04:21:09,0,4,,"Hi all,I’m working as a reporting analyst mostly automating report generation/ producing reports. But wanting to move into more of a data analyst/ BI role. Through networking, I’ve managed to set up a couple of coffee meetings with some lead data scientists in my organisation.I’d really like to make the most of out this time and would like to know some recommendations for questions or comments around what topics I should try to discuss. I’ve got a list of personal questions surrounding feedback around my current development plans but I really would like to show that I’m interested in their work. I guess for those who have been/are in a similar position, what would you recommend asking about?Thanks for the feedback.",,
815,https://www.reddit.com/r/datascience/comments/d56llg/question_data_merging_in_academics_and_industry/,d56llg,question_data_merging_in_academics_and_industry,enzsio,1.0,1,2019-09-16 23:01:38,0,2,,"Hi,I am curious to know about peoples opinions in data merging datasheets from different database sources in research/industry? Is is worth while to create a merged master flat-file and use it to derive spreadsheets to answer questions (i.e. if more data is added to the master flat-file, reproduce the study)? Or just answer questions based on data sets?I want to know what the common practice is for both? Personally, I think pulling data and merging data sets to maintain reproducible results is very important. What are your thoughts?best,enzsio",,"Discussion,"
816,https://www.reddit.com/r/datascience/comments/d56hh7/help_with_unsupervised_text_classification/,d56hh7,help_with_unsupervised_text_classification,callahman,1.0,1,2019-09-16 22:53:22,0,4,,"I have a pretty large set of review data, and my company is interested in categorizing the reviews.Rather than trying to come up with the classifications arbitrarily, I would like to derive the categories from the reviews themselves.Originally I was thinking that I could do a Bag of Words + Sentiment analysis to get some features, and then drop a clustering model onto the results to determine some categories. Is this a decent approach? Or have better text-centric approaches been developed that I'm missing?Thanks in advance!",,
817,https://www.reddit.com/r/datascience/comments/d4mm87/deploying_models_on_r/,d4mm87,deploying_models_on_r,da_chosen1,0.95,111,2019-09-15 18:20:06,0,37,,"One of the most common criticism against using R is the ability to use model for deployment. I recently attended a talk at Google, and the speaker presented on how to deployment model on the Google cloud.Check it out:https://code.markedmondson.me/r-at-scale-gcp.html#/",,"Discussion,"
818,https://www.reddit.com/r/datascience/comments/d4t7xk/just_completed_data_quest_data_scientist_python/,d4t7xk,just_completed_data_quest_data_scientist_python,saturnwalker,0.68,19,2019-09-16 02:37:52,0,12,,"Hi fellows!Background: master degree in biostatistics from school of public health, have been working as an epidemiologist for over 4 years in a local government. My main work is managing the health department data repository and generating reports and insights for the health policy team. I mostly use Excel, Access, SAS, SQL server, Tableau, occasionally R.Motivation: bored with government work and tired of the bureaucratic BS, need a career boost and some exciting work, also a salary bump.Goal: data scientist /machine learning job in private sector, mainly interested health related industry like healthcare given my background, but I am open to all domains.What have I completed: Data Quest data scientist python path, took me about 6 months, love all the projects, but very introductory, especially in the machine learning part.What’s Next?Should I complete the Data Quest data engineer path? Will it help? It seems pretty short and can help with big data.I am planning to take the Andrew Ng’s machine learning course and five deep learning courses next. But I heard they are pretty theoretical and difficult.Should I start looking for a job now? Fee like I have the basic skills to start a entry level data scientist job that is not machine learning focused.What do you think I should do next? Any recommended online courses?Thank you in advance! Appreciate any comments!",,
819,https://www.reddit.com/r/datascience/comments/d4y6lb/etlelt_tool_suggestion_any_suggestions_for/,d4y6lb,etlelt_tool_suggestion_any_suggestions_for,thatusername8346,1.0,2,2019-09-16 11:20:34,0,19,,"I have a situation where we want to regularly process csv/xlsx/json (mainly the first two) files that have different formats into a consistent format, and load the results into BigQuery. There's currently around 5GB to process, and it's expected that the annual limit would be 100GB.I'm looking at something like Google Data Fusion for this, but am wondering whether there are any other suggestions.The server has to be located within the EU for GDPR reasons.",,"Tooling,"
820,https://www.reddit.com/r/datascience/comments/d4wtop/unsupervised_text_classification/,d4wtop,unsupervised_text_classification,antisama,1.0,3,2019-09-16 08:28:55,0,1,,"Hi everyone, I wanted to ask you, what are the most adapted algorithms for unsupervised text classification (I saw there is dbscan, kmeans ...) and what text input (tf idf, doc2vec, ...) is best suited for each algorithm to perform at its finest, knowing that I have multiple texts in which there is a lot of nammed entities and Jargon.Thank you for your submissions.",,
821,https://www.reddit.com/r/datascience/comments/d4m0wm/actuarial_science_grad/,d4m0wm,actuarial_science_grad,mediator15,0.85,37,2019-09-15 17:36:21,0,37,,"I just graduated from uni with an actuarial science major and economics minor, do you think I have a chance to get in the data science career? I feel they prefer CS. Do you have any recommendations on how to start building up my experience and knowledge?",,
822,https://www.reddit.com/r/datascience/comments/d4ylt6/doubt_regarding_whether_or_not_to_use_vendor/,d4ylt6,doubt_regarding_whether_or_not_to_use_vendor,Philidespo,0.5,0,2019-09-16 12:10:36,0,0,,"So, I have been assigned to setup a 3 node Hadoop cluster for research  work involving Hadoop and Spark. And now I am confused as to whether set  up  a cluster with plain Hadoop or use some vendor distribution like  Cloudera CDH. Since it is for research it would involve timing of jobs  and emphasis on overheads and such stuff so that is something that has  to be taken into consideration. So, are there any particular advantages  or disadvantages of using plain or vendor distribution and what would be  the best practice in this particular scenario ? Thanks is advance.",,"Projects,"
823,https://www.reddit.com/r/datascience/comments/d4n1ui/finding_an_example_of_messy_data_to_demonstrate/,d4n1ui,finding_an_example_of_messy_data_to_demonstrate,clarinetist001,0.93,13,2019-09-15 18:52:08,0,10,,"I'm looking for a messy data set that is available as a .csv or an .xlsx file that I can use to demonstrate to students the process of turning a data set into a tidy one using R. (I would prefer to avoid .html or .pdf for now, as I'll be covering those topics later and would like for students to at least see an example that they would understand at this point.)I would prefer one that has no resemblance to a data set with a row = observation and column = variable tabular data structure, has primary keys (which preferably aren't in a single row per observation), and one in which I could at least demonstrate the process in about 15-20 minutes of lecturing to a class which is aware of basic programming structures (loops, conditional statements, and functions). Where can I find such a data set? I had tried looking for financial data spreadsheet files, but haven't had any luck.",,"Education,"
824,https://www.reddit.com/r/datascience/comments/d4mb3g/how_accepted_is_a_business_analytics_msc_in_the/,d4mb3g,how_accepted_is_a_business_analytics_msc_in_the,szutsmester,0.74,13,2019-09-15 17:57:27,0,30,,"I am currently finishing my psychology Ba, and I would like to pursue a career in ds. Considering business analytics, since I am interested in economics as well. What is your opinion, is this a good school of thought? Any experience is greatly appreciated.",,"Education,"
825,https://www.reddit.com/r/datascience/comments/d4o4cr/can_i_get_some_feedback_im_applying_for_summer/,d4o4cr,can_i_get_some_feedback_im_applying_for_summer,insanelylogical,0.76,9,2019-09-15 20:10:18,0,13,,Pivoted from biology and looking to enter data science or machine learning engineer type jobs.https://imgur.com/a/v81droK,,"Job Search,"
826,https://www.reddit.com/r/datascience/comments/d4ms47/weekly_entering_transitioning_thread_15_sep_2019/,d4ms47,weekly_entering_transitioning_thread_15_sep_2019,datascience-bot,0.92,10,2019-09-15 18:32:26,0,36,,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki.You can also search for past weekly threads here.",,"Discussion,"
827,https://www.reddit.com/r/datascience/comments/d4pdlb/cs_bachelors_to_data_science_masters_program_good/,d4pdlb,cs_bachelors_to_data_science_masters_program_good,black_widow48,0.75,4,2019-09-15 21:40:56,0,11,,"I have a bachelor's degree in computer science. I am now a data analyst for a Fortune 500 company. Aside from creating MS Power BI dashboards, I also do a lot of PHP scripting, database design, and I do full stack web development too.I'm only making 62k/year at my current job. This is nowhere near what I want to be making, and the job is just sort of unfulfilling in general. I feel like I'm not using a lot of the skills I have as a person with a degree in computer science... Like basically anyone off the streets could take a month to learn SQL and accomplish most of what I do.I figure I'd be more satisfied if I got a position as a data scientist or something similar. I've always been fascinated by machine learning, AI, neural networks etc. And big data seems to be where the money is at in computer science right now too, so I figure it might be the route to take (at least for now).So now that I've got my bachelor's degree in computer science, I'm currently going to school for a master's degree in data science with a concentration in computational intelligence. I figure even if data science doesn't last, my bachelor's in computer science will still be enough to move into other things if I want to. And I'll be graduating with my Master's in December 2020, or earlier if I decide to take more classes faster. So it'll take a year and a half or less for that.Does this sound like a smart route to take in today's world of computer science? I certainly didn't get a degree in CS to make only 62k/year like I do now (especially since I already have over 100k in student debt), and I need something more complex and fulfilling. And money obviously isn't everything, but I like money and likely won't be satisfied until I'm making at least double what I'm making now. Life ain't cheap these days, and neither are my hobbies. Lol. And lots of things interest me in CS, so I might as well just go where the money is.",,
828,https://www.reddit.com/r/datascience/comments/d4d8a1/should_i_have_a_computer_science_major_with_a/,d4d8a1,should_i_have_a_computer_science_major_with_a,BombBurper,0.81,40,2019-09-15 02:07:28,0,30,,"I'm applying for college rn, and I want to become a data scientist but I've heard that since schools like uc san diego have only recently started introducing data science masters programs, they are unproven and they just contain a hodgepodge of courses from cs and stats, where you become a jack of two trades master of none. So what are your thoughts on this? What should I do?",,
829,https://www.reddit.com/r/datascience/comments/d4xgsk/why_nondatascientists_can_lead_data_science_teams/,d4xgsk,why_nondatascientists_can_lead_data_science_teams,PaulLaughlin,0.09,0,2019-09-16 09:45:50,0,12,,,https://customerinsightleader.com/others/non-data-scientists-lead-data-science-teams/,"Discussion,"
830,https://www.reddit.com/r/datascience/comments/d43bil/extensive_and_comprehensive_cheatsheets_for/,d43bil,extensive_and_comprehensive_cheatsheets_for,[deleted],0.98,350,2019-09-14 12:03:29,0,14,,,https://drive.google.com/folderview?id=0ByIrJAE4KMTtaGhRcXkxNHhmY2M&usp=sharing,"Education,"
831,https://www.reddit.com/r/datascience/comments/d4mg38/weekly_entering_transitioning_thread_15_sep_2019/,d4mg38,weekly_entering_transitioning_thread_15_sep_2019,AutoModerator,0.5,0,2019-09-15 18:07:35,0,1,,"Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:Learning resources (e.g. books, tutorials, videos)Traditional education (e.g. schools, degrees, electives)Alternative education (e.g. online courses, bootcamps)Job search questions (e.g. resumes, applying, career prospects)Elementary questions (e.g. where to start, what next)While you wait for answers from the community, check out the FAQ and Resources pages on our wiki.You can also search for past weekly threads here.Last configured: 2019-02-17 09:32 AM EDT",,"Discussion,"
832,https://www.reddit.com/r/datascience/comments/d42a3c/so_i_built_an_interesting_bot_in_r/,d42a3c,so_i_built_an_interesting_bot_in_r,casacrypto,0.73,84,2019-09-14 09:46:27,0,53,,"So I got drunk on Monday night and went on a coding rampage, I ended up starting a trading strategy but I turned it into a twitter bot that predicts wether if BTC is going up or down, And holy shit, not only is right more than half the time, it’s right over 70% of time , it tweets historical accuracies, post some interesting graphs from real time data, retweets news and even has personality when you tweet at it, anyways I plan on open sourcing this in the future, this was done in R and using real exchange volume data with an XG boost algorithm and some hyper parameter tuning...oh yeaaa follow it and more to come, give me ideas as wellhttps://mobile.twitter.com/bitstreetbets",,
833,https://www.reddit.com/r/datascience/comments/d40f0q/correlation_doesnt_imply_causation_is_repeated_a/,d40f0q,correlation_doesnt_imply_causation_is_repeated_a,Blytheway,0.86,55,2019-09-14 06:07:08,0,36,,,,
834,https://www.reddit.com/r/datascience/comments/d4inb8/have_to_do_my_master_thesis_on_sentiment_analysis/,d4inb8,have_to_do_my_master_thesis_on_sentiment_analysis,slickster18,0.22,0,2019-09-15 12:09:50,0,3,,,,
835,https://www.reddit.com/r/datascience/comments/d4cnfi/anyone_use_survey123_for_arcgis/,d4cnfi,anyone_use_survey123_for_arcgis,MarkusOber,0.33,0,2019-09-15 01:17:11,0,3,,I'm wondering how easy it is to learn to use and how much it costs. Does it require a lot of programming background (or GIS expertise) or is it pretty intuitive to use?,,
836,https://www.reddit.com/r/datascience/comments/d4cdk4/how_to_use_google_colab_a_great_tool_if_you_need/,d4cdk4,how_to_use_google_colab_a_great_tool_if_you_need,The_Peter_Quill,0.44,0,2019-09-15 00:54:27,0,0,,,https://www.geeksforgeeks.org/how-to-use-google-colab/,"Tooling,"
837,https://www.reddit.com/r/datascience/comments/d440w9/products_i_want_as_a_data_scientist/,d440w9,products_i_want_as_a_data_scientist,saadmrb,0.62,6,2019-09-14 13:32:16,0,25,,"1- A platform that collects and funnels data sources into one data lake or warehouse.2- Software that automatically aggregates various data inputs of Excel, MySQL, Pdfs, Docs, Text files, etc..3- Tech that saves hours, days of data processing time.4- Intelligent platform that automates data pipeline process and performs data cleaning to store data in a more human-friendly format.5- Tech that improves data quality and transparency to optimize operations.What about you ?",,
838,https://www.reddit.com/r/datascience/comments/d3temx/opinion_on_ibm_data_scientist_role/,d3temx,opinion_on_ibm_data_scientist_role,p_hacker,0.97,95,2019-09-13 20:25:55,0,39,,"I figured it's a long shot, but I don't know where else to post this so I'm going to try here. I'm wondering if there is anyone on this forum who works for IBM or has worked for them in the past as a data scientist. I'm in the process of interviewing with them and they want me to fly over to their research triangle park campus in NC (I'm on the west coast and the position will be based in my current city). I've read a bunch of the glassdoor reviews for IBM and they seem to be pretty mixed, with some people giving pretty negative reviews which is why I'm posting here to try and get a few more opinions.I'm already working as a data scientist but have been applying at a few other places lately to see what other options I could move into. From the limited info I've been given, this position seems good but I'd really appreciate any info/advice before I fly across the country in a few weeks just for an interview.Job posting I'm referring to:https://careers.ibm.com/ShowJob/Id/744109/Data%20Scientist",,"Discussion,"
839,https://www.reddit.com/r/datascience/comments/d4dmut/is_this_a_good_enough_resume_for_an_entry_level/,d4dmut,is_this_a_good_enough_resume_for_an_entry_level,dash_365,0.36,0,2019-09-15 02:43:58,0,18,,,https://docdro.id/1OBlmGN,"Job Search,"
840,https://www.reddit.com/r/datascience/comments/d4b77l/how_would_you_come_up_with_a_data_science_model/,d4b77l,how_would_you_come_up_with_a_data_science_model,nouseforaname888,0.29,0,2019-09-14 23:19:12,0,7,,Just wondering...Lemme clarify. Say people are big consumers of beef burgers. How many of them would likely switch to impossible burgers?,,"Discussion,"
841,https://www.reddit.com/r/datascience/comments/d3x3ex/advice_on_laptop_for_data_science/,d3x3ex,advice_on_laptop_for_data_science,Peemsters_Yacht_Cap,0.74,7,2019-09-14 00:59:40,0,7,,"Hey folks! First of all, my apologies for creating another laptop advice post, but I couldn't find one that covered my exact question.Anyways, I have a bit of money from a research grant to get a new laptop for data science projects. I think I've decided to switch over to Linux (from Windows on a Lenovo laptop), and am thinking of going with a System 76 laptop with Pop OS. Due to the grant, I have a clear amount of funding that I have available for this. But I am torn between two options: either get a lower end model (either Galaga Pro or Darter Pro) with the highest memory and processor options available, or get a higher end model (Oryx Pro) with a better GPU but with weaker memory and processor options.At this point, I don't use deep learning much at all, but I do a lot of machine learning. The real issue is that we don't really know what we're going to be doing on this project, and I personally don't know where my career will take me. With this in mind, which of the two options do you think would be wiser? A stronger overall machine without NVIDIA graphics, or a weaker machine with better graphics capabilities?Any advice would be greatly appreciated!",,
842,https://www.reddit.com/r/datascience/comments/d3cage/i_finally_feel_like_a_true_data_analyst/,d3cage,i_finally_feel_like_a_true_data_analyst,RareIncrease,0.97,532,2019-09-12 20:38:38,0,48,,"Just transitioned to the industry. Had a business stakeholder at my firm ask me to provide him some stats/data that would ""wow"" the client. I ask for more specific stuff and he really didn't provide any.I did it bois. I'm in and feel part of the club.",,
843,https://www.reddit.com/r/datascience/comments/d3nc53/learnig_scala_for_machine_learning/,d3nc53,learnig_scala_for_machine_learning,LjungatheNord,0.84,15,2019-09-13 12:37:58,0,11,,"So ive worked as a data engineer for the past couple years using Python,SQL and the Occasional R to build shiny applications. I am currently studying a masters in data analytics using R heavily. I was wondering if learning Scala is useful, how many of you use it with spark or is pyspark/sparkR enough",,"Tooling,"
844,https://www.reddit.com/r/datascience/comments/d3smfz/sparse_matrix_textrank/,d3smfz,sparse_matrix_textrank,1Wittgenstein1,1.0,4,2019-09-13 19:29:36,0,2,,"Hi all,I want to run the standard TextRank algorithm on a quite large corpus (100,000 documents x 15+- sentences per document). The standard implementation. The purpose is text summarization.I am seeing popularized online (e.g., https://towardsdatascience.com/textrank-for-keyword-extraction-by-python-c0bae21bcec0) does not use a sparse matrix.Can someone point me to a reliable sparse matrix implementation ?",,"Projects,"
845,https://www.reddit.com/r/datascience/comments/d3padm/best_videos_introducing_machine_learning_theory/,d3padm,best_videos_introducing_machine_learning_theory,1st_parry,0.9,8,2019-09-13 15:30:15,0,6,,"Dipping my toes into ML after a year of data analysis. I want to watch a high level overview by someone passionate and knowledgeable of the subject, like a college video lecture. Any hints?Thanks!",,
846,https://www.reddit.com/r/datascience/comments/d3r6te/lyft_kaggle_challenge_3d_object_detection_for/,d3r6te,lyft_kaggle_challenge_3d_object_detection_for,SpecificTwo,0.62,3,2019-09-13 17:49:38,0,3,,,https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles,"Discussion,"
847,https://www.reddit.com/r/datascience/comments/d3u4zf/need_help_with_separating_a_column_in_r/,d3u4zf,need_help_with_separating_a_column_in_r,svargs01,0.4,0,2019-09-13 21:18:41,0,6,,"Hi!I’m currently working on cleaning up a dataset and I’m struggling with how to separate a date into Month, Day, Year. The date is listed in the column as 1012012 (for January 1, 2012). I can’t seem to figure out how to separate the column into three columns with day, month, and year without a delimiter. Also, I realized that for later months like October, it’d be 10012012 (the length of the character is different because 0 at the front of a data entry in CSV isn’t recognized). Let me know there’s anyway to manipulate this data.Thanks!",,"Projects,"
848,https://www.reddit.com/r/datascience/comments/d3w1aj/anyone_has_built_an_ai_beauty_context_jet_which/,d3w1aj,anyone_has_built_an_ai_beauty_context_jet_which,bodytexture,0.2,0,2019-09-13 23:38:08,0,5,,,,
849,https://www.reddit.com/r/datascience/comments/d3pyxo/thoughts_on_banjo/,d3pyxo,thoughts_on_banjo,greendogufo,0.5,0,2019-09-13 16:22:31,0,4,,I'm interested in any thoughts or opinions on the company Banjo:https://ban.jo/Specifically on the type of work they do related to criminal justice data.Thanks in advance for any feedback!,,"Discussion,"
850,https://www.reddit.com/r/datascience/comments/d366j6/an_article_i_wrote_giving_a_more_mathematical/,d366j6,an_article_i_wrote_giving_a_more_mathematical,ballzoffury,0.94,139,2019-09-12 12:57:32,0,18,,,https://dorianbrown.dev/what-is-supervised-learning/,
851,https://www.reddit.com/r/MachinesLearn/comments/d3663o/an_article_i_wrote_giving_a_more_mathematical/,d3663o,an_article_i_wrote_giving_a_more_mathematical,ballzoffury,0.89,48,2019-09-12 12:56:19,0,8,,,https://dorianbrown.dev/what-is-supervised-learning/,
852,https://www.reddit.com/r/datascience/comments/d3ov5e/if_youre_using_keras_is_it_possible_to_emulate/,d3ov5e,if_youre_using_keras_is_it_possible_to_emulate,snip3r77,0.67,1,2019-09-13 14:56:32,0,4,,as in manage to obtain similar score using the same optimization with fast.ai?how do we know what is being done under the hood for the latter.,,"Discussion,"
853,https://www.reddit.com/r/datascience/comments/d3jd3w/validity_of_certain_variables_in_a_conversion/,d3jd3w,validity_of_certain_variables_in_a_conversion,tacothecat,0.99,1,2019-09-13 05:35:01,0,0,,"I am working on a quote conversion model using training data consisting of the most recent iteration of quotes started in the past year.  I would like to include the quote sequence # in the model, essentially how many iterations in the quote process have been completed.  A quote sequence of 1 is guaranteed to be not converted and in general conversion increases with quote sequence.  Is this a valid variable to include?  Should i just exclude quotes with a sequence # of 1 to prevent leakage?",,
854,https://www.reddit.com/r/datascience/comments/d2rym1/this_video_shows_the_most_popular_programming/,d2rym1,this_video_shows_the_most_popular_programming,qaops,0.97,722,2019-09-11 17:31:48,0,91,,,,"Fun/Trivia,"
855,https://www.reddit.com/r/datascience/comments/d3aru2/reasonable_salary_expectations_for_a_manager_of/,d3aru2,reasonable_salary_expectations_for_a_manager_of,waynetrain017,0.78,5,2019-09-12 18:53:57,0,13,,"Hi all,I’m currently through 3 rounds of interviews for a Manager of Data Analytics position with a 3rd party company that works with a large network of college athletic departments. The athletic department I would work with would be considered an elite midwestern university.We are at the point where we’ll need to be on the same page compensation wise before they bring me out for the final interview with the athletic department. I was curious if anyone had previous experience in a role like this or in a similar sport analytics situation and what would be a reasonable salary request?Some background:alumni of the university I’d work withMS in data analytics and grad certificate in MIS1.5 years working as an analyst for an investment firm (current job)3 years as an analytics intern/consultant in Division I sports (undergrad/grad)Tableau/R/SQL/SPSS experienceJob requires me to move halfway across the countryCost of living would be ~5% cheaperWill have to pay out the remaining 6 months of my current leaseSignificantly unhappy with my current role/responsibilitiesI know sport organizations are typically able to acquire talent at a slight discount due to the “wow” factor of working in sports. Any insight regarding current manager of DA salaries, salaries in sports, or input on this current situation is greatly appreciated. Apologies for the vagueness of a few details.",,"Job Search,"
856,https://www.reddit.com/r/datascience/comments/d35nmk/are_there_are_good_introductions_for_awareness/,d35nmk,are_there_are_good_introductions_for_awareness,thatusername8346,0.82,7,2019-09-12 12:00:54,0,5,,"I'm a bit ignorant of things such as GDPR, and was wondering if anyone knew of some good introductions to things that I should perhaps be aware of when working with peoples data. I'm not expecting to be an expert in compliance or whatever, but it'd be nice to read though / watch some stuff that might at least encourage appropriate alarm bells to ring if I find myself doing something that might develop into an issue later or whatever.[edit] I'm in the UK, if that's useful information.",,"Discussion,"
857,https://www.reddit.com/r/datascience/comments/d37ac4/will_commercial_insurance_underwriting_be/,d37ac4,will_commercial_insurance_underwriting_be,Wooden_Team,0.64,3,2019-09-12 14:38:07,0,3,,I currently work as an insurance underwriter underwriting cyber liability for commercial applicants. I am wondering if my job is in danger of being replaced by big data? Is anybody working on this? Thanks,,
858,https://www.reddit.com/r/datascience/comments/d3aql9/data_management_coursevideo/,d3aql9,data_management_coursevideo,nutzki,0.33,0,2019-09-12 18:51:39,0,0,,"Anyone know of good resources/teaching material on basic data management (online course, videos, etc.)? I'd like to implement it into one of my classes and would appreciate any recommended material. I'm looking for more general stuff, like proper file naming, organizing of tables/dataframes, how to make 'tidy' data. Thanks!",,"Education,"
859,https://www.reddit.com/r/datascience/comments/d31y9k/statistical_modeling_with_python_howto_top/,d31y9k,statistical_modeling_with_python_howto_top,alphaharris1,0.73,9,2019-09-12 05:20:16,0,1,,"Statistical Modeling with Python: How-to & Top LibrariesThis post covers some of the essential statistical modeling frameworks and methods for Python, which can help us do statistical modeling and probabilistic computation.Introduction: Why Python for data scienceWhy these frameworks are necessaryStart with NumPyMatplotlib and Seaborn for visualizationUsing Seaborn and MatplotlibSciPy for inferential statisticsStatsmodels for advanced modelingScikit-learn for statistical learningConclusionWhy these frameworks are necessaryWhile Python is most popular for data wrangling, visualization, general machine learning, deep learning and associated linear algebra (tensor and matrix operations), and web integration, its statistical modeling abilities are far less advertised. A large percentage of data scientists still use other special statistical languages such as R, MATLAB, or SAS over Python for their modeling and analysis.While each of these alternatives offer their own unique blend of features and power for statistical analyses, it’s useful for an up-and-coming data scientist to know more about various Python frameworks and methods that can be used for routine operations of descriptive and inferential statistics.The biggest motivation for learning about these frameworks is that statistical inference and probabilistic modeling represent the bread and butter of a data scientists’ daily work. However, only by using such Python-based tools can a powerful end-to-end data science pipeline (a complete flow extending from data acquisition to final business decision generation) be built using a single programming language.If using different statistical languages for various tasks, you may face some problems. For example:Conducting any web scraping and database access using SQL commands and Python libraries such as BeautifulSoup and SQLalchemyCleaning up and preparing your data tables using Pandas, but then switching to R or SPSS for performing statistical tests and computing confidence intervalsUsing ggplot2 for creating visualization, and then using a standalone LaTeX editor to type up the final analytics reportSwitching between multiple programmatic frameworks makes the process cumbersome and error-prone.What if you could do statistical modeling, analysis, and visualization all inside a core Python platform? Let’s see what frameworks and methods exist for accomplishing such tasks.Start with NumPyNumPy is the de-facto standard for numerical computation in Python, used as the base for building more advanced libraries for data science and machine learning applications such as TensorFlow or Scikit-learn. For numeric processing, NumPy is much faster than native Python code due to the vectorized implementation of its methods and the fact that many of its core routines are written in C (based on the CPython framework).Although the majority of NumPy related discussions are focused on its linear algebra routines, it offers a decent set of statistical modeling functions for performing basic descriptive statistics and generating random variables based on various discrete and continuous distributions.For example, let’s create a NumPy array from a simple Python list and compute basic descriptive statistics like mean, median, standard deviation, quantiles, etc.The code for this article may be found at Kite’s Github repository.import numpy as np

# Define a python list
a_list = [2, 4, -1, 5.5, 3.5, -2, 5, 4, 6.5, 7.5]

# Convert the list into numpy array
an_array = np.array(a_list)

# Compute and print various statistics
print('Mean:', an_array.mean())
print('Median:', np.median(an_array))
print('Range (Max - min):', np.ptp(an_array))
print('Standard deviation:', an_array.std())
print('80th percentile:', np.percentile(an_array, 80))
print('0.2-quantile:', np.quantile(an_array, 0.2))
The results are as follows:Mean: 3.5
Median: 4.0
Range (Max - min): 9.5
Standard deviation: 2.9068883707497264
80th percentile: 5.699999999999999
0.2-quantile: 1.4000000000000001
To read more about Numpy, Matplotlib, Seaborn, and Statsmodels, check out the full article by Tirtha Sarkar.Tirtha Sarkar is a semiconductor technologist, data science author, and author of pydbgen, MLR, and doepy packages. He holds a Ph.D. in Electrical Engineering and M.S. in Data Analytics.",,"Discussion,"
860,https://www.reddit.com/r/datascience/comments/d2sreb/rejected_after_the_technical_part_of_interview/,d2sreb,rejected_after_the_technical_part_of_interview,poolguy8,0.92,64,2019-09-11 18:24:07,0,19,,"""Thank you for taking time to chat with our team. As I mentioned during the interview we have several candidates for this position.   Unfortunately, the other candidates had stronger technical skills in alignment with our work needs, and thus we will not be extending  you an internship offer at this time. You are certainly welcome to apply for a future internship with the group.  To be a stronger candidate you many want to focus  on fundamental skills, because with a strong foundation you can dive into any project.  If you have questions about specific skills  I would be glad to meet with you and chat about this more. Thank you again for considering our group and best of luck with your studies.""",,
861,https://www.reddit.com/r/datascience/comments/d35xex/how_much_python_is_enough_from_a_career_standpoint/,d35xex,how_much_python_is_enough_from_a_career_standpoint,NewStart793,0.43,0,2019-09-12 12:31:00,0,7,,"So, I have previously worked with Oracle SQL, Unix: shell scripting, sed; Java, OOP concepts in Java, design patterns and SOLID principles in Java, R programming. Sadly I don't know any front end stuff.I have recently started learning python using the tutorials on kaggle. I am not sure how much I need to know because I am not currently using python for anything in my masters. We had to learn about Hypothesis testing and linear modelling and etc, but we preferred using R and Excel in classes.My question is: How much python do I need to know for data science ? As an object oriented language, I feel that there should be a lot of stuff available, but how much should I know ?I taught myself Java using Kathy Sierra books and was preparing for OCJP at one point of time. There are so many in depth concepts in Java that it's difficult to say that you can be sure about all of them :)For example: Overriding, overloading, inheritance: interfaces and classes, exception handling, threading are all the tip of the iceberg.So, should I approach python the same way ? As an OOP language or what approach is better ?",,"Discussion,"
862,https://www.reddit.com/r/datascience/comments/d34qhj/im_a_teen_in_a_3rd_world_country_willing_to_be_a/,d34qhj,im_a_teen_in_a_3rd_world_country_willing_to_be_a,[deleted],0.54,1,2019-09-12 10:07:30,0,10,,,,"Education,"
863,https://www.reddit.com/r/datascience/comments/d2oh3m/new_job_offer_in_data_scienceengineering_in_a/,d2oh3m,new_job_offer_in_data_scienceengineering_in_a,ManBearHybrid,0.92,40,2019-09-11 13:15:33,0,17,,"Hi all, I've been offered a job at a med-tech company in Cambridge, UK, doing data science and data engineering (the actual job will require me to do a little of both - probably more engineering than science at first, but it will vary). The company started in 2015. My problem is that I'm not from the UK so I have no idea if the salary they're offering is within the market range for the local industry, and how it compares to cost-of-living, etc (rent in Cambridge is expensive!). I've tried to do some research online (Glassdoor, etc) but the results vary wildly.They've offered me about GBP 55k per year, plus benefits (life/health insurance, pension, etc). If I do a straight currency conversion to where I live now, this is decent - but cost of living is also very cheap here.Some background about me: I have a Master's degree in biomedical engineering. I worked for about four years doing clinical research and R&D of surgical products, but for the last year(ish) I've been working on a fixed-term contract writing code for a team of actuaries in the finance industry. This is where I picked up my skills in AWS, Python, databases, ETL, etc. This contract is coming to an end soon, though, which is why I'm looking for the next thing.The company also wants me there soon because I have European citizenship (don't live in Europe though), so would need to be living in the UK before Brexit happens to secure my right to live and work there. We both know that there's no guarantee that Brexit will even happen in October, but it's a risk that we need to manage.Please help guys, what are your thoughts here? Is this a decent offer or are they low-balling me?Thanks for readingEDIT: Thanks for the responses. I am suitably encouraged that it is a good offer.",,"Job Search,"
864,https://www.reddit.com/r/datascience/comments/d2uyto/which_jupyter_environment_would_you_recommend/,d2uyto,which_jupyter_environment_would_you_recommend,0_marauders_0,1.0,11,2019-09-11 20:50:27,0,6,,"ML friends, I'm super curious - for those of you who use Jupyter, which environment do you use? Which would you recommend?Vanilla JupyterJupyterLabKaggle KernelsGoogle CollabVS Code Jupyter notebooksOr another version?Thank you! :)",,"Discussion,"
865,https://www.reddit.com/r/datascience/comments/d2jhx2/how_do_you_guys_deal_with_feeling_inadequate_at/,d2jhx2,how_do_you_guys_deal_with_feeling_inadequate_at,sluglyfe2014,0.97,123,2019-09-11 04:56:41,0,34,,"A little bit of background:I have a bachelors degree in Molecular Biology with only a data boot camp certificate to my name. I’ve been programming/ practicing my data skills for just over a year now and I am 2.5 months into my new job as a data analyst at a tech startup in SF. I’ve been mostly working with python and SQL as a member of the data engineering team.I can’t tell if I’m just over thinking it but I feel like I’m disappointing my entire data team. I’ve been incredibly anxious at work due to feeling stupid and performing below expectations. It feels like every single member of the team is a genius and working as a cohesive team while I’m easily the most junior member that gets largely ignored. This has the negative side effect of making me self conscious about socializing or making friends at work even though everyone around me is really nice and friendly.Everyone’s been working long hours including weekends and I’m usually hesitant to ask questions because of how unimportant my work is compared to what they’re working on. I do also think that struggling through a problem is good for me in the long run although it can be quite frustrating in the short term.Whenever I do ask questions, I try to be as thorough as possible to show that I’ve thought deeply about the problem, but it feels like my manager would rather work on his own stuff. This is my first real 9-5 job and  I’d appreciate any advice on navigating my situation. Feels like I just word vomited my feelings so thanks for reading if you did.TLDR:Data bootcamper struggling to feel competent at work",,"Career,"
866,https://www.reddit.com/r/datascience/comments/d32c9a/what_software_and_tools_do_you_use_to_clean_your/,d32c9a,what_software_and_tools_do_you_use_to_clean_your,BombBurperZ,0.33,0,2019-09-12 05:54:36,0,4,,Or do you just use pandas? Is using tools a good practice or is learning everything about pandas more important? Is excel a good data cleaning tool?,,
867,https://www.reddit.com/r/datascience/comments/d319hp/how_much_programming_is_needed_in_data_science/,d319hp,how_much_programming_is_needed_in_data_science,Sorokose,0.5,0,2019-09-12 04:22:35,0,7,,Ive heard that data scientists generally dont do complex programming. Its basically computational statistics and data cleaning/visualization.Is this true?,,
868,https://www.reddit.com/r/datascience/comments/d2zy2h/what_types_of_integrationdifferentiation_are/,d2zy2h,what_types_of_integrationdifferentiation_are,WaveyJP,0.33,0,2019-09-12 02:38:40,0,3,,just asking because I'm not sure how much of my calc knowledge i should try to retain from alevel since the Uni course that I'm starting won't go heavily into calc for 2 years,,"Education,"
869,https://www.reddit.com/r/datascience/comments/d2xokk/is_there_any_indication_that_the_data_science_job/,d2xokk,is_there_any_indication_that_the_data_science_job,Chicagodivemaster,0.4,0,2019-09-11 23:52:10,0,13,,,,
870,https://www.reddit.com/r/datascience/comments/d2wqbw/how_to_make_woe_monotonic/,d2wqbw,how_to_make_woe_monotonic,octaviocipo,1.0,1,2019-09-11 22:47:35,0,3,,Hi everyone!I calculated weight of evidence of a variable which has .31 information value but variable is not monotonic. Should i use the variable on logistic regression model and how can i make it monotonic?Thanks!,,"Education,"
871,https://www.reddit.com/r/datascience/comments/d29qu0/scraping_a_public_website_doesnt_violate_the_cfaa/,d29qu0,scraping_a_public_website_doesnt_violate_the_cfaa,da_chosen1,0.98,196,2019-09-10 18:07:39,0,23,,"In a major ruling by the U.S. Ninth Circuit Court of Appeals, data that's publicly available (e.g. LinkedIn profiles) has been deemed to be legally okay to scrape. Depending on the data, there may be copyright violations but that's different. The ruling has huge implications for e-commerce businesses of all sorts.Article ",,"Discussion,"
872,https://www.reddit.com/r/datascience/comments/d2vyp4/partial_least_square_versus_traditional_mlr_in/,d2vyp4,partial_least_square_versus_traditional_mlr_in,dcap87,0.5,0,2019-09-11 21:56:44,0,3,,What is your opinion on using Partial Least Square regression on sample sets with correlated predictors versus stratifying and using MLR or simplifying the model to remove the correlated variable in a real world situation?I apologize in advance if this is a dumb question. I am a student.,,"Discussion,"
873,https://www.reddit.com/r/datascience/comments/d2vv2b/experiences_with_being_a_bootcamp_mentor/,d2vv2b,experiences_with_being_a_bootcamp_mentor,chef_lars,0.33,0,2019-09-11 21:50:01,0,1,,"I've been contacted a few times about potentially being a mentor for a data science bootcamp (specifically Thinkful). I'm guessing positions like this are similar to TAs in college courses but with perhaps more one on one interaction. Anyone have any experience with these types of positions? Thoughts on type of work, required amount of time, pay?I'm generally dubious about bootcamps but do enjoy helping out aspiring learners so I'm curious more than anything.",,"Discussion,"
874,https://www.reddit.com/r/datascience/comments/d2u6te/options_for_showcasing_projects/,d2u6te,options_for_showcasing_projects,hellowerlt,1.0,1,2019-09-11 19:58:18,0,1,,"I've been learning data science on my own over the past 4 months in the hopes of making a career switch. I feel confident enough to tackle my first project in R.  I want to be able to share my projects with potential employers. I'm aware of Git and its benefits. However, I'm overwhelmed at how to start using it.I tried installing GitHub Desktop onto my computer; but frankly, I'm running out of space on my C drive (less than 10 GB left). I have RStudio installed on my external drive. It is my understanding RStudio likes to look in the C drive so it can easily find Git.Is installing Git or GitHub Desktop necessary? If so, can I install Git to my external drive and tell RStudio to look for Git in that location?Alternatively, can I use the manual upload of my project files to GitHub?How much do employers care if you know Git (i.e., setting up a connection rather than manually uploading onto GitHub)?Sorry if these questions are stupid... I'm really new at this and just feel overwhelmed about what to do.",,"Projects,"
875,https://www.reddit.com/r/datascience/comments/d2tc1r/tips_on_retaining_python_knowledge_as_a_beginner/,d2tc1r,tips_on_retaining_python_knowledge_as_a_beginner,StickyballsParty,0.5,0,2019-09-11 19:01:58,0,13,,"I'm working my way through the IBM Data Science program and I'm finding it hard to retain all of the commands and syntax when it comes to things like Panda and Numpy.Should I pause these videos and use a separate site/tool to really understand Python completely before moving on? I don't want to get too sidetracked, but I am very confused. Any tips would be appreciated.",,
876,https://www.reddit.com/r/datascience/comments/d2huwa/reddit_tech_salary_sheet/,d2huwa,reddit_tech_salary_sheet,TomahawkChopped,1.0,16,2019-09-11 02:56:09,0,0,,"tldr; view reddit's tech salary data here (or download a csv) and share yours hereA recent comment in r/sysadmin makes it apparent that not everyone has access to the same amount of salary information for their company and industry as everyone else:https://www.reddit.com/r/sysadmin/comments/d28b5y/once_again_you_were_all_so_right_got_mad_looked/eztcjcn?utm_source=share&utm_medium=web2xHaving this data is a benefit to you and sharing it is a benefit to the world. As the commenter above put it, the taboo associated with not discussing salary information only benefits the companies that use this lack of public information to their benefit in salary negotiations.Inside Google we've had an open spreadsheet for years that allows employees from all ladders, locations, and levels to add salary information. This usually gets sliced up and filtered across different dimensions making for some interesting insights:https://qz.com/458615/theres-reportedly-a-big-secret-spreadsheet-where-google-employees-share-their-salaries/I don't see why we can't have an open store of information sourced from various tech career related subs to create a similar body of knowledge. I've created this form and have opened the backing spreadsheet  for this purpose. I hope it leads to some interesting insights:salary form: https://forms.gle/u1uQKqzVdZisBYUx7raw data: https://docs.google.com/spreadsheets/d/13icckT8wb2ME3FTzgGyokoCTQMU9kBMqQXvg0V3_x54(I have not added my own info to the form yet so that I don't reveal too much personally identifiable information - I will do so when the form collects a significant number of responses).edit: added a tldr;edit2: to download a CSV click here, thanks u/freelusi0n:https://spreadsheets.google.com/feeds/download/spreadsheets/Export?key=13icckT8wb2ME3FTzgGyokoCTQMU9kBMqQXvg0V3_x54&exportFormat=csvalso I understand everyone wants filters, but for the moment there are too many viewers on the sheet, so even if I add filters to the edit view I don't think you'll see them due to the traffic on the sheet. my best advice is to download the CSV above and copy into a private sheet of your own, then filter from there. in the meantime I'll see if there is a better way to scale seeing the raw dataothers have asked for more charts in the summary results, the ones that are at the end are simply provided by Forms to summarize the data, I don't think I have control over those.",https://www.reddit.com/r/sysadmin/comments/d2g4hm/reddit_tech_salary_sheet/,"Meta,"
877,https://www.reddit.com/r/sysadmin/comments/d2g4hm/reddit_tech_salary_sheet/,d2g4hm,reddit_tech_salary_sheet,TomahawkChopped,0.98,864,2019-09-11 00:51:58,0,373,"Tech,","tldr; view reddit's tech salary data here (or download a csv) and share yours hereA recent comment in r/sysadmin makes it apparent that not everyone has access to the same amount of salary information for their company and industry as everyone else:https://www.reddit.com/r/sysadmin/comments/d28b5y/once_again_you_were_all_so_right_got_mad_looked/eztcjcn?utm_source=share&utm_medium=web2xHaving this data is a benefit to you and sharing it is a benefit to the world. As the commenter above put it, the taboo associated with not discussing salary information only benefits the companies that use this lack of public information to their benefit in salary negotiations.Inside Google we've had an open spreadsheet for years that allows employees from all ladders, locations, and levels to add salary information. This usually gets sliced up and filtered across different dimensions making for some interesting insights:https://qz.com/458615/theres-reportedly-a-big-secret-spreadsheet-where-google-employees-share-their-salaries/I don't see why we can't have an open store of information sourced from various tech career related subs to create a similar body of knowledge. I've created this form and have opened the backing spreadsheet  for this purpose. I hope it leads to some interesting insights:salary form: https://forms.gle/u1uQKqzVdZisBYUx7raw data: https://docs.google.com/spreadsheets/d/13icckT8wb2ME3FTzgGyokoCTQMU9kBMqQXvg0V3_x54(I have not added my own info to the form yet so that I don't reveal too much personally identifiable information - I will do so when the form collects a significant number of responses).edit: added a tldr;edit2: to download a CSV click here, thanks u/freelusi0n:https://spreadsheets.google.com/feeds/download/spreadsheets/Export?key=13icckT8wb2ME3FTzgGyokoCTQMU9kBMqQXvg0V3_x54&exportFormat=csvalso I understand everyone wants filters, but for the moment there are too many viewers on the sheet, so even if I add filters to the edit view I don't think you'll see them due to the traffic on the sheet. my best advice is to download the CSV above and copy into a private sheet of your own, then filter from there. in the meantime I'll see if there is a better way to scale seeing the raw dataothers have asked for more charts in the summary results, the ones that are at the end are simply provided by Forms to summarize the data, I don't think I have control over those.",,
878,https://www.reddit.com/r/datascience/comments/d2k7uy/open_source_alternative_reporting_tool_to_power_bi/,d2k7uy,open_source_alternative_reporting_tool_to_power_bi,laisant,1.0,8,2019-09-11 05:55:24,0,7,,"I've been creating reports for my company for a while, and the de facto interface for report creation and distribution is Power BI. The tool is great for many reasons, but one glaring issue in my case is the fact that a Power BI premium workspace can only have a single Power BI app related to it. Thus, for different audiences, I would need different premium workspaces, and that is not always ideal.What I'd like to have is a systematic workflow for interactive report creation and distribution that doesn't have this limitation. The resource would preferably be open source, so that way the budget does not have to compete with Power BI.I enjoy using R, and a Shiny Report would have all the functionality I would need for the type of reporting I do, but I am unsure from a development process what having a space where I could grant another person access to download a report, or what other sort of specifications I would need.For reference, I'm fairly well versed when it comes to the statistics side of data science, but the engineering aspect is completely foreign to me. Hopefully this endeavor can be a step in the right direction!",,"Discussion,"
879,https://www.reddit.com/r/datascience/comments/d2rlep/fraud_detection_in_bank_transaction/,d2rlep,fraud_detection_in_bank_transaction,Elbarro,0.67,1,2019-09-11 17:06:55,0,7,,"Hey guys.I was recently moved to a new project, in which the objective is to detect fraudulent transaction. The data set will have information about the clients, the transaction and the account manager. The problem that we have is that, the dataset is really imbalanced (much less fraudulent transactions than fraudulent). We considered some solutions like using SMOTE but we are current studying the usage of Generative Adversarial Networks.Anyway, I am just posting this know if anybody here has any experience in this type of scenario and if so, if you can give us some pointers or some techniques that you have used in the past that worked well in a similar scenario.We don't have the data set yet, but it should include transaction data from 5 to 10 years.Thank you!",,"Projects,"
880,https://www.reddit.com/r/datascience/comments/d2r9na/generating_data/,d2r9na,generating_data,VminVsky,1.0,1,2019-09-11 16:45:13,0,0,,"Hi everyone,I'm currently tasked with generating sales data between two timestamps. The user is supposed to input the time range, the average number of customers that come during for each hour during each day in a week. I was wondering what type of modelling or simulation I should use to create this?The task is to generate my own data to create graphs and run algorithms on before we have access to the real data.Thanks.",,"Projects,"
881,https://www.reddit.com/r/datascience/comments/d2czsl/if_youre_having_trouble_breaking_into_the_field/,d2czsl,if_youre_having_trouble_breaking_into_the_field,minced314,0.78,29,2019-09-10 21:33:28,0,22,,,https://www.pcmag.com/news/370627/looking-to-switch-careers-data-science-is-booming,
882,https://www.reddit.com/r/datascience/comments/d2q7dg/what_do_you_love_or_hate_about_jupyter_notebooks/,d2q7dg,what_do_you_love_or_hate_about_jupyter_notebooks,cambridge295,0.5,0,2019-09-11 15:30:41,0,10,,"For example, I love ability to do data science relatively fast, but hate that there is no way to collaborate with others on a notebook.",,"Discussion,"
883,https://www.reddit.com/r/datascience/comments/d25jhr/data_analysis_screencast_like_david_robinsons/,d25jhr,data_analysis_screencast_like_david_robinsons,Pervert_Spongebob,0.94,125,2019-09-10 12:15:37,0,16,,I really like David Robinson's videos of real time data analysis with datasets from github. I wonder if there are more channels that post videos like this? Could still be in R or in Python,,
884,https://www.reddit.com/r/datascience/comments/d2o4r3/faces_dataset_with_career_annotations/,d2o4r3,faces_dataset_with_career_annotations,rosamundo,0.4,0,2019-09-11 12:44:01,0,0,,Does anyone know of any open-source dataset of faces with career annotations?Thank you!,,"Projects,"
885,https://www.reddit.com/r/datascience/comments/d2i2o7/nontraditional_data_visualisation/,d2i2o7,nontraditional_data_visualisation,trivial_importance,0.83,4,2019-09-11 03:11:48,0,1,,"What are some non-traditional data that you have worked on or are working on? By non-traditional, I mean that cannot be visualized using simple bar plots, histogram, line plots or scatter plots. Some that requires a custom way of looking at it.How did you go about it? What was the end result?",,"Discussion,"
886,https://www.reddit.com/r/datascience/comments/d2lkr0/need_literature_on_how_to_handle_data_sets/,d2lkr0,need_literature_on_how_to_handle_data_sets,milanm23,0.4,0,2019-09-11 08:01:25,0,4,,Hi there. I need to analyze a data set with 100000 observations with 20 covariates. 10 of them are dummies. Can anyone suggest me any literature how to handle data sets with a lot of dummies? Thanks,,
887,https://www.reddit.com/r/datascience/comments/d2e11q/unsupervised_learning_to_market_behavior/,d2e11q,unsupervised_learning_to_market_behavior,lamres,0.64,3,2019-09-10 22:36:55,0,1,,This article describes the technique that forecasts the market behavior. The second part demonstrates the application of the approach in a trading strategy.https://towardsdatascience.com/unsupervised-learning-to-market-behavior-forecasting-ee8f78650415,https://www.reddit.com/r/stocks/comments/d2ci4t/unsupervised_learning_to_market_behavior/,"Projects,"
888,https://www.reddit.com/r/stocks/comments/d2ci4t/unsupervised_learning_to_market_behavior/,d2ci4t,unsupervised_learning_to_market_behavior,lamres,0.88,7,2019-09-10 21:03:13,0,0,"Finance & Business,",This article describes the technique that forecasts the market behavior. The second part demonstrates the application of the approach in a trading strategy.https://towardsdatascience.com/unsupervised-learning-to-market-behavior-forecasting-ee8f78650415,,
889,https://www.reddit.com/r/datascience/comments/d2jo4r/how_to_approach_string_variable_where_each/,d2jo4r,how_to_approach_string_variable_where_each,cladindryice,1.0,1,2019-09-11 05:10:17,0,1,,"Hi all, I’m currently struggling on a personal project and need some advice as to what’s the next step for me. My project is essentially predicting police fatalities in US metropolises; the dataset is filled with mostly categorical (e.g. SubjectArmed, SubjectRace, etc. )  and string variables (e.g. NatureOfStop, Notes (of the event that took place), etc.).There is a string variable called FullNarrative. Sometimes, it’s a single paragraph giving context to what the officer(s)/victim were doing before an incident took place and sometimes, it’s a link to an article outlining the event. With other string variables like NatureOfStop, I used the BJS’ definition of different types of crime and labeled if an event was a property crime, violent crime, drug-related crime, mental health related, etc.Working with the variable NatureOfStop took a lot of labor, and I’m not sure if what I did for that variable would be the best use of my time, especially when I’m given a small paragraph with lots of detail. How should I approach this variable? I’ve been suggested to look into basic NLP techniques, but I’m not familiar with NLP at all so I don’t really know what it is I need.Thanks a lot!",,"Projects,"
890,https://www.reddit.com/r/datascience/comments/d2b588/eli5_apache_spark_hadoop_tensorflow_tableau_other/,d2b588,eli5_apache_spark_hadoop_tensorflow_tableau_other,the_emcee,0.8,3,2019-09-10 19:36:19,0,2,,"This post is going to be very naive and I'm sorry.I'm a recent college grad with a BA in Economics and a Comp Sci minor who wants to eventually end up in Data Science. I've taken courses and have some prior experience that allowed for statistical analysis in Python and R (touch of SQL extraction as well), but I know nothing about industry-standard tools of the trade. Like does it even make sense for me to ask ""how does a 22-yr-old bum on a job hunt 'start' using Apache Spark?""Are these tools what I ""graduate"" into from doing projects in a .ipynb where I'm, for example, looking at features of a csv dataset of emails to predict whether they're spam or not?Also, some data analyst positions I'm applying to (because data scientist itself seems above my paygrade until I do more machine learning stuff in grad school hopefully) place a lot of focus on Excel (with VLOOKUP and Pivot Tables being considered ""advanced""); is that a bit of a red flag in the sense I won't be learning much towards pivoting out of Data Analyst into Data Scientist? Maybe I just don't know enough about Excel's regression analysis functionality or interconnected-ness with other tools/codestacks, but it seems like a data team emphasizing Excel wouldn't be caught up to speed with the industry",,"Discussion,"
891,https://www.reddit.com/r/datascience/comments/d22ahc/forming_a_data_for_good_group/,d22ahc,forming_a_data_for_good_group,laisant,0.84,31,2019-09-10 05:52:55,0,12,,"Full disclosure, this is going to be a bit of a long post.I’ve been in the analytics industry for about a year now, and have slowly been coming to the realization that serving the needs of whatever company I work for is not going to be fulfilling. To be clear, I don’t mean that the work isn’t satisfying, challenging, and stimulating, just that doing this type of work isn’t fulfilling. Furthermore, I feel as if it is unfair of me to put that kind of weight on a job which, by its nature, is designed to simply keep making people money.Without getting into the weeds too much, I want to take the skills and techniques I’ve been able to develop through my schooling, side projects, and my day job, and use them for something that could be fulfilling. I also want to be able to help my community (I live in the Saint Louis, MO area; there’s no shortage of social issues around here). I know that there are hackathons and similar competitions that present themselves every few months, but I want something a little more consistent.  In short, I want to form a group  of likeminded people who would get together on a regular basis to tackle social issues in the area, like crime rates, child death, etc.Would anyone happen to know how to go about starting such a project, and how to keep it going? I’ve checked out apps like Meetup to try and see if such a thing exists here and, and it seems like there is a panel that might meet up every now and then, but other than that my search hasn’t yielded anything.Thanks to everyone who made it this far, and I look forward to hearing your feedback!",,"Discussion,"
892,https://www.reddit.com/r/datascience/comments/d2e0lm/where_do_data_scientist_and_analysis_spend_most/,d2e0lm,where_do_data_scientist_and_analysis_spend_most,gmh1977,0.46,0,2019-09-10 22:36:09,0,6,,"I made this graphic for a presentation at work to try to emphasis how much time it takes to preprocess and structure data. Do you just find that you spend most of your time in the data modeling stage? Also, do you think I should put percentages?During my presentation is there anything I should highlight for these staages.Any feedback is welcomed.  I used the word analyiss cause the PHD data scientist at my company reserve that title :)",,"Discussion,"
893,https://www.reddit.com/r/datascience/comments/d2dz5b/am_i_hurting_the_growth_of_myself_and_team_by/,d2dz5b,am_i_hurting_the_growth_of_myself_and_team_by,Reksalp105,0.67,1,2019-09-10 22:33:46,0,6,,"Hope the title makes sense.I oversee a small (3 person) analytics team for my organization. LSS - I was the company's sole Data Analyst that moved out of IT to support our Sales Group exclusively and ultimately was assigned under our Financial leadership. (3 years ago)The company is beginning to invest in an Analytics infrastructure; our IT group has brought on BI / Data Analytics resources that offer what I believe to be more expertise than what my current vertical [management] offers. As the title states, am I handicapping my and my team's growth by remaining under the Finance organization?",,"Discussion,"
894,https://www.reddit.com/r/datascience/comments/d2dsyz/project_lead_advice/,d2dsyz,project_lead_advice,Wozezeka,1.0,1,2019-09-10 22:23:09,0,3,,I've been managing a large portfolio of projects for two years now and I've been promoted. Now I'll have an analyst and research assistant to help me manage the workload I've been managing solo (so relieved!). Overseeing the work of others will be new to me and I'm looking for resources about managing team data projects. I feel like it might be different from typical team management because everything is so inter-dependent with databases and code.,,"Projects,"
895,https://www.reddit.com/r/datascience/comments/d1xxhx/can_you_derive_the_most_likely_ruleset_of_this/,d1xxhx,can_you_derive_the_most_likely_ruleset_of_this,AbyssExpander,0.87,53,2019-09-10 00:04:14,0,7,,,,"Projects,"
896,https://www.reddit.com/r/datascience/comments/d2d5l4/looking_for_us_city_population_510_yr_growth/,d2d5l4,looking_for_us_city_population_510_yr_growth,TechMeetsRealEstate,0.5,0,2019-09-10 21:43:11,0,0,,"I'm pretty sure I've scoured the government (Census, BLS, FRED) and oft-cited economic organization (Brookings, Pew, Urban Institute, ULI, UVA StatChat) websites for some sort of projection, but I may have missed something... Is there a reputable or generally relied upon dataset that estimates population growth projections for US cities?",,"Discussion,"
897,https://www.reddit.com/r/datascience/comments/d2glns/advice_for_first_interview_with_facebook_recruiter/,d2glns,advice_for_first_interview_with_facebook_recruiter,brinestx,0.43,0,2019-09-11 01:25:10,0,4,,"Hello everyone! I have an initial phone interview next week with a FB recruiter for a data science internship position. I'm not really sure what to expect, so I'm studying up on behavioral questions, projects that I've done in the past as well as questions that might be related to SQL and R. For those of you that have gone through this process, what should I expect for a first round, and do you have any advice for prepping?",,"Job Search,"
